{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4920f6d-a0b9-48d9-9178-072a257a302f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: 0\n",
      "Dataset classes: ['angry', 'contempt', 'disgust', 'fear', 'happy', 'natural', 'sad', 'sleepy', 'surprised']\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# 1. ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏûÑÌè¨Ìä∏ Î∞è Í∏∞Î≥∏ ÏÑ§Ï†ï\n",
    "# --------------------------------------------------------------------------\n",
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics.utils.torch_utils import model_info\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 2. Ïã§Ìóò ÌôòÍ≤Ω Î∞è ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "# Ïã§Ìóò ÎåÄÏÉÅ Î™®Îç∏ Î¶¨Ïä§Ìä∏\n",
    "MODELS_TO_TEST = ['yolov5n', 'yolov8n', 'yolov10n'] # ÏòàÏãúÎ°ú Î™®Îç∏ ÏàòÎ•º Ï§ÑÏûÑ, ÌïÑÏöîÏãú ÏàòÏ†ï\n",
    "# Îç∞Ïù¥ÌÑ∞ Ï¶ùÍ∞ï ÏòµÏÖò Î¶¨Ïä§Ìä∏\n",
    "AUGMENT_OPTIONS = [True, False]\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î∞è Î™®Îç∏ Ï†ÄÏû• Í≤ΩÎ°ú (ÏÇ¨Ïö©Ïûê ÌôòÍ≤ΩÏóê ÎßûÍ≤å ÏàòÏ†ï)\n",
    "DATA_PATH = r\"D:\\Virtual_Fahion\\GraduationThesis2\\data\"\n",
    "MODEL_SAVE_DIR = r\"D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\"\n",
    "\n",
    "# ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 16\n",
    "IMG_SIZE = 640\n",
    "OPTIMIZER = 'Adam'\n",
    "\n",
    "# GPU ÏÑ§Ï†ï\n",
    "DEVICE = '0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ YAML ÌååÏùº Î°úÎìú\n",
    "data_yaml_path = os.path.join(DATA_PATH, 'data.yaml')\n",
    "with open(data_yaml_path) as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "print(f\"Dataset classes: {data_config['names']}\")\n",
    "\n",
    "# F1-Score Í≥ÑÏÇ∞ Ìï®Ïàò\n",
    "def calculate_f1_score(precision, recall):\n",
    "    return 2 * (precision * recall) / (precision + recall + 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d4b8803-a1fd-4d69-8589-3ae79fd7533c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üöÄ STARTING EXPERIMENT FOR MODEL: yolov5n (Aug: True)\n",
      "============================================================\n",
      "\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov5nu.pt to 'yolov5nu.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.3MB 73.3MB/s 0.1s\n",
      "New https://pypi.org/project/ultralytics/8.3.203 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=D:\\Virtual_Fahion\\GraduationThesis2\\data\\data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train_yolov5n_aug_True, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=D:\\Virtual_Fahion\\GraduationThesis2\\saveModels, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov5n_aug_True, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    753067  ultralytics.nn.modules.head.Detect           [9, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,510,219 parameters, 2,510,203 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.4MB 60.7MB/s 0.1s\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 434.5599.6 MB/s, size: 67.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2\\data\\train\\labels.cache... 64864 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 64864/64864 64.8Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 367.876.9 MB/s, size: 43.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2\\data\\valid\\labels.cache... 1720 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1720/1720 1.7Mit/s 0.0s\n",
      "Plotting labels to D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov5n_aug_True\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov5n_aug_True\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/30      2.04G      1.261      2.159      1.624         48        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 8.8it/s 7:42<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 6.9it/s 7.8s0.2s\n",
      "                   all       1720       1720      0.298      0.314      0.183     0.0982\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/30      2.37G      1.184      1.958      1.548         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 9.7it/s 6:600<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.5it/s 7.2s0.1s\n",
      "                   all       1720       1720       0.32      0.449      0.292       0.17\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/30      2.37G      1.134      1.852      1.506         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.1it/s 6:41<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.7it/s 7.0s0.1s\n",
      "                   all       1720       1720      0.351      0.501      0.406      0.251\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/30      2.37G        1.1       1.76      1.481         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.3it/s 6:34<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.4it/s 7.3s0.1s\n",
      "                   all       1720       1720       0.42      0.491      0.448      0.288\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/30      2.37G      1.078      1.706      1.462         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.3it/s 6:33<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.7it/s 7.0s0.1s\n",
      "                   all       1720       1720      0.387      0.535      0.471      0.312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/30      2.37G      1.053      1.659      1.446         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.3it/s 6:34<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.5it/s 7.2s0.1s\n",
      "                   all       1720       1720      0.452      0.566      0.508      0.335\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/30      2.37G       1.04      1.623      1.437         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.3it/s 6:34<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.7it/s 7.1s0.1s\n",
      "                   all       1720       1720      0.451      0.575      0.525      0.351\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/30      2.37G      1.031      1.598      1.431         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.3it/s 6:34<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.7it/s 7.0s0.1s\n",
      "                   all       1720       1720      0.472      0.593      0.538      0.366\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/30      2.37G      1.023      1.573      1.424         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.3it/s 6:35<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.7it/s 7.0s0.1s\n",
      "                   all       1720       1720      0.513      0.582      0.563      0.386\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/30      2.37G      1.015      1.557      1.418         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.3it/s 6:34<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.5it/s 7.2s0.1s\n",
      "                   all       1720       1720      0.518      0.579      0.576      0.397\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/30      2.37G      1.009      1.538      1.416         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.3it/s 6:33<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.5it/s 7.2s0.1s\n",
      "                   all       1720       1720      0.513      0.589      0.585      0.408\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/30      2.37G     0.9972       1.52      1.408         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.3it/s 6:34<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.6it/s 7.1s0.1s\n",
      "                   all       1720       1720      0.514      0.621      0.597      0.416\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/30      2.37G     0.9912      1.498      1.403         43        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.3it/s 6:34<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.6it/s 7.1s0.1s\n",
      "                   all       1720       1720       0.53      0.619      0.607      0.426\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/30      2.37G      0.987       1.48      1.398         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.3it/s 6:34<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.4it/s 7.3s0.1s\n",
      "                   all       1720       1720      0.542      0.615      0.611      0.429\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/30      2.37G     0.9772      1.467      1.392         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.3it/s 6:34<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.7it/s 7.0s0.1s\n",
      "                   all       1720       1720      0.553      0.603      0.615      0.433\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/30      2.37G     0.9734      1.456       1.39         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.3it/s 6:34<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.5it/s 7.2s0.1s\n",
      "                   all       1720       1720      0.546      0.611      0.614      0.434\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/30      2.37G     0.9664      1.438      1.385         37        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.3it/s 6:34<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.7it/s 7.1s0.1s\n",
      "                   all       1720       1720      0.546      0.617      0.618      0.435\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/30      2.37G       0.96      1.421      1.382         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.3it/s 6:34<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.7it/s 7.0s0.1s\n",
      "                   all       1720       1720      0.554      0.606      0.621      0.437\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/30      2.37G     0.9526      1.406      1.376         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.3it/s 6:34<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.6it/s 7.1s0.1s\n",
      "                   all       1720       1720      0.572      0.595      0.626      0.441\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/30      2.37G      0.947      1.395       1.37         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.3it/s 6:34<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.6it/s 7.1s0.1s\n",
      "                   all       1720       1720      0.578      0.589      0.629      0.445\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/30      2.37G      0.956      1.163      1.544         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.4it/s 6:30<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.7it/s 7.0s0.1s\n",
      "                   all       1720       1720      0.575      0.595      0.634       0.45\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/30      2.37G     0.9293      1.114      1.518         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.4it/s 6:29<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.6it/s 7.1s0.1s\n",
      "                   all       1720       1720      0.585      0.606       0.64      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/30      2.37G     0.9152       1.08      1.502         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.4it/s 6:30<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.6it/s 7.1s0.1s\n",
      "                   all       1720       1720      0.589      0.617      0.645      0.461\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/30      2.37G     0.9055       1.05      1.491         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.4it/s 6:29<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.6it/s 7.1s0.1s\n",
      "                   all       1720       1720      0.597      0.611      0.652      0.467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/30      2.37G     0.8914      1.028      1.479         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.4it/s 6:30<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.7it/s 7.0s0.1s\n",
      "                   all       1720       1720      0.608      0.609      0.658      0.472\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/30      2.37G     0.8767      1.001      1.465         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.4it/s 6:29<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.7it/s 7.0s0.1s\n",
      "                   all       1720       1720      0.612      0.609      0.663      0.477\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/30      2.37G     0.8641     0.9758      1.454         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.4it/s 6:30<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.8it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.622      0.614      0.669      0.482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/30      2.37G     0.8536      0.947       1.44         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.4it/s 6:31<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.4it/s 7.3s0.1s\n",
      "                   all       1720       1720      0.631      0.615      0.673      0.487\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/30      2.37G     0.8408      0.922       1.43         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.3it/s 6:34<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.6it/s 7.1s0.1s\n",
      "                   all       1720       1720      0.647      0.617      0.678      0.491\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/30      2.37G     0.8288     0.9007      1.418         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.3it/s 6:33<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.7it/s 7.1s0.1s\n",
      "                   all       1720       1720      0.652      0.619      0.683      0.496\n",
      "\n",
      "30 epochs completed in 3.368 hours.\n",
      "Optimizer stripped from D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov5n_aug_True\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov5n_aug_True\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov5n_aug_True\\weights\\best.pt...\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,504,699 parameters, 0 gradients, 7.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 5.4it/s 10.1s.2s\n",
      "                   all       1720       1720      0.632       0.64      0.691      0.511\n",
      "                 angry        258        258       0.58      0.643      0.695      0.526\n",
      "              contempt         82         82      0.581       0.61      0.678      0.567\n",
      "               disgust        108        108      0.651      0.546      0.663      0.575\n",
      "                  fear        107        107      0.585      0.684      0.661      0.533\n",
      "                 happy        387        387      0.779      0.832      0.885      0.672\n",
      "               natural        172        172      0.542      0.488      0.527      0.349\n",
      "                   sad        312        312      0.495      0.715      0.674      0.448\n",
      "                sleepy         38         38       0.83      0.515      0.648      0.327\n",
      "             surprised        256        256      0.643       0.73      0.791      0.597\n",
      "Speed: 0.2ms preprocess, 1.7ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov5n_aug_True\u001b[0m\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,504,699 parameters, 0 gradients, 7.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 655.2633.2 MB/s, size: 80.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2\\data\\valid\\labels.cache... 1720 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1720/1720  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 108/108 12.8it/s 8.4s0.2s\n",
      "                   all       1720       1720       0.65      0.621      0.683      0.496\n",
      "                 angry        258        258      0.604      0.601      0.697      0.517\n",
      "              contempt         82         82      0.631      0.598      0.653      0.517\n",
      "               disgust        108        108      0.646      0.444      0.619      0.515\n",
      "                  fear        107        107       0.59      0.654      0.654      0.521\n",
      "                 happy        387        387      0.798      0.855      0.894      0.663\n",
      "               natural        172        172      0.515      0.506      0.508      0.338\n",
      "                   sad        312        312      0.531      0.674      0.671      0.435\n",
      "                sleepy         38         38       0.88        0.5      0.651       0.36\n",
      "             surprised        256        256      0.661      0.754      0.799      0.595\n",
      "Speed: 0.2ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2\\runs\\detect\\val\u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "üìà VISUALIZING TRAINING & VALIDATION ANALYSIS FOR: yolov5n (Aug: True)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "üìä EXTRACTING PERFORMANCE INDICATORS FOR: yolov5n (Aug: True)\n",
      "--------------------------------------------------\n",
      "layer                                    name                type  gradient  parameters               shape        mu     sigma\n",
      "    0                     model.0.conv.weight              Conv2d     False        1728       [16, 3, 6, 6]  -0.00934      2.05        float32\n",
      "    0                       model.0.conv.bias              Conv2d     False          16                [16]      0.49      5.28        float32\n",
      "    1                             model.0.act                SiLU     False           0                  []         -         -              -\n",
      "    2                     model.1.conv.weight              Conv2d     False        4608      [32, 16, 3, 3]  -0.00358     0.193        float32\n",
      "    2                       model.1.conv.bias              Conv2d     False          32                [32]     0.882      6.37        float32\n",
      "    3                 model.2.cv1.conv.weight              Conv2d     False         512      [16, 32, 1, 1]  -0.00843    0.0483        float32\n",
      "    3                   model.2.cv1.conv.bias              Conv2d     False          16                [16]      1.51      3.75        float32\n",
      "    4                 model.2.cv2.conv.weight              Conv2d     False         512      [16, 32, 1, 1]   -0.0127     0.139        float32\n",
      "    4                   model.2.cv2.conv.bias              Conv2d     False          16                [16]      2.88      4.75        float32\n",
      "    5                 model.2.cv3.conv.weight              Conv2d     False        1024      [32, 32, 1, 1]  -0.00757     0.158        float32\n",
      "    5                   model.2.cv3.conv.bias              Conv2d     False          32                [32]      0.78      4.31        float32\n",
      "    6             model.2.m.0.cv1.conv.weight              Conv2d     False         256      [16, 16, 1, 1]   0.00837     0.586        float32\n",
      "    6               model.2.m.0.cv1.conv.bias              Conv2d     False          16                [16]      1.14      6.96        float32\n",
      "    7             model.2.m.0.cv2.conv.weight              Conv2d     False        2304      [16, 16, 3, 3]   -0.0061      0.13        float32\n",
      "    7               model.2.m.0.cv2.conv.bias              Conv2d     False          16                [16]     0.532      4.05        float32\n",
      "    8                     model.3.conv.weight              Conv2d     False       18432      [64, 32, 3, 3] -0.000821    0.0328        float32\n",
      "    8                       model.3.conv.bias              Conv2d     False          64                [64]     0.544      3.82        float32\n",
      "    9                 model.4.cv1.conv.weight              Conv2d     False        2048      [32, 64, 1, 1] -0.000553    0.0569        float32\n",
      "    9                   model.4.cv1.conv.bias              Conv2d     False          32                [32]       1.6      4.31        float32\n",
      "   10                 model.4.cv2.conv.weight              Conv2d     False        2048      [32, 64, 1, 1]   0.00483     0.162        float32\n",
      "   10                   model.4.cv2.conv.bias              Conv2d     False          32                [32]     0.662      4.71        float32\n",
      "   11                 model.4.cv3.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  -0.00387     0.112        float32\n",
      "   11                   model.4.cv3.conv.bias              Conv2d     False          64                [64]     -2.13      5.06        float32\n",
      "   12             model.4.m.0.cv1.conv.weight              Conv2d     False        1024      [32, 32, 1, 1]  0.000971     0.139        float32\n",
      "   12               model.4.m.0.cv1.conv.bias              Conv2d     False          32                [32]     -1.34      5.25        float32\n",
      "   13             model.4.m.0.cv2.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  0.000421    0.0402        float32\n",
      "   13               model.4.m.0.cv2.conv.bias              Conv2d     False          32                [32]    -0.646      2.35        float32\n",
      "   14             model.4.m.1.cv1.conv.weight              Conv2d     False        1024      [32, 32, 1, 1]   -0.0119     0.189        float32\n",
      "   14               model.4.m.1.cv1.conv.bias              Conv2d     False          32                [32]    -0.718      6.16        float32\n",
      "   15             model.4.m.1.cv2.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00229     0.063        float32\n",
      "   15               model.4.m.1.cv2.conv.bias              Conv2d     False          32                [32]     0.972       3.9        float32\n",
      "   16                     model.5.conv.weight              Conv2d     False       73728     [128, 64, 3, 3]  0.000376    0.0207        float32\n",
      "   16                       model.5.conv.bias              Conv2d     False         128               [128]     -1.23      3.37        float32\n",
      "   17                 model.6.cv1.conv.weight              Conv2d     False        8192     [64, 128, 1, 1]  1.29e-05    0.0276        float32\n",
      "   17                   model.6.cv1.conv.bias              Conv2d     False          64                [64]   -0.0243      4.23        float32\n",
      "   18                 model.6.cv2.conv.weight              Conv2d     False        8192     [64, 128, 1, 1]  0.000568     0.108        float32\n",
      "   18                   model.6.cv2.conv.bias              Conv2d     False          64                [64]    -0.791      3.61        float32\n",
      "   19                 model.6.cv3.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]  -0.00283    0.0584        float32\n",
      "   19                   model.6.cv3.conv.bias              Conv2d     False         128               [128]     -3.04      6.02        float32\n",
      "   20             model.6.m.0.cv1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  0.000668     0.111        float32\n",
      "   20               model.6.m.0.cv1.conv.bias              Conv2d     False          64                [64]     -4.88      4.69        float32\n",
      "   21             model.6.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -8.19e-05     0.013        float32\n",
      "   21               model.6.m.0.cv2.conv.bias              Conv2d     False          64                [64]    -0.716      3.03        float32\n",
      "   22             model.6.m.1.cv1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  -0.00751     0.143        float32\n",
      "   22               model.6.m.1.cv1.conv.bias              Conv2d     False          64                [64]     -2.87      5.99        float32\n",
      "   23             model.6.m.1.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -0.00097    0.0326        float32\n",
      "   23               model.6.m.1.cv2.conv.bias              Conv2d     False          64                [64]    -0.453      3.12        float32\n",
      "   24             model.6.m.2.cv1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  -0.00776     0.112        float32\n",
      "   24               model.6.m.2.cv1.conv.bias              Conv2d     False          64                [64]     -2.97      6.43        float32\n",
      "   25             model.6.m.2.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000613    0.0352        float32\n",
      "   25               model.6.m.2.cv2.conv.bias              Conv2d     False          64                [64]    -0.356      3.84        float32\n",
      "   26                     model.7.conv.weight              Conv2d     False      294912    [256, 128, 3, 3] -8.32e-06    0.0084        float32\n",
      "   26                       model.7.conv.bias              Conv2d     False         256               [256]     -2.66      3.42        float32\n",
      "   27                 model.8.cv1.conv.weight              Conv2d     False       32768    [128, 256, 1, 1]     6e-06    0.0136        float32\n",
      "   27                   model.8.cv1.conv.bias              Conv2d     False         128               [128]     -2.01      3.74        float32\n",
      "   28                 model.8.cv2.conv.weight              Conv2d     False       32768    [128, 256, 1, 1] -0.000508    0.0265        float32\n",
      "   28                   model.8.cv2.conv.bias              Conv2d     False         128               [128]     -2.72      5.02        float32\n",
      "   29                 model.8.cv3.conv.weight              Conv2d     False       65536    [256, 256, 1, 1] -0.000667     0.033        float32\n",
      "   29                   model.8.cv3.conv.bias              Conv2d     False         256               [256]     -2.71      4.05        float32\n",
      "   30             model.8.m.0.cv1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]  -0.00191     0.105        float32\n",
      "   30               model.8.m.0.cv1.conv.bias              Conv2d     False         128               [128]     -5.58      5.47        float32\n",
      "   31             model.8.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -6.67e-05    0.0103        float32\n",
      "   31               model.8.m.0.cv2.conv.bias              Conv2d     False         128               [128]     -2.84      3.79        float32\n",
      "   32                 model.9.cv1.conv.weight              Conv2d     False       32768    [128, 256, 1, 1]  -0.00272    0.0398        float32\n",
      "   32                   model.9.cv1.conv.bias              Conv2d     False         128               [128]      2.23      7.09        float32\n",
      "   33                 model.9.cv2.conv.weight              Conv2d     False      131072    [256, 512, 1, 1]  5.46e-06     0.017        float32\n",
      "   33                   model.9.cv2.conv.bias              Conv2d     False         256               [256]     -3.56      5.65        float32\n",
      "   34                               model.9.m           MaxPool2d     False           0                  []         -         -              -\n",
      "   35                    model.10.conv.weight              Conv2d     False       32768    [128, 256, 1, 1]  -0.00436     0.103        float32\n",
      "   35                      model.10.conv.bias              Conv2d     False         128               [128]     -2.23      4.36        float32\n",
      "   36                                model.11            Upsample     False           0                  []         -         -              -\n",
      "   37                                model.12              Concat     False           0                  []         -         -              -\n",
      "   38                model.13.cv1.conv.weight              Conv2d     False       16384     [64, 256, 1, 1] -0.000819    0.0504        float32\n",
      "   38                  model.13.cv1.conv.bias              Conv2d     False          64                [64]     -2.24      4.22        float32\n",
      "   39                model.13.cv2.conv.weight              Conv2d     False       16384     [64, 256, 1, 1]  -0.00144    0.0458        float32\n",
      "   39                  model.13.cv2.conv.bias              Conv2d     False          64                [64]    -0.262      4.85        float32\n",
      "   40                model.13.cv3.conv.weight              Conv2d     False       16384    [128, 128, 1, 1] -8.97e-05     0.051        float32\n",
      "   40                  model.13.cv3.conv.bias              Conv2d     False         128               [128]     -1.75      4.46        float32\n",
      "   41            model.13.m.0.cv1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  -0.00154     0.184        float32\n",
      "   41              model.13.m.0.cv1.conv.bias              Conv2d     False          64                [64]     -3.74      4.53        float32\n",
      "   42            model.13.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  3.05e-05    0.0103        float32\n",
      "   42              model.13.m.0.cv2.conv.bias              Conv2d     False          64                [64]    -0.693       4.2        float32\n",
      "   43                    model.14.conv.weight              Conv2d     False        8192     [64, 128, 1, 1]  1.25e-05    0.0217        float32\n",
      "   43                      model.14.conv.bias              Conv2d     False          64                [64]     0.815      5.35        float32\n",
      "   44                                model.15            Upsample     False           0                  []         -         -              -\n",
      "   45                                model.16              Concat     False           0                  []         -         -              -\n",
      "   46                model.17.cv1.conv.weight              Conv2d     False        4096     [32, 128, 1, 1] -0.000181    0.0513        float32\n",
      "   46                  model.17.cv1.conv.bias              Conv2d     False          32                [32]     0.429      4.74        float32\n",
      "   47                model.17.cv2.conv.weight              Conv2d     False        4096     [32, 128, 1, 1]   0.00134    0.0644        float32\n",
      "   47                  model.17.cv2.conv.bias              Conv2d     False          32                [32]      3.14      4.71        float32\n",
      "   48                model.17.cv3.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  0.000954     0.088        float32\n",
      "   48                  model.17.cv3.conv.bias              Conv2d     False          64                [64]     -2.43      4.73        float32\n",
      "   49            model.17.m.0.cv1.conv.weight              Conv2d     False        1024      [32, 32, 1, 1]  -0.00229     0.103        float32\n",
      "   49              model.17.m.0.cv1.conv.bias              Conv2d     False          32                [32]     -3.59      5.68        float32\n",
      "   50            model.17.m.0.cv2.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  4.95e-06    0.0226        float32\n",
      "   50              model.17.m.0.cv2.conv.bias              Conv2d     False          32                [32]     0.604      3.85        float32\n",
      "   51                    model.18.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  8.86e-05    0.0109        float32\n",
      "   51                      model.18.conv.bias              Conv2d     False          64                [64]    -0.465      4.57        float32\n",
      "   52                                model.19              Concat     False           0                  []         -         -              -\n",
      "   53                model.20.cv1.conv.weight              Conv2d     False        8192     [64, 128, 1, 1]   0.00202    0.0703        float32\n",
      "   53                  model.20.cv1.conv.bias              Conv2d     False          64                [64]     -1.99       4.5        float32\n",
      "   54                model.20.cv2.conv.weight              Conv2d     False        8192     [64, 128, 1, 1]  0.000766    0.0452        float32\n",
      "   54                  model.20.cv2.conv.bias              Conv2d     False          64                [64]     -1.25      5.07        float32\n",
      "   55                model.20.cv3.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]   0.00017    0.0551        float32\n",
      "   55                  model.20.cv3.conv.bias              Conv2d     False         128               [128]     -3.56      4.43        float32\n",
      "   56            model.20.m.0.cv1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]   0.00156    0.0588        float32\n",
      "   56              model.20.m.0.cv1.conv.bias              Conv2d     False          64                [64]     -1.92      4.14        float32\n",
      "   57            model.20.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000209    0.0158        float32\n",
      "   57              model.20.m.0.cv2.conv.bias              Conv2d     False          64                [64]     -0.79      3.03        float32\n",
      "   58                    model.21.conv.weight              Conv2d     False      147456    [128, 128, 3, 3]  5.46e-05   0.00662        float32\n",
      "   58                      model.21.conv.bias              Conv2d     False         128               [128]      -3.8      3.11        float32\n",
      "   59                                model.22              Concat     False           0                  []         -         -              -\n",
      "   60                model.23.cv1.conv.weight              Conv2d     False       32768    [128, 256, 1, 1] -8.51e-05    0.0548        float32\n",
      "   60                  model.23.cv1.conv.bias              Conv2d     False         128               [128]     -1.82      4.44        float32\n",
      "   61                model.23.cv2.conv.weight              Conv2d     False       32768    [128, 256, 1, 1]  -0.00083    0.0613        float32\n",
      "   61                  model.23.cv2.conv.bias              Conv2d     False         128               [128]     -4.04      4.28        float32\n",
      "   62                model.23.cv3.conv.weight              Conv2d     False       65536    [256, 256, 1, 1] -0.000504    0.0366        float32\n",
      "   62                  model.23.cv3.conv.bias              Conv2d     False         256               [256]     -5.81      4.31        float32\n",
      "   63            model.23.m.0.cv1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]  0.000796    0.0498        float32\n",
      "   63              model.23.m.0.cv1.conv.bias              Conv2d     False         128               [128]     -5.63      4.81        float32\n",
      "   64            model.23.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3]  -7.7e-05     0.014        float32\n",
      "   64              model.23.m.0.cv2.conv.bias              Conv2d     False         128               [128]     -2.85      3.36        float32\n",
      "   65            model.24.cv2.0.0.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000431    0.0143        float32\n",
      "   65              model.24.cv2.0.0.conv.bias              Conv2d     False          64                [64]     -3.71      4.65        float32\n",
      "   66            model.24.cv2.0.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000151   0.00703        float32\n",
      "   66              model.24.cv2.0.1.conv.bias              Conv2d     False          64                [64]     -6.87      4.88        float32\n",
      "   67                 model.24.cv2.0.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   0.00477    0.0831        float32\n",
      "   67                   model.24.cv2.0.2.bias              Conv2d     False          64                [64]      1.73      1.61        float32\n",
      "   68            model.24.cv2.1.0.conv.weight              Conv2d     False       73728     [64, 128, 3, 3] -0.000264    0.0087        float32\n",
      "   68              model.24.cv2.1.0.conv.bias              Conv2d     False          64                [64]     -3.99      5.06        float32\n",
      "   69            model.24.cv2.1.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000352   0.00984        float32\n",
      "   69              model.24.cv2.1.1.conv.bias              Conv2d     False          64                [64]     -5.58      5.64        float32\n",
      "   70                 model.24.cv2.1.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   0.00658     0.131        float32\n",
      "   70                   model.24.cv2.1.2.bias              Conv2d     False          64                [64]     0.908      1.86        float32\n",
      "   71            model.24.cv2.2.0.conv.weight              Conv2d     False      147456     [64, 256, 3, 3] -0.000377    0.0137        float32\n",
      "   71              model.24.cv2.2.0.conv.bias              Conv2d     False          64                [64]     -1.28      4.05        float32\n",
      "   72            model.24.cv2.2.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000923    0.0117        float32\n",
      "   72              model.24.cv2.2.1.conv.bias              Conv2d     False          64                [64]    -0.238      2.36        float32\n",
      "   73                 model.24.cv2.2.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   -0.0287     0.298        float32\n",
      "   73                   model.24.cv2.2.2.bias              Conv2d     False          64                [64]      0.65       2.4        float32\n",
      "   74            model.24.cv3.0.0.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000178    0.0114        float32\n",
      "   74              model.24.cv3.0.0.conv.bias              Conv2d     False          64                [64]     -4.86      5.24        float32\n",
      "   75            model.24.cv3.0.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  6.58e-05   0.00376        float32\n",
      "   75              model.24.cv3.0.1.conv.bias              Conv2d     False          64                [64]     -5.81      4.58        float32\n",
      "   76                 model.24.cv3.0.2.weight              Conv2d     False         576       [9, 64, 1, 1]   -0.0216     0.134        float32\n",
      "   76                   model.24.cv3.0.2.bias              Conv2d     False           9                 [9]      -9.2      2.31        float32\n",
      "   77            model.24.cv3.1.0.conv.weight              Conv2d     False       73728     [64, 128, 3, 3] -5.63e-05   0.00746        float32\n",
      "   77              model.24.cv3.1.0.conv.bias              Conv2d     False          64                [64]     -5.79      4.51        float32\n",
      "   78            model.24.cv3.1.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -4.67e-05   0.00974        float32\n",
      "   78              model.24.cv3.1.1.conv.bias              Conv2d     False          64                [64]      -5.9      4.76        float32\n",
      "   79                 model.24.cv3.1.2.weight              Conv2d     False         576       [9, 64, 1, 1]   -0.0436     0.179        float32\n",
      "   79                   model.24.cv3.1.2.bias              Conv2d     False           9                 [9]     -6.25     0.877        float32\n",
      "   80            model.24.cv3.2.0.conv.weight              Conv2d     False      147456     [64, 256, 3, 3] -0.000101   0.00694        float32\n",
      "   80              model.24.cv3.2.0.conv.bias              Conv2d     False          64                [64]     -5.13      4.59        float32\n",
      "   81            model.24.cv3.2.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -0.00111     0.142        float32\n",
      "   81              model.24.cv3.2.1.conv.bias              Conv2d     False          64                [64]     -2.41      4.37        float32\n",
      "   82                 model.24.cv3.2.2.weight              Conv2d     False         576       [9, 64, 1, 1]    -0.166     0.362        float32\n",
      "   82                   model.24.cv3.2.2.bias              Conv2d     False           9                 [9]     -3.87      1.31        float32\n",
      "   83                model.24.dfl.conv.weight              Conv2d     False          16       [1, 16, 1, 1]       7.5      4.76        float32\n",
      "YOLOv5n summary (fused): 84 layers, 2,504,699 parameters, 0 gradients, 7.1 GFLOPs\n",
      "\n",
      "============================================================\n",
      "üöÄ STARTING EXPERIMENT FOR MODEL: yolov5n (Aug: False)\n",
      "============================================================\n",
      "\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.203 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=D:\\Virtual_Fahion\\GraduationThesis2\\data\\data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train_yolov5n_aug_False, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=D:\\Virtual_Fahion\\GraduationThesis2\\saveModels, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov5n_aug_False, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    753067  ultralytics.nn.modules.head.Detect           [9, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,510,219 parameters, 2,510,203 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 200.570.9 MB/s, size: 20.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2\\data\\train\\labels.cache... 64864 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 64864/64864 64.8Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 534.9402.4 MB/s, size: 83.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2\\data\\valid\\labels.cache... 1720 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1720/1720 1.7Mit/s 0.0s\n",
      "Plotting labels to D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov5n_aug_False\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov5n_aug_False\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/30      2.12G      1.261      2.159      1.624         48        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 8.7it/s 7:45<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.5it/s 7.2s0.1s\n",
      "                   all       1720       1720      0.298      0.314      0.183     0.0982\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/30      2.44G      1.184      1.958      1.548         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 9.6it/s 7:01<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.7it/s 7.1s0.1s\n",
      "                   all       1720       1720       0.32      0.449      0.292       0.17\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/30      2.44G      1.134      1.852      1.506         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.0it/s 6:45<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.5it/s 7.2s0.1s\n",
      "                   all       1720       1720      0.351      0.501      0.406      0.251\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/30      2.45G        1.1       1.76      1.481         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.2it/s 6:38<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.6it/s 7.1s0.1s\n",
      "                   all       1720       1720       0.42      0.491      0.448      0.288\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/30      2.45G      1.078      1.706      1.462         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.2it/s 6:38<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.7it/s 7.0s0.1s\n",
      "                   all       1720       1720      0.387      0.535      0.471      0.312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/30      2.45G      1.053      1.659      1.446         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.1it/s 6:40<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.6it/s 7.1s0.1s\n",
      "                   all       1720       1720      0.452      0.566      0.508      0.335\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/30      2.45G       1.04      1.623      1.437         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.2it/s 6:37<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.451      0.575      0.525      0.351\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/30      2.45G      1.031      1.598      1.431         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.4it/s 6:31<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.8it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.472      0.593      0.538      0.366\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/30      2.45G      1.023      1.573      1.424         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.4it/s 6:30<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.8it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.513      0.582      0.563      0.386\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/30      2.45G      1.015      1.557      1.418         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.4it/s 6:30<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.8it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.518      0.579      0.576      0.397\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/30      2.45G      1.009      1.538      1.416         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.4it/s 6:30<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.513      0.589      0.585      0.408\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/30      2.45G     0.9972       1.52      1.408         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.4it/s 6:29<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.8it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.514      0.621      0.597      0.416\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/30      2.45G     0.9912      1.498      1.403         43        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.4it/s 6:29<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.7it/s 7.0s0.1s\n",
      "                   all       1720       1720       0.53      0.619      0.607      0.426\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/30      2.45G      0.987       1.48      1.398         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.3it/s 6:32<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.8it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.542      0.615      0.611      0.429\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/30      2.45G     0.9772      1.467      1.392         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.3it/s 6:32<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.8it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.553      0.603      0.615      0.433\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/30      2.45G     0.9734      1.456       1.39         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.3it/s 6:32<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.6it/s 7.1s0.1s\n",
      "                   all       1720       1720      0.546      0.611      0.614      0.434\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/30      2.45G     0.9664      1.438      1.385         37        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.4it/s 6:31<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.8it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.546      0.617      0.618      0.435\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/30      2.45G       0.96      1.421      1.382         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.4it/s 6:31<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.554      0.606      0.621      0.437\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/30      2.45G     0.9526      1.406      1.376         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.4it/s 6:31<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.8it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.572      0.595      0.626      0.441\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/30      2.45G      0.947      1.395       1.37         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.4it/s 6:31<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.7it/s 7.0s0.1s\n",
      "                   all       1720       1720      0.578      0.589      0.629      0.445\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/30      2.45G      0.956      1.163      1.544         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.5it/s 6:28<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.8it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.575      0.595      0.634       0.45\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/30      2.45G     0.9293      1.114      1.518         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.5it/s 6:27<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.8it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.585      0.606       0.64      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/30      2.45G     0.9152       1.08      1.502         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.5it/s 6:27<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.6it/s 7.1s0.1s\n",
      "                   all       1720       1720      0.589      0.617      0.645      0.461\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/30      2.45G     0.9055       1.05      1.491         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.5it/s 6:27<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.597      0.611      0.652      0.467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/30      2.45G     0.8914      1.028      1.479         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.5it/s 6:28<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.7it/s 7.0s0.1s\n",
      "                   all       1720       1720      0.608      0.609      0.658      0.472\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/30      2.45G     0.8767      1.001      1.465         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.5it/s 6:28<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.8it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.612      0.609      0.663      0.477\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/30      2.45G     0.8641     0.9758      1.454         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.5it/s 6:27<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.622      0.614      0.669      0.482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/30      2.45G     0.8536      0.947       1.44         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.5it/s 6:27<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.6it/s 7.1s0.1s\n",
      "                   all       1720       1720      0.631      0.615      0.673      0.487\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/30      2.45G     0.8408      0.922       1.43         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.5it/s 6:27<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.8it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.647      0.617      0.678      0.491\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/30      2.45G     0.8288     0.9007      1.418         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.5it/s 6:28<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.652      0.619      0.683      0.496\n",
      "\n",
      "30 epochs completed in 3.353 hours.\n",
      "Optimizer stripped from D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov5n_aug_False\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov5n_aug_False\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov5n_aug_False\\weights\\best.pt...\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,504,699 parameters, 0 gradients, 7.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 6.5it/s 8.4s0.1s\n",
      "                   all       1720       1720      0.652      0.621      0.683      0.496\n",
      "                 angry        258        258      0.608      0.597        0.7      0.518\n",
      "              contempt         82         82      0.643      0.598      0.653      0.517\n",
      "               disgust        108        108      0.646      0.444      0.619      0.515\n",
      "                  fear        107        107       0.59      0.654      0.654       0.52\n",
      "                 happy        387        387      0.799      0.855      0.894      0.663\n",
      "               natural        172        172      0.516      0.506      0.508      0.338\n",
      "                   sad        312        312       0.53      0.673      0.671      0.434\n",
      "                sleepy         38         38       0.88        0.5       0.65       0.36\n",
      "             surprised        256        256      0.659      0.758      0.799      0.595\n",
      "Speed: 0.3ms preprocess, 0.7ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov5n_aug_False\u001b[0m\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,504,699 parameters, 0 gradients, 7.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 861.4235.6 MB/s, size: 36.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2\\data\\valid\\labels.cache... 1720 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1720/1720 1.7Mit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 108/108 13.5it/s 8.0s0.1s\n",
      "                   all       1720       1720       0.65      0.621      0.683      0.496\n",
      "                 angry        258        258      0.604      0.601      0.697      0.517\n",
      "              contempt         82         82      0.631      0.598      0.653      0.517\n",
      "               disgust        108        108      0.646      0.444      0.619      0.515\n",
      "                  fear        107        107       0.59      0.654      0.654      0.521\n",
      "                 happy        387        387      0.798      0.855      0.894      0.663\n",
      "               natural        172        172      0.515      0.506      0.508      0.338\n",
      "                   sad        312        312      0.531      0.674      0.671      0.435\n",
      "                sleepy         38         38       0.88        0.5      0.651       0.36\n",
      "             surprised        256        256      0.661      0.754      0.799      0.595\n",
      "Speed: 0.2ms preprocess, 0.9ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2\\runs\\detect\\val2\u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "üìà VISUALIZING TRAINING & VALIDATION ANALYSIS FOR: yolov5n (Aug: False)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "üìä EXTRACTING PERFORMANCE INDICATORS FOR: yolov5n (Aug: False)\n",
      "--------------------------------------------------\n",
      "layer                                    name                type  gradient  parameters               shape        mu     sigma\n",
      "    0                     model.0.conv.weight              Conv2d     False        1728       [16, 3, 6, 6]  -0.00934      2.05        float32\n",
      "    0                       model.0.conv.bias              Conv2d     False          16                [16]      0.49      5.28        float32\n",
      "    1                             model.0.act                SiLU     False           0                  []         -         -              -\n",
      "    2                     model.1.conv.weight              Conv2d     False        4608      [32, 16, 3, 3]  -0.00358     0.193        float32\n",
      "    2                       model.1.conv.bias              Conv2d     False          32                [32]     0.882      6.37        float32\n",
      "    3                 model.2.cv1.conv.weight              Conv2d     False         512      [16, 32, 1, 1]  -0.00843    0.0483        float32\n",
      "    3                   model.2.cv1.conv.bias              Conv2d     False          16                [16]      1.51      3.75        float32\n",
      "    4                 model.2.cv2.conv.weight              Conv2d     False         512      [16, 32, 1, 1]   -0.0127     0.139        float32\n",
      "    4                   model.2.cv2.conv.bias              Conv2d     False          16                [16]      2.88      4.75        float32\n",
      "    5                 model.2.cv3.conv.weight              Conv2d     False        1024      [32, 32, 1, 1]  -0.00757     0.158        float32\n",
      "    5                   model.2.cv3.conv.bias              Conv2d     False          32                [32]      0.78      4.31        float32\n",
      "    6             model.2.m.0.cv1.conv.weight              Conv2d     False         256      [16, 16, 1, 1]   0.00837     0.586        float32\n",
      "    6               model.2.m.0.cv1.conv.bias              Conv2d     False          16                [16]      1.14      6.96        float32\n",
      "    7             model.2.m.0.cv2.conv.weight              Conv2d     False        2304      [16, 16, 3, 3]   -0.0061      0.13        float32\n",
      "    7               model.2.m.0.cv2.conv.bias              Conv2d     False          16                [16]     0.532      4.05        float32\n",
      "    8                     model.3.conv.weight              Conv2d     False       18432      [64, 32, 3, 3] -0.000821    0.0328        float32\n",
      "    8                       model.3.conv.bias              Conv2d     False          64                [64]     0.544      3.82        float32\n",
      "    9                 model.4.cv1.conv.weight              Conv2d     False        2048      [32, 64, 1, 1] -0.000553    0.0569        float32\n",
      "    9                   model.4.cv1.conv.bias              Conv2d     False          32                [32]       1.6      4.31        float32\n",
      "   10                 model.4.cv2.conv.weight              Conv2d     False        2048      [32, 64, 1, 1]   0.00483     0.162        float32\n",
      "   10                   model.4.cv2.conv.bias              Conv2d     False          32                [32]     0.662      4.71        float32\n",
      "   11                 model.4.cv3.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  -0.00387     0.112        float32\n",
      "   11                   model.4.cv3.conv.bias              Conv2d     False          64                [64]     -2.13      5.06        float32\n",
      "   12             model.4.m.0.cv1.conv.weight              Conv2d     False        1024      [32, 32, 1, 1]  0.000971     0.139        float32\n",
      "   12               model.4.m.0.cv1.conv.bias              Conv2d     False          32                [32]     -1.34      5.25        float32\n",
      "   13             model.4.m.0.cv2.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  0.000421    0.0402        float32\n",
      "   13               model.4.m.0.cv2.conv.bias              Conv2d     False          32                [32]    -0.646      2.35        float32\n",
      "   14             model.4.m.1.cv1.conv.weight              Conv2d     False        1024      [32, 32, 1, 1]   -0.0119     0.189        float32\n",
      "   14               model.4.m.1.cv1.conv.bias              Conv2d     False          32                [32]    -0.718      6.16        float32\n",
      "   15             model.4.m.1.cv2.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00229     0.063        float32\n",
      "   15               model.4.m.1.cv2.conv.bias              Conv2d     False          32                [32]     0.972       3.9        float32\n",
      "   16                     model.5.conv.weight              Conv2d     False       73728     [128, 64, 3, 3]  0.000376    0.0207        float32\n",
      "   16                       model.5.conv.bias              Conv2d     False         128               [128]     -1.23      3.37        float32\n",
      "   17                 model.6.cv1.conv.weight              Conv2d     False        8192     [64, 128, 1, 1]  1.29e-05    0.0276        float32\n",
      "   17                   model.6.cv1.conv.bias              Conv2d     False          64                [64]   -0.0243      4.23        float32\n",
      "   18                 model.6.cv2.conv.weight              Conv2d     False        8192     [64, 128, 1, 1]  0.000568     0.108        float32\n",
      "   18                   model.6.cv2.conv.bias              Conv2d     False          64                [64]    -0.791      3.61        float32\n",
      "   19                 model.6.cv3.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]  -0.00283    0.0584        float32\n",
      "   19                   model.6.cv3.conv.bias              Conv2d     False         128               [128]     -3.04      6.02        float32\n",
      "   20             model.6.m.0.cv1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  0.000668     0.111        float32\n",
      "   20               model.6.m.0.cv1.conv.bias              Conv2d     False          64                [64]     -4.88      4.69        float32\n",
      "   21             model.6.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -8.19e-05     0.013        float32\n",
      "   21               model.6.m.0.cv2.conv.bias              Conv2d     False          64                [64]    -0.716      3.03        float32\n",
      "   22             model.6.m.1.cv1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  -0.00751     0.143        float32\n",
      "   22               model.6.m.1.cv1.conv.bias              Conv2d     False          64                [64]     -2.87      5.99        float32\n",
      "   23             model.6.m.1.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -0.00097    0.0326        float32\n",
      "   23               model.6.m.1.cv2.conv.bias              Conv2d     False          64                [64]    -0.453      3.12        float32\n",
      "   24             model.6.m.2.cv1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  -0.00776     0.112        float32\n",
      "   24               model.6.m.2.cv1.conv.bias              Conv2d     False          64                [64]     -2.97      6.43        float32\n",
      "   25             model.6.m.2.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000613    0.0352        float32\n",
      "   25               model.6.m.2.cv2.conv.bias              Conv2d     False          64                [64]    -0.356      3.84        float32\n",
      "   26                     model.7.conv.weight              Conv2d     False      294912    [256, 128, 3, 3] -8.32e-06    0.0084        float32\n",
      "   26                       model.7.conv.bias              Conv2d     False         256               [256]     -2.66      3.42        float32\n",
      "   27                 model.8.cv1.conv.weight              Conv2d     False       32768    [128, 256, 1, 1]     6e-06    0.0136        float32\n",
      "   27                   model.8.cv1.conv.bias              Conv2d     False         128               [128]     -2.01      3.74        float32\n",
      "   28                 model.8.cv2.conv.weight              Conv2d     False       32768    [128, 256, 1, 1] -0.000508    0.0265        float32\n",
      "   28                   model.8.cv2.conv.bias              Conv2d     False         128               [128]     -2.72      5.02        float32\n",
      "   29                 model.8.cv3.conv.weight              Conv2d     False       65536    [256, 256, 1, 1] -0.000667     0.033        float32\n",
      "   29                   model.8.cv3.conv.bias              Conv2d     False         256               [256]     -2.71      4.05        float32\n",
      "   30             model.8.m.0.cv1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]  -0.00191     0.105        float32\n",
      "   30               model.8.m.0.cv1.conv.bias              Conv2d     False         128               [128]     -5.58      5.47        float32\n",
      "   31             model.8.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -6.67e-05    0.0103        float32\n",
      "   31               model.8.m.0.cv2.conv.bias              Conv2d     False         128               [128]     -2.84      3.79        float32\n",
      "   32                 model.9.cv1.conv.weight              Conv2d     False       32768    [128, 256, 1, 1]  -0.00272    0.0398        float32\n",
      "   32                   model.9.cv1.conv.bias              Conv2d     False         128               [128]      2.23      7.09        float32\n",
      "   33                 model.9.cv2.conv.weight              Conv2d     False      131072    [256, 512, 1, 1]  5.46e-06     0.017        float32\n",
      "   33                   model.9.cv2.conv.bias              Conv2d     False         256               [256]     -3.56      5.65        float32\n",
      "   34                               model.9.m           MaxPool2d     False           0                  []         -         -              -\n",
      "   35                    model.10.conv.weight              Conv2d     False       32768    [128, 256, 1, 1]  -0.00436     0.103        float32\n",
      "   35                      model.10.conv.bias              Conv2d     False         128               [128]     -2.23      4.36        float32\n",
      "   36                                model.11            Upsample     False           0                  []         -         -              -\n",
      "   37                                model.12              Concat     False           0                  []         -         -              -\n",
      "   38                model.13.cv1.conv.weight              Conv2d     False       16384     [64, 256, 1, 1] -0.000819    0.0504        float32\n",
      "   38                  model.13.cv1.conv.bias              Conv2d     False          64                [64]     -2.24      4.22        float32\n",
      "   39                model.13.cv2.conv.weight              Conv2d     False       16384     [64, 256, 1, 1]  -0.00144    0.0458        float32\n",
      "   39                  model.13.cv2.conv.bias              Conv2d     False          64                [64]    -0.262      4.85        float32\n",
      "   40                model.13.cv3.conv.weight              Conv2d     False       16384    [128, 128, 1, 1] -8.97e-05     0.051        float32\n",
      "   40                  model.13.cv3.conv.bias              Conv2d     False         128               [128]     -1.75      4.46        float32\n",
      "   41            model.13.m.0.cv1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  -0.00154     0.184        float32\n",
      "   41              model.13.m.0.cv1.conv.bias              Conv2d     False          64                [64]     -3.74      4.53        float32\n",
      "   42            model.13.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  3.05e-05    0.0103        float32\n",
      "   42              model.13.m.0.cv2.conv.bias              Conv2d     False          64                [64]    -0.693       4.2        float32\n",
      "   43                    model.14.conv.weight              Conv2d     False        8192     [64, 128, 1, 1]  1.25e-05    0.0217        float32\n",
      "   43                      model.14.conv.bias              Conv2d     False          64                [64]     0.815      5.35        float32\n",
      "   44                                model.15            Upsample     False           0                  []         -         -              -\n",
      "   45                                model.16              Concat     False           0                  []         -         -              -\n",
      "   46                model.17.cv1.conv.weight              Conv2d     False        4096     [32, 128, 1, 1] -0.000181    0.0513        float32\n",
      "   46                  model.17.cv1.conv.bias              Conv2d     False          32                [32]     0.429      4.74        float32\n",
      "   47                model.17.cv2.conv.weight              Conv2d     False        4096     [32, 128, 1, 1]   0.00134    0.0644        float32\n",
      "   47                  model.17.cv2.conv.bias              Conv2d     False          32                [32]      3.14      4.71        float32\n",
      "   48                model.17.cv3.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  0.000954     0.088        float32\n",
      "   48                  model.17.cv3.conv.bias              Conv2d     False          64                [64]     -2.43      4.73        float32\n",
      "   49            model.17.m.0.cv1.conv.weight              Conv2d     False        1024      [32, 32, 1, 1]  -0.00229     0.103        float32\n",
      "   49              model.17.m.0.cv1.conv.bias              Conv2d     False          32                [32]     -3.59      5.68        float32\n",
      "   50            model.17.m.0.cv2.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  4.95e-06    0.0226        float32\n",
      "   50              model.17.m.0.cv2.conv.bias              Conv2d     False          32                [32]     0.604      3.85        float32\n",
      "   51                    model.18.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  8.86e-05    0.0109        float32\n",
      "   51                      model.18.conv.bias              Conv2d     False          64                [64]    -0.465      4.57        float32\n",
      "   52                                model.19              Concat     False           0                  []         -         -              -\n",
      "   53                model.20.cv1.conv.weight              Conv2d     False        8192     [64, 128, 1, 1]   0.00202    0.0703        float32\n",
      "   53                  model.20.cv1.conv.bias              Conv2d     False          64                [64]     -1.99       4.5        float32\n",
      "   54                model.20.cv2.conv.weight              Conv2d     False        8192     [64, 128, 1, 1]  0.000766    0.0452        float32\n",
      "   54                  model.20.cv2.conv.bias              Conv2d     False          64                [64]     -1.25      5.07        float32\n",
      "   55                model.20.cv3.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]   0.00017    0.0551        float32\n",
      "   55                  model.20.cv3.conv.bias              Conv2d     False         128               [128]     -3.56      4.43        float32\n",
      "   56            model.20.m.0.cv1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]   0.00156    0.0588        float32\n",
      "   56              model.20.m.0.cv1.conv.bias              Conv2d     False          64                [64]     -1.92      4.14        float32\n",
      "   57            model.20.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000209    0.0158        float32\n",
      "   57              model.20.m.0.cv2.conv.bias              Conv2d     False          64                [64]     -0.79      3.03        float32\n",
      "   58                    model.21.conv.weight              Conv2d     False      147456    [128, 128, 3, 3]  5.46e-05   0.00662        float32\n",
      "   58                      model.21.conv.bias              Conv2d     False         128               [128]      -3.8      3.11        float32\n",
      "   59                                model.22              Concat     False           0                  []         -         -              -\n",
      "   60                model.23.cv1.conv.weight              Conv2d     False       32768    [128, 256, 1, 1] -8.51e-05    0.0548        float32\n",
      "   60                  model.23.cv1.conv.bias              Conv2d     False         128               [128]     -1.82      4.44        float32\n",
      "   61                model.23.cv2.conv.weight              Conv2d     False       32768    [128, 256, 1, 1]  -0.00083    0.0613        float32\n",
      "   61                  model.23.cv2.conv.bias              Conv2d     False         128               [128]     -4.04      4.28        float32\n",
      "   62                model.23.cv3.conv.weight              Conv2d     False       65536    [256, 256, 1, 1] -0.000504    0.0366        float32\n",
      "   62                  model.23.cv3.conv.bias              Conv2d     False         256               [256]     -5.81      4.31        float32\n",
      "   63            model.23.m.0.cv1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]  0.000796    0.0498        float32\n",
      "   63              model.23.m.0.cv1.conv.bias              Conv2d     False         128               [128]     -5.63      4.81        float32\n",
      "   64            model.23.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3]  -7.7e-05     0.014        float32\n",
      "   64              model.23.m.0.cv2.conv.bias              Conv2d     False         128               [128]     -2.85      3.36        float32\n",
      "   65            model.24.cv2.0.0.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000431    0.0143        float32\n",
      "   65              model.24.cv2.0.0.conv.bias              Conv2d     False          64                [64]     -3.71      4.65        float32\n",
      "   66            model.24.cv2.0.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000151   0.00703        float32\n",
      "   66              model.24.cv2.0.1.conv.bias              Conv2d     False          64                [64]     -6.87      4.88        float32\n",
      "   67                 model.24.cv2.0.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   0.00477    0.0831        float32\n",
      "   67                   model.24.cv2.0.2.bias              Conv2d     False          64                [64]      1.73      1.61        float32\n",
      "   68            model.24.cv2.1.0.conv.weight              Conv2d     False       73728     [64, 128, 3, 3] -0.000264    0.0087        float32\n",
      "   68              model.24.cv2.1.0.conv.bias              Conv2d     False          64                [64]     -3.99      5.06        float32\n",
      "   69            model.24.cv2.1.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000352   0.00984        float32\n",
      "   69              model.24.cv2.1.1.conv.bias              Conv2d     False          64                [64]     -5.58      5.64        float32\n",
      "   70                 model.24.cv2.1.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   0.00658     0.131        float32\n",
      "   70                   model.24.cv2.1.2.bias              Conv2d     False          64                [64]     0.908      1.86        float32\n",
      "   71            model.24.cv2.2.0.conv.weight              Conv2d     False      147456     [64, 256, 3, 3] -0.000377    0.0137        float32\n",
      "   71              model.24.cv2.2.0.conv.bias              Conv2d     False          64                [64]     -1.28      4.05        float32\n",
      "   72            model.24.cv2.2.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000923    0.0117        float32\n",
      "   72              model.24.cv2.2.1.conv.bias              Conv2d     False          64                [64]    -0.238      2.36        float32\n",
      "   73                 model.24.cv2.2.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   -0.0287     0.298        float32\n",
      "   73                   model.24.cv2.2.2.bias              Conv2d     False          64                [64]      0.65       2.4        float32\n",
      "   74            model.24.cv3.0.0.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000178    0.0114        float32\n",
      "   74              model.24.cv3.0.0.conv.bias              Conv2d     False          64                [64]     -4.86      5.24        float32\n",
      "   75            model.24.cv3.0.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  6.58e-05   0.00376        float32\n",
      "   75              model.24.cv3.0.1.conv.bias              Conv2d     False          64                [64]     -5.81      4.58        float32\n",
      "   76                 model.24.cv3.0.2.weight              Conv2d     False         576       [9, 64, 1, 1]   -0.0216     0.134        float32\n",
      "   76                   model.24.cv3.0.2.bias              Conv2d     False           9                 [9]      -9.2      2.31        float32\n",
      "   77            model.24.cv3.1.0.conv.weight              Conv2d     False       73728     [64, 128, 3, 3] -5.63e-05   0.00746        float32\n",
      "   77              model.24.cv3.1.0.conv.bias              Conv2d     False          64                [64]     -5.79      4.51        float32\n",
      "   78            model.24.cv3.1.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -4.67e-05   0.00974        float32\n",
      "   78              model.24.cv3.1.1.conv.bias              Conv2d     False          64                [64]      -5.9      4.76        float32\n",
      "   79                 model.24.cv3.1.2.weight              Conv2d     False         576       [9, 64, 1, 1]   -0.0436     0.179        float32\n",
      "   79                   model.24.cv3.1.2.bias              Conv2d     False           9                 [9]     -6.25     0.877        float32\n",
      "   80            model.24.cv3.2.0.conv.weight              Conv2d     False      147456     [64, 256, 3, 3] -0.000101   0.00694        float32\n",
      "   80              model.24.cv3.2.0.conv.bias              Conv2d     False          64                [64]     -5.13      4.59        float32\n",
      "   81            model.24.cv3.2.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -0.00111     0.142        float32\n",
      "   81              model.24.cv3.2.1.conv.bias              Conv2d     False          64                [64]     -2.41      4.37        float32\n",
      "   82                 model.24.cv3.2.2.weight              Conv2d     False         576       [9, 64, 1, 1]    -0.166     0.362        float32\n",
      "   82                   model.24.cv3.2.2.bias              Conv2d     False           9                 [9]     -3.87      1.31        float32\n",
      "   83                model.24.dfl.conv.weight              Conv2d     False          16       [1, 16, 1, 1]       7.5      4.76        float32\n",
      "YOLOv5n summary (fused): 84 layers, 2,504,699 parameters, 0 gradients, 7.1 GFLOPs\n",
      "\n",
      "============================================================\n",
      "üöÄ STARTING EXPERIMENT FOR MODEL: yolov8n (Aug: True)\n",
      "============================================================\n",
      "\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6.2MB 76.4MB/s 0.1s\n",
      "New https://pypi.org/project/ultralytics/8.3.203 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=D:\\Virtual_Fahion\\GraduationThesis2\\data\\data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train_yolov8n_aug_True, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=D:\\Virtual_Fahion\\GraduationThesis2\\saveModels, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov8n_aug_True, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    753067  ultralytics.nn.modules.head.Detect           [9, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,012,603 parameters, 3,012,587 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 214.093.3 MB/s, size: 20.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2\\data\\train\\labels.cache... 64864 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 64864/64864  0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 545.8393.6 MB/s, size: 83.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2\\data\\valid\\labels.cache... 1720 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1720/1720 1.7Mit/s 0.0s\n",
      "Plotting labels to D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov8n_aug_True\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov8n_aug_True\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/30      2.03G      1.237      2.122      1.601         48        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 9.7it/s 6:599<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.8it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.307      0.458      0.237       0.13\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/30      2.26G      1.145      1.899      1.517         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.6it/s 6:22<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.6it/s 7.1s0.1s\n",
      "                   all       1720       1720      0.328      0.467      0.311      0.178\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/30      2.26G      1.105      1.795      1.484         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.1it/s 6:07<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.8it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.354      0.558       0.44      0.285\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/30      2.26G      1.076      1.714      1.462         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:59<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.6it/s 7.1s0.1s\n",
      "                   all       1720       1720      0.422      0.549      0.463      0.305\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/30      2.26G      1.051      1.662      1.444         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:59<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.448      0.574      0.508      0.346\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/30      2.26G      1.032      1.623      1.433         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:58<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.469      0.561      0.537       0.37\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/30      2.26G      1.014       1.59       1.42         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:59<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.7it/s 7.0s0.1s\n",
      "                   all       1720       1720      0.514      0.551      0.567      0.391\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/30      2.28G       1.01      1.558      1.417         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:58<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720       0.55      0.581      0.593      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/30      2.28G      1.004      1.533       1.41         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:58<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.1it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.558      0.582      0.612       0.43\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/30      2.28G     0.9946      1.519      1.404         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:59<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.571      0.591      0.616      0.435\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/30      2.28G     0.9856      1.498      1.399         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:58<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.569      0.604      0.625      0.443\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/30      2.28G     0.9777      1.484      1.393         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:58<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.583      0.589      0.633      0.451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/30      2.28G      0.973      1.466       1.39         43        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:59<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.1it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.587      0.596      0.642      0.458\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/30      2.28G     0.9673      1.445      1.385         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 6:00<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.598      0.599      0.649      0.463\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/30      2.28G     0.9563      1.432      1.377         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:58<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.607      0.605      0.652      0.467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/30      2.28G     0.9545      1.424      1.377         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:59<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.1it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.607      0.609      0.656       0.47\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/30      2.28G     0.9437      1.407       1.37         37        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:58<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.613      0.607      0.658      0.471\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/30      2.28G     0.9382      1.393      1.368         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:58<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.1it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.612      0.613       0.66      0.474\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/30      2.28G     0.9326      1.375      1.362         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:58<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.614      0.615      0.663      0.477\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/30      2.28G     0.9278      1.364      1.357         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:59<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.633      0.597      0.665      0.479\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/30      2.28G     0.9377      1.128      1.528         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.4it/s 5:55<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.649      0.601       0.67      0.484\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/30      2.28G     0.9096      1.082      1.499         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.4it/s 5:56<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.661      0.592      0.676      0.491\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/30      2.28G     0.8916      1.055      1.482         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.4it/s 5:55<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.1it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.669      0.596      0.681      0.496\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/30      2.28G      0.884      1.022      1.473         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.4it/s 5:54<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.674      0.605      0.686      0.501\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/30      2.28G     0.8708     0.9957      1.462         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.4it/s 5:55<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.682        0.6      0.691      0.506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/30      2.28G     0.8552     0.9699      1.445         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.4it/s 5:55<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.693      0.598      0.695      0.511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/30      2.28G     0.8464     0.9406      1.436         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.4it/s 5:55<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.666      0.614      0.699      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/30      2.28G     0.8329     0.9179      1.423         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.4it/s 5:55<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.653      0.622      0.704       0.52\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/30      2.28G     0.8185     0.8882      1.412         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.4it/s 5:55<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.1it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.683       0.62      0.708      0.525\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/30      2.28G     0.8097     0.8641      1.401         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.4it/s 5:55<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.671      0.634      0.712      0.529\n",
      "\n",
      "30 epochs completed in 3.067 hours.\n",
      "Optimizer stripped from D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov8n_aug_True\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov8n_aug_True\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov8n_aug_True\\weights\\best.pt...\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "Model summary (fused): 72 layers, 3,007,403 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 5.7it/s 9.5s0.2s\n",
      "                   all       1720       1720      0.657      0.637      0.712      0.535\n",
      "                 angry        258        258      0.615      0.628      0.714      0.551\n",
      "              contempt         82         82      0.573      0.646      0.673      0.555\n",
      "               disgust        108        108      0.725      0.546      0.721       0.62\n",
      "                  fear        107        107      0.681       0.71      0.721      0.586\n",
      "                 happy        387        387      0.824      0.827      0.901      0.689\n",
      "               natural        172        172      0.547      0.492      0.527      0.366\n",
      "                   sad        312        312      0.625      0.628      0.701       0.48\n",
      "                sleepy         38         38        0.6      0.605      0.668      0.375\n",
      "             surprised        256        256      0.727      0.646      0.778      0.596\n",
      "Speed: 0.1ms preprocess, 1.6ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov8n_aug_True\u001b[0m\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "Model summary (fused): 72 layers, 3,007,403 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 418.292.8 MB/s, size: 36.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2\\data\\valid\\labels.cache... 1720 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1720/1720 860.0Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 108/108 13.6it/s 7.9s0.1s\n",
      "                   all       1720       1720      0.668      0.636      0.712      0.529\n",
      "                 angry        258        258      0.658      0.609      0.715      0.541\n",
      "              contempt         82         82      0.462      0.695      0.649      0.542\n",
      "               disgust        108        108      0.735      0.539      0.716      0.604\n",
      "                  fear        107        107      0.636      0.685      0.707      0.557\n",
      "                 happy        387        387      0.821      0.842      0.906      0.692\n",
      "               natural        172        172      0.519      0.477      0.537      0.372\n",
      "                   sad        312        312      0.648      0.596      0.713      0.485\n",
      "                sleepy         38         38      0.819      0.594      0.679      0.368\n",
      "             surprised        256        256      0.711      0.691       0.79      0.603\n",
      "Speed: 0.2ms preprocess, 1.0ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2\\runs\\detect\\val3\u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "üìà VISUALIZING TRAINING & VALIDATION ANALYSIS FOR: yolov8n (Aug: True)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "üìä EXTRACTING PERFORMANCE INDICATORS FOR: yolov8n (Aug: True)\n",
      "--------------------------------------------------\n",
      "layer                                    name                type  gradient  parameters               shape        mu     sigma\n",
      "    0                     model.0.conv.weight              Conv2d     False         432       [16, 3, 3, 3]   -0.0458      5.18        float32\n",
      "    0                       model.0.conv.bias              Conv2d     False          16                [16]      1.47      6.68        float32\n",
      "    1                             model.0.act                SiLU     False           0                  []         -         -              -\n",
      "    2                     model.1.conv.weight              Conv2d     False        4608      [32, 16, 3, 3]  0.000437     0.236        float32\n",
      "    2                       model.1.conv.bias              Conv2d     False          32                [32]     -1.32      6.71        float32\n",
      "    3                 model.2.cv1.conv.weight              Conv2d     False        1024      [32, 32, 1, 1]   -0.0179      0.11        float32\n",
      "    3                   model.2.cv1.conv.bias              Conv2d     False          32                [32]      1.97      2.65        float32\n",
      "    4                 model.2.cv2.conv.weight              Conv2d     False        1536      [32, 48, 1, 1]   -0.0122     0.111        float32\n",
      "    4                   model.2.cv2.conv.bias              Conv2d     False          32                [32]     0.204      5.23        float32\n",
      "    5             model.2.m.0.cv1.conv.weight              Conv2d     False        2304      [16, 16, 3, 3]  -0.00393     0.152        float32\n",
      "    5               model.2.m.0.cv1.conv.bias              Conv2d     False          16                [16]     0.652      6.09        float32\n",
      "    6             model.2.m.0.cv2.conv.weight              Conv2d     False        2304      [16, 16, 3, 3]   -0.0065    0.0986        float32\n",
      "    6               model.2.m.0.cv2.conv.bias              Conv2d     False          16                [16]      2.26      5.27        float32\n",
      "    7                     model.3.conv.weight              Conv2d     False       18432      [64, 32, 3, 3] -0.000775    0.0336        float32\n",
      "    7                       model.3.conv.bias              Conv2d     False          64                [64]    -0.247      3.36        float32\n",
      "    8                 model.4.cv1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]   -0.0015     0.158        float32\n",
      "    8                   model.4.cv1.conv.bias              Conv2d     False          64                [64]     0.178      4.92        float32\n",
      "    9                 model.4.cv2.conv.weight              Conv2d     False        8192     [64, 128, 1, 1]  -0.00142    0.0548        float32\n",
      "    9                   model.4.cv2.conv.bias              Conv2d     False          64                [64]     -1.82      4.66        float32\n",
      "   10             model.4.m.0.cv1.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00239    0.0648        float32\n",
      "   10               model.4.m.0.cv1.conv.bias              Conv2d     False          32                [32]     -2.69       4.9        float32\n",
      "   11             model.4.m.0.cv2.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00114    0.0403        float32\n",
      "   11               model.4.m.0.cv2.conv.bias              Conv2d     False          32                [32]     -0.44      2.72        float32\n",
      "   12             model.4.m.1.cv1.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00141     0.029        float32\n",
      "   12               model.4.m.1.cv1.conv.bias              Conv2d     False          32                [32]     -2.86       3.6        float32\n",
      "   13             model.4.m.1.cv2.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00593     0.116        float32\n",
      "   13               model.4.m.1.cv2.conv.bias              Conv2d     False          32                [32]     0.135      4.02        float32\n",
      "   14                     model.5.conv.weight              Conv2d     False       73728     [128, 64, 3, 3]  3.68e-05    0.0171        float32\n",
      "   14                       model.5.conv.bias              Conv2d     False         128               [128]    -0.839      3.62        float32\n",
      "   15                 model.6.cv1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]  0.000465    0.0738        float32\n",
      "   15                   model.6.cv1.conv.bias              Conv2d     False         128               [128]     -1.79      4.81        float32\n",
      "   16                 model.6.cv2.conv.weight              Conv2d     False       32768    [128, 256, 1, 1] -0.000928    0.0244        float32\n",
      "   16                   model.6.cv2.conv.bias              Conv2d     False         128               [128]     -4.68      4.88        float32\n",
      "   17             model.6.m.0.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -0.00121    0.0373        float32\n",
      "   17               model.6.m.0.cv1.conv.bias              Conv2d     False          64                [64]     -3.91      4.33        float32\n",
      "   18             model.6.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]   -0.0021    0.0317        float32\n",
      "   18               model.6.m.0.cv2.conv.bias              Conv2d     False          64                [64]     -2.43       3.9        float32\n",
      "   19             model.6.m.1.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -0.00153    0.0239        float32\n",
      "   19               model.6.m.1.cv1.conv.bias              Conv2d     False          64                [64]     -4.63       4.7        float32\n",
      "   20             model.6.m.1.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -0.00405     0.103        float32\n",
      "   20               model.6.m.1.cv2.conv.bias              Conv2d     False          64                [64]    -0.842       3.2        float32\n",
      "   21                     model.7.conv.weight              Conv2d     False      294912    [256, 128, 3, 3] -3.38e-05   0.00806        float32\n",
      "   21                       model.7.conv.bias              Conv2d     False         256               [256]     -3.28      4.15        float32\n",
      "   22                 model.8.cv1.conv.weight              Conv2d     False       65536    [256, 256, 1, 1] -0.000151    0.0233        float32\n",
      "   22                   model.8.cv1.conv.bias              Conv2d     False         256               [256]     -5.61      4.94        float32\n",
      "   23                 model.8.cv2.conv.weight              Conv2d     False       98304    [256, 384, 1, 1] -0.000256    0.0237        float32\n",
      "   23                   model.8.cv2.conv.bias              Conv2d     False         256               [256]     -3.55      3.92        float32\n",
      "   24             model.8.m.0.cv1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -0.000238    0.0264        float32\n",
      "   24               model.8.m.0.cv1.conv.bias              Conv2d     False         128               [128]     -6.38      4.71        float32\n",
      "   25             model.8.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -0.000492    0.0193        float32\n",
      "   25               model.8.m.0.cv2.conv.bias              Conv2d     False         128               [128]      -3.4      5.27        float32\n",
      "   26                 model.9.cv1.conv.weight              Conv2d     False       32768    [128, 256, 1, 1]    -0.003    0.0404        float32\n",
      "   26                   model.9.cv1.conv.bias              Conv2d     False         128               [128]      3.54      6.98        float32\n",
      "   27                 model.9.cv2.conv.weight              Conv2d     False      131072    [256, 512, 1, 1] -2.31e-05    0.0176        float32\n",
      "   27                   model.9.cv2.conv.bias              Conv2d     False         256               [256]     -4.23      6.91        float32\n",
      "   28                               model.9.m           MaxPool2d     False           0                  []         -         -              -\n",
      "   29                                model.10            Upsample     False           0                  []         -         -              -\n",
      "   30                                model.11              Concat     False           0                  []         -         -              -\n",
      "   31                model.12.cv1.conv.weight              Conv2d     False       49152    [128, 384, 1, 1]   -0.0021    0.0672        float32\n",
      "   31                  model.12.cv1.conv.bias              Conv2d     False         128               [128]     -3.19      4.42        float32\n",
      "   32                model.12.cv2.conv.weight              Conv2d     False       24576    [128, 192, 1, 1]  -0.00136    0.0565        float32\n",
      "   32                  model.12.cv2.conv.bias              Conv2d     False         128               [128]     -2.09      4.56        float32\n",
      "   33            model.12.m.0.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000149    0.0243        float32\n",
      "   33              model.12.m.0.cv1.conv.bias              Conv2d     False          64                [64]     -6.35      4.25        float32\n",
      "   34            model.12.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -8.03e-05    0.0153        float32\n",
      "   34              model.12.m.0.cv2.conv.bias              Conv2d     False          64                [64]     -1.76      4.13        float32\n",
      "   35                                model.13            Upsample     False           0                  []         -         -              -\n",
      "   36                                model.14              Concat     False           0                  []         -         -              -\n",
      "   37                model.15.cv1.conv.weight              Conv2d     False       12288     [64, 192, 1, 1] -0.000941    0.0444        float32\n",
      "   37                  model.15.cv1.conv.bias              Conv2d     False          64                [64]     -1.17      5.16        float32\n",
      "   38                model.15.cv2.conv.weight              Conv2d     False        6144      [64, 96, 1, 1]  0.000885    0.0582        float32\n",
      "   38                  model.15.cv2.conv.bias              Conv2d     False          64                [64]      -3.3      4.55        float32\n",
      "   39            model.15.m.0.cv1.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]   0.00038    0.0507        float32\n",
      "   39              model.15.m.0.cv1.conv.bias              Conv2d     False          32                [32]     -4.37      4.79        float32\n",
      "   40            model.15.m.0.cv2.conv.weight              Conv2d     False        9216      [32, 32, 3, 3] -0.000291    0.0314        float32\n",
      "   40              model.15.m.0.cv2.conv.bias              Conv2d     False          32                [32]     0.285      4.02        float32\n",
      "   41                    model.16.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  0.000202   0.00948        float32\n",
      "   41                      model.16.conv.bias              Conv2d     False          64                [64]     -1.73      3.16        float32\n",
      "   42                                model.17              Concat     False           0                  []         -         -              -\n",
      "   43                model.18.cv1.conv.weight              Conv2d     False       24576    [128, 192, 1, 1]  3.38e-05    0.0547        float32\n",
      "   43                  model.18.cv1.conv.bias              Conv2d     False         128               [128]     -3.79      4.65        float32\n",
      "   44                model.18.cv2.conv.weight              Conv2d     False       24576    [128, 192, 1, 1]  4.03e-05    0.0258        float32\n",
      "   44                  model.18.cv2.conv.bias              Conv2d     False         128               [128]     -4.34      4.38        float32\n",
      "   45            model.18.m.0.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000393    0.0189        float32\n",
      "   45              model.18.m.0.cv1.conv.bias              Conv2d     False          64                [64]     -4.96       4.3        float32\n",
      "   46            model.18.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  0.000186     0.034        float32\n",
      "   46              model.18.m.0.cv2.conv.bias              Conv2d     False          64                [64]     -1.21      3.33        float32\n",
      "   47                    model.19.conv.weight              Conv2d     False      147456    [128, 128, 3, 3]  3.29e-05   0.00464        float32\n",
      "   47                      model.19.conv.bias              Conv2d     False         128               [128]     -3.64      3.05        float32\n",
      "   48                                model.20              Concat     False           0                  []         -         -              -\n",
      "   49                model.21.cv1.conv.weight              Conv2d     False       98304    [256, 384, 1, 1]  -0.00123    0.0615        float32\n",
      "   49                  model.21.cv1.conv.bias              Conv2d     False         256               [256]     -5.36      4.43        float32\n",
      "   50                model.21.cv2.conv.weight              Conv2d     False       98304    [256, 384, 1, 1] -0.000575    0.0272        float32\n",
      "   50                  model.21.cv2.conv.bias              Conv2d     False         256               [256]     -6.16      4.19        float32\n",
      "   51            model.21.m.0.cv1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -0.000199    0.0176        float32\n",
      "   51              model.21.m.0.cv1.conv.bias              Conv2d     False         128               [128]     -5.73      4.08        float32\n",
      "   52            model.21.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -0.000167    0.0172        float32\n",
      "   52              model.21.m.0.cv2.conv.bias              Conv2d     False         128               [128]     -2.45      3.17        float32\n",
      "   53            model.22.cv2.0.0.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000381     0.012        float32\n",
      "   53              model.22.cv2.0.0.conv.bias              Conv2d     False          64                [64]     -2.86      5.63        float32\n",
      "   54            model.22.cv2.0.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000284   0.00764        float32\n",
      "   54              model.22.cv2.0.1.conv.bias              Conv2d     False          64                [64]     -6.77       5.2        float32\n",
      "   55                 model.22.cv2.0.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   0.00469    0.0758        float32\n",
      "   55                   model.22.cv2.0.2.bias              Conv2d     False          64                [64]      2.06      1.68        float32\n",
      "   56            model.22.cv2.1.0.conv.weight              Conv2d     False       73728     [64, 128, 3, 3] -0.000383   0.00903        float32\n",
      "   56              model.22.cv2.1.0.conv.bias              Conv2d     False          64                [64]     -3.47      5.74        float32\n",
      "   57            model.22.cv2.1.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000136   0.00908        float32\n",
      "   57              model.22.cv2.1.1.conv.bias              Conv2d     False          64                [64]     -5.38      5.57        float32\n",
      "   58                 model.22.cv2.1.2.weight              Conv2d     False        4096      [64, 64, 1, 1]     0.006     0.125        float32\n",
      "   58                   model.22.cv2.1.2.bias              Conv2d     False          64                [64]      1.04      2.11        float32\n",
      "   59            model.22.cv2.2.0.conv.weight              Conv2d     False      147456     [64, 256, 3, 3] -0.000285    0.0149        float32\n",
      "   59              model.22.cv2.2.0.conv.bias              Conv2d     False          64                [64]     -1.65      4.15        float32\n",
      "   60            model.22.cv2.2.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000698    0.0107        float32\n",
      "   60              model.22.cv2.2.1.conv.bias              Conv2d     False          64                [64]   -0.0155      1.54        float32\n",
      "   61                 model.22.cv2.2.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   -0.0279     0.292        float32\n",
      "   61                   model.22.cv2.2.2.bias              Conv2d     False          64                [64]     0.768      2.34        float32\n",
      "   62            model.22.cv3.0.0.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]   5.3e-05    0.0134        float32\n",
      "   62              model.22.cv3.0.0.conv.bias              Conv2d     False          64                [64]     -4.71      5.23        float32\n",
      "   63            model.22.cv3.0.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000102   0.00226        float32\n",
      "   63              model.22.cv3.0.1.conv.bias              Conv2d     False          64                [64]     -4.52       5.8        float32\n",
      "   64                 model.22.cv3.0.2.weight              Conv2d     False         576       [9, 64, 1, 1]   -0.0245     0.111        float32\n",
      "   64                   model.22.cv3.0.2.bias              Conv2d     False           9                 [9]     -10.2      3.67        float32\n",
      "   65            model.22.cv3.1.0.conv.weight              Conv2d     False       73728     [64, 128, 3, 3] -1.22e-05   0.00722        float32\n",
      "   65              model.22.cv3.1.0.conv.bias              Conv2d     False          64                [64]     -5.59      4.82        float32\n",
      "   66            model.22.cv3.1.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  2.91e-06    0.0076        float32\n",
      "   66              model.22.cv3.1.1.conv.bias              Conv2d     False          64                [64]     -4.98      4.78        float32\n",
      "   67                 model.22.cv3.1.2.weight              Conv2d     False         576       [9, 64, 1, 1]    -0.047     0.171        float32\n",
      "   67                   model.22.cv3.1.2.bias              Conv2d     False           9                 [9]     -6.37      1.37        float32\n",
      "   68            model.22.cv3.2.0.conv.weight              Conv2d     False      147456     [64, 256, 3, 3] -8.81e-05   0.00835        float32\n",
      "   68              model.22.cv3.2.0.conv.bias              Conv2d     False          64                [64]     -4.66      4.56        float32\n",
      "   69            model.22.cv3.2.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -0.00033     0.138        float32\n",
      "   69              model.22.cv3.2.1.conv.bias              Conv2d     False          64                [64]     -2.72      5.73        float32\n",
      "   70                 model.22.cv3.2.2.weight              Conv2d     False         576       [9, 64, 1, 1]     -0.18     0.356        float32\n",
      "   70                   model.22.cv3.2.2.bias              Conv2d     False           9                 [9]      -3.9      1.21        float32\n",
      "   71                model.22.dfl.conv.weight              Conv2d     False          16       [1, 16, 1, 1]       7.5      4.76        float32\n",
      "Model summary (fused): 72 layers, 3,007,403 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "============================================================\n",
      "üöÄ STARTING EXPERIMENT FOR MODEL: yolov8n (Aug: False)\n",
      "============================================================\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.203 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=D:\\Virtual_Fahion\\GraduationThesis2\\data\\data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train_yolov8n_aug_False, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=D:\\Virtual_Fahion\\GraduationThesis2\\saveModels, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov8n_aug_False, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    753067  ultralytics.nn.modules.head.Detect           [9, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,012,603 parameters, 3,012,587 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 214.181.8 MB/s, size: 20.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2\\data\\train\\labels.cache... 64864 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 64864/64864 64.9Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 660.0519.0 MB/s, size: 83.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2\\data\\valid\\labels.cache... 1720 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1720/1720 1.7Mit/s 0.0s\n",
      "Plotting labels to D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov8n_aug_False\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov8n_aug_False\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/30      2.04G      1.237      2.122      1.601         48        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 9.9it/s 6:511<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.307      0.458      0.237       0.13\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/30      2.15G      1.145      1.899      1.517         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.7it/s 6:20<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.2it/s 6.6s0.1s\n",
      "                   all       1720       1720      0.328      0.467      0.311      0.178\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/30      2.15G      1.105      1.795      1.484         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.1it/s 6:06<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.354      0.558       0.44      0.285\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/30      2.15G      1.076      1.714      1.462         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:58<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.1it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.422      0.549      0.463      0.305\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/30      2.15G      1.051      1.662      1.444         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:58<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.448      0.574      0.508      0.346\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/30      2.15G      1.032      1.623      1.433         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:59<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.469      0.561      0.537       0.37\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/30      2.15G      1.014       1.59       1.42         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:58<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.514      0.551      0.567      0.391\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/30      2.15G       1.01      1.558      1.417         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:58<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720       0.55      0.581      0.593      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/30      2.15G      1.004      1.533       1.41         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:58<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.1it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.558      0.582      0.612       0.43\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/30      2.15G     0.9946      1.519      1.404         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:58<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.1it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.571      0.591      0.616      0.435\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/30      2.15G     0.9856      1.498      1.399         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:58<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.1it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.569      0.604      0.625      0.443\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/30      2.15G     0.9777      1.484      1.393         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:58<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.1it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.583      0.589      0.633      0.451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/30      2.15G      0.973      1.466       1.39         43        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:58<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.587      0.596      0.642      0.458\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/30      2.15G     0.9673      1.445      1.385         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:58<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.598      0.599      0.649      0.463\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/30      2.17G     0.9563      1.432      1.377         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.4it/s 5:57<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.1it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.607      0.605      0.652      0.467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/30      2.17G     0.9539      1.423      1.377         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.3it/s 5:57<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.1it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.609      0.608      0.657      0.471\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/30      2.17G     0.9437      1.406      1.369         37        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.4it/s 5:57<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.612      0.609      0.659      0.472\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/30      2.17G     0.9359      1.394      1.365         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.4it/s 5:57<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.1it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.614      0.612      0.662      0.475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/30      2.17G       0.93      1.375       1.36         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.4it/s 5:56<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.619      0.608      0.663      0.478\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/30      2.17G     0.9243      1.364      1.355         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.4it/s 5:57<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.627      0.605      0.665      0.479\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/30      2.17G     0.9348      1.127      1.525         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.4it/s 5:54<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.649      0.598      0.668      0.482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/30      2.17G     0.9093      1.081      1.499         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.4it/s 5:54<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.644      0.603      0.673      0.488\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/30      2.17G     0.8919      1.052      1.483         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.5it/s 5:54<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.652        0.6      0.678      0.494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/30      2.17G     0.8861      1.021      1.475         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.5it/s 5:54<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.653        0.6      0.683        0.5\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/30      2.17G     0.8687     0.9982      1.461         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.4it/s 5:55<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.1it/s 6.6s0.1s\n",
      "                   all       1720       1720      0.664      0.602      0.688      0.506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/30      2.17G      0.851     0.9716      1.442         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.4it/s 5:55<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.2it/s 6.6s0.1s\n",
      "                   all       1720       1720      0.675      0.598      0.693      0.509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/30      2.17G     0.8432     0.9427      1.434         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.4it/s 5:55<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.8it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.666      0.609      0.697      0.514\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/30      2.17G     0.8329     0.9183      1.424         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.5it/s 5:54<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.669      0.607      0.701      0.517\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/30      2.17G     0.8171     0.8904      1.411         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.4it/s 5:54<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.675      0.608      0.705      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/30      2.17G      0.806     0.8664      1.399         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.5it/s 5:54<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.1it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.677       0.62      0.709      0.525\n",
      "\n",
      "30 epochs completed in 3.058 hours.\n",
      "Optimizer stripped from D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov8n_aug_False\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov8n_aug_False\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov8n_aug_False\\weights\\best.pt...\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "Model summary (fused): 72 layers, 3,007,403 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 6.7it/s 8.1s0.1s\n",
      "                   all       1720       1720      0.677       0.62      0.709      0.525\n",
      "                 angry        258        258      0.679      0.624      0.722       0.54\n",
      "              contempt         82         82      0.508      0.718      0.643      0.531\n",
      "               disgust        108        108      0.745      0.528      0.701       0.59\n",
      "                  fear        107        107      0.648      0.673       0.71      0.559\n",
      "                 happy        387        387      0.821      0.832      0.904       0.69\n",
      "               natural        172        172      0.553      0.448      0.549      0.376\n",
      "                   sad        312        312      0.661      0.568      0.705      0.484\n",
      "                sleepy         38         38      0.746      0.542      0.661      0.356\n",
      "             surprised        256        256      0.731      0.648      0.784      0.597\n",
      "Speed: 0.1ms preprocess, 0.7ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov8n_aug_False\u001b[0m\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "Model summary (fused): 72 layers, 3,007,403 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 442.897.8 MB/s, size: 36.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2\\data\\valid\\labels.cache... 1720 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1720/1720 1.7Mit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 108/108 13.3it/s 8.1s0.1s\n",
      "                   all       1720       1720      0.677      0.619      0.709      0.525\n",
      "                 angry        258        258       0.68      0.628      0.722      0.542\n",
      "              contempt         82         82      0.507      0.715      0.643      0.532\n",
      "               disgust        108        108      0.745      0.528      0.702       0.59\n",
      "                  fear        107        107      0.648      0.673       0.71      0.559\n",
      "                 happy        387        387      0.822      0.834      0.903      0.689\n",
      "               natural        172        172      0.553      0.448       0.55      0.377\n",
      "                   sad        312        312      0.655       0.56      0.705      0.483\n",
      "                sleepy         38         38      0.746      0.541      0.661      0.355\n",
      "             surprised        256        256      0.739      0.645      0.784      0.597\n",
      "Speed: 0.2ms preprocess, 0.9ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2\\runs\\detect\\val4\u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "üìà VISUALIZING TRAINING & VALIDATION ANALYSIS FOR: yolov8n (Aug: False)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "üìä EXTRACTING PERFORMANCE INDICATORS FOR: yolov8n (Aug: False)\n",
      "--------------------------------------------------\n",
      "layer                                    name                type  gradient  parameters               shape        mu     sigma\n",
      "    0                     model.0.conv.weight              Conv2d     False         432       [16, 3, 3, 3]   -0.0446      5.18        float32\n",
      "    0                       model.0.conv.bias              Conv2d     False          16                [16]      1.42      6.68        float32\n",
      "    1                             model.0.act                SiLU     False           0                  []         -         -              -\n",
      "    2                     model.1.conv.weight              Conv2d     False        4608      [32, 16, 3, 3]  0.000422     0.242        float32\n",
      "    2                       model.1.conv.bias              Conv2d     False          32                [32]     -1.03      5.94        float32\n",
      "    3                 model.2.cv1.conv.weight              Conv2d     False        1024      [32, 32, 1, 1]   -0.0172     0.108        float32\n",
      "    3                   model.2.cv1.conv.bias              Conv2d     False          32                [32]      1.99      2.56        float32\n",
      "    4                 model.2.cv2.conv.weight              Conv2d     False        1536      [32, 48, 1, 1]   -0.0125     0.111        float32\n",
      "    4                   model.2.cv2.conv.bias              Conv2d     False          32                [32]     0.318      5.28        float32\n",
      "    5             model.2.m.0.cv1.conv.weight              Conv2d     False        2304      [16, 16, 3, 3]   -0.0034     0.153        float32\n",
      "    5               model.2.m.0.cv1.conv.bias              Conv2d     False          16                [16]      0.65       6.2        float32\n",
      "    6             model.2.m.0.cv2.conv.weight              Conv2d     False        2304      [16, 16, 3, 3]  -0.00611    0.0975        float32\n",
      "    6               model.2.m.0.cv2.conv.bias              Conv2d     False          16                [16]      2.13      5.26        float32\n",
      "    7                     model.3.conv.weight              Conv2d     False       18432      [64, 32, 3, 3] -0.000546    0.0337        float32\n",
      "    7                       model.3.conv.bias              Conv2d     False          64                [64]    -0.326      3.37        float32\n",
      "    8                 model.4.cv1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  -0.00189     0.159        float32\n",
      "    8                   model.4.cv1.conv.bias              Conv2d     False          64                [64]     0.151      4.93        float32\n",
      "    9                 model.4.cv2.conv.weight              Conv2d     False        8192     [64, 128, 1, 1]  -0.00136    0.0549        float32\n",
      "    9                   model.4.cv2.conv.bias              Conv2d     False          64                [64]      -1.8      4.63        float32\n",
      "   10             model.4.m.0.cv1.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00233    0.0649        float32\n",
      "   10               model.4.m.0.cv1.conv.bias              Conv2d     False          32                [32]     -2.71      5.04        float32\n",
      "   11             model.4.m.0.cv2.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00134    0.0407        float32\n",
      "   11               model.4.m.0.cv2.conv.bias              Conv2d     False          32                [32]    -0.334      2.68        float32\n",
      "   12             model.4.m.1.cv1.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00127    0.0288        float32\n",
      "   12               model.4.m.1.cv1.conv.bias              Conv2d     False          32                [32]     -2.98      3.58        float32\n",
      "   13             model.4.m.1.cv2.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00517     0.117        float32\n",
      "   13               model.4.m.1.cv2.conv.bias              Conv2d     False          32                [32]     0.116      4.11        float32\n",
      "   14                     model.5.conv.weight              Conv2d     False       73728     [128, 64, 3, 3]   4.7e-05     0.017        float32\n",
      "   14                       model.5.conv.bias              Conv2d     False         128               [128]    -0.829      3.61        float32\n",
      "   15                 model.6.cv1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]  0.000467    0.0738        float32\n",
      "   15                   model.6.cv1.conv.bias              Conv2d     False         128               [128]     -1.79      4.83        float32\n",
      "   16                 model.6.cv2.conv.weight              Conv2d     False       32768    [128, 256, 1, 1] -0.000824    0.0243        float32\n",
      "   16                   model.6.cv2.conv.bias              Conv2d     False         128               [128]     -4.76       4.8        float32\n",
      "   17             model.6.m.0.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -0.00123    0.0373        float32\n",
      "   17               model.6.m.0.cv1.conv.bias              Conv2d     False          64                [64]     -3.85       4.4        float32\n",
      "   18             model.6.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -0.00214    0.0323        float32\n",
      "   18               model.6.m.0.cv2.conv.bias              Conv2d     False          64                [64]     -2.43      3.88        float32\n",
      "   19             model.6.m.1.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -0.00148    0.0241        float32\n",
      "   19               model.6.m.1.cv1.conv.bias              Conv2d     False          64                [64]     -4.63      4.58        float32\n",
      "   20             model.6.m.1.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -0.00383     0.103        float32\n",
      "   20               model.6.m.1.cv2.conv.bias              Conv2d     False          64                [64]    -0.811      3.21        float32\n",
      "   21                     model.7.conv.weight              Conv2d     False      294912    [256, 128, 3, 3] -3.99e-05   0.00809        float32\n",
      "   21                       model.7.conv.bias              Conv2d     False         256               [256]     -3.27      4.18        float32\n",
      "   22                 model.8.cv1.conv.weight              Conv2d     False       65536    [256, 256, 1, 1] -0.000166    0.0234        float32\n",
      "   22                   model.8.cv1.conv.bias              Conv2d     False         256               [256]     -5.61      4.94        float32\n",
      "   23                 model.8.cv2.conv.weight              Conv2d     False       98304    [256, 384, 1, 1] -0.000274    0.0239        float32\n",
      "   23                   model.8.cv2.conv.bias              Conv2d     False         256               [256]     -3.54      3.93        float32\n",
      "   24             model.8.m.0.cv1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -0.000251    0.0266        float32\n",
      "   24               model.8.m.0.cv1.conv.bias              Conv2d     False         128               [128]     -6.39      4.73        float32\n",
      "   25             model.8.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -0.000498    0.0189        float32\n",
      "   25               model.8.m.0.cv2.conv.bias              Conv2d     False         128               [128]     -3.42      5.24        float32\n",
      "   26                 model.9.cv1.conv.weight              Conv2d     False       32768    [128, 256, 1, 1]   -0.0029    0.0402        float32\n",
      "   26                   model.9.cv1.conv.bias              Conv2d     False         128               [128]      3.54      6.99        float32\n",
      "   27                 model.9.cv2.conv.weight              Conv2d     False      131072    [256, 512, 1, 1] -3.36e-05    0.0175        float32\n",
      "   27                   model.9.cv2.conv.bias              Conv2d     False         256               [256]      -4.2      6.81        float32\n",
      "   28                               model.9.m           MaxPool2d     False           0                  []         -         -              -\n",
      "   29                                model.10            Upsample     False           0                  []         -         -              -\n",
      "   30                                model.11              Concat     False           0                  []         -         -              -\n",
      "   31                model.12.cv1.conv.weight              Conv2d     False       49152    [128, 384, 1, 1]    -0.002    0.0669        float32\n",
      "   31                  model.12.cv1.conv.bias              Conv2d     False         128               [128]     -3.26      4.39        float32\n",
      "   32                model.12.cv2.conv.weight              Conv2d     False       24576    [128, 192, 1, 1]  -0.00137    0.0567        float32\n",
      "   32                  model.12.cv2.conv.bias              Conv2d     False         128               [128]     -2.12      4.55        float32\n",
      "   33            model.12.m.0.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000168    0.0245        float32\n",
      "   33              model.12.m.0.cv1.conv.bias              Conv2d     False          64                [64]     -6.32      4.27        float32\n",
      "   34            model.12.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000118    0.0155        float32\n",
      "   34              model.12.m.0.cv2.conv.bias              Conv2d     False          64                [64]     -1.76      4.14        float32\n",
      "   35                                model.13            Upsample     False           0                  []         -         -              -\n",
      "   36                                model.14              Concat     False           0                  []         -         -              -\n",
      "   37                model.15.cv1.conv.weight              Conv2d     False       12288     [64, 192, 1, 1]   -0.0009     0.044        float32\n",
      "   37                  model.15.cv1.conv.bias              Conv2d     False          64                [64]     -1.14      5.12        float32\n",
      "   38                model.15.cv2.conv.weight              Conv2d     False        6144      [64, 96, 1, 1]  0.000943    0.0588        float32\n",
      "   38                  model.15.cv2.conv.bias              Conv2d     False          64                [64]     -3.29      4.55        float32\n",
      "   39            model.15.m.0.cv1.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]   0.00045    0.0518        float32\n",
      "   39              model.15.m.0.cv1.conv.bias              Conv2d     False          32                [32]     -4.38      4.72        float32\n",
      "   40            model.15.m.0.cv2.conv.weight              Conv2d     False        9216      [32, 32, 3, 3] -0.000324    0.0315        float32\n",
      "   40              model.15.m.0.cv2.conv.bias              Conv2d     False          32                [32]     0.274      4.08        float32\n",
      "   41                    model.16.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  0.000203   0.00946        float32\n",
      "   41                      model.16.conv.bias              Conv2d     False          64                [64]     -1.71      3.21        float32\n",
      "   42                                model.17              Concat     False           0                  []         -         -              -\n",
      "   43                model.18.cv1.conv.weight              Conv2d     False       24576    [128, 192, 1, 1] -9.89e-05    0.0552        float32\n",
      "   43                  model.18.cv1.conv.bias              Conv2d     False         128               [128]     -3.72      4.71        float32\n",
      "   44                model.18.cv2.conv.weight              Conv2d     False       24576    [128, 192, 1, 1]  6.69e-05    0.0257        float32\n",
      "   44                  model.18.cv2.conv.bias              Conv2d     False         128               [128]     -4.34      4.36        float32\n",
      "   45            model.18.m.0.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000367    0.0192        float32\n",
      "   45              model.18.m.0.cv1.conv.bias              Conv2d     False          64                [64]     -4.99      4.25        float32\n",
      "   46            model.18.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  0.000213    0.0343        float32\n",
      "   46              model.18.m.0.cv2.conv.bias              Conv2d     False          64                [64]     -1.22      3.33        float32\n",
      "   47                    model.19.conv.weight              Conv2d     False      147456    [128, 128, 3, 3]  4.48e-05   0.00463        float32\n",
      "   47                      model.19.conv.bias              Conv2d     False         128               [128]     -3.64      3.05        float32\n",
      "   48                                model.20              Concat     False           0                  []         -         -              -\n",
      "   49                model.21.cv1.conv.weight              Conv2d     False       98304    [256, 384, 1, 1]  -0.00131    0.0613        float32\n",
      "   49                  model.21.cv1.conv.bias              Conv2d     False         256               [256]     -5.31      4.47        float32\n",
      "   50                model.21.cv2.conv.weight              Conv2d     False       98304    [256, 384, 1, 1] -0.000561    0.0271        float32\n",
      "   50                  model.21.cv2.conv.bias              Conv2d     False         256               [256]     -6.18      4.19        float32\n",
      "   51            model.21.m.0.cv1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -0.000191    0.0176        float32\n",
      "   51              model.21.m.0.cv1.conv.bias              Conv2d     False         128               [128]     -5.72      4.03        float32\n",
      "   52            model.21.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -0.000174    0.0173        float32\n",
      "   52              model.21.m.0.cv2.conv.bias              Conv2d     False         128               [128]     -2.42      3.19        float32\n",
      "   53            model.22.cv2.0.0.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000389     0.012        float32\n",
      "   53              model.22.cv2.0.0.conv.bias              Conv2d     False          64                [64]      -2.9      5.65        float32\n",
      "   54            model.22.cv2.0.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000334   0.00756        float32\n",
      "   54              model.22.cv2.0.1.conv.bias              Conv2d     False          64                [64]     -6.61      5.25        float32\n",
      "   55                 model.22.cv2.0.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   0.00452    0.0761        float32\n",
      "   55                   model.22.cv2.0.2.bias              Conv2d     False          64                [64]      2.07      1.67        float32\n",
      "   56            model.22.cv2.1.0.conv.weight              Conv2d     False       73728     [64, 128, 3, 3] -0.000388   0.00905        float32\n",
      "   56              model.22.cv2.1.0.conv.bias              Conv2d     False          64                [64]      -3.5      5.75        float32\n",
      "   57            model.22.cv2.1.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000148   0.00904        float32\n",
      "   57              model.22.cv2.1.1.conv.bias              Conv2d     False          64                [64]     -5.35      5.57        float32\n",
      "   58                 model.22.cv2.1.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   0.00592     0.125        float32\n",
      "   58                   model.22.cv2.1.2.bias              Conv2d     False          64                [64]      1.03      2.12        float32\n",
      "   59            model.22.cv2.2.0.conv.weight              Conv2d     False      147456     [64, 256, 3, 3]  -0.00029    0.0148        float32\n",
      "   59              model.22.cv2.2.0.conv.bias              Conv2d     False          64                [64]     -1.62      4.16        float32\n",
      "   60            model.22.cv2.2.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000696    0.0106        float32\n",
      "   60              model.22.cv2.2.1.conv.bias              Conv2d     False          64                [64] -0.000483      1.47        float32\n",
      "   61                 model.22.cv2.2.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   -0.0279     0.293        float32\n",
      "   61                   model.22.cv2.2.2.bias              Conv2d     False          64                [64]     0.758      2.35        float32\n",
      "   62            model.22.cv3.0.0.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  7.28e-05    0.0133        float32\n",
      "   62              model.22.cv3.0.0.conv.bias              Conv2d     False          64                [64]     -4.72      5.41        float32\n",
      "   63            model.22.cv3.0.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000109   0.00225        float32\n",
      "   63              model.22.cv3.0.1.conv.bias              Conv2d     False          64                [64]     -4.51      5.79        float32\n",
      "   64                 model.22.cv3.0.2.weight              Conv2d     False         576       [9, 64, 1, 1]   -0.0236     0.111        float32\n",
      "   64                   model.22.cv3.0.2.bias              Conv2d     False           9                 [9]     -10.2      3.61        float32\n",
      "   65            model.22.cv3.1.0.conv.weight              Conv2d     False       73728     [64, 128, 3, 3] -2.15e-05   0.00733        float32\n",
      "   65              model.22.cv3.1.0.conv.bias              Conv2d     False          64                [64]     -5.65      4.86        float32\n",
      "   66            model.22.cv3.1.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -4.22e-05   0.00768        float32\n",
      "   66              model.22.cv3.1.1.conv.bias              Conv2d     False          64                [64]     -4.89      4.84        float32\n",
      "   67                 model.22.cv3.1.2.weight              Conv2d     False         576       [9, 64, 1, 1]   -0.0464     0.172        float32\n",
      "   67                   model.22.cv3.1.2.bias              Conv2d     False           9                 [9]     -6.38      1.39        float32\n",
      "   68            model.22.cv3.2.0.conv.weight              Conv2d     False      147456     [64, 256, 3, 3] -8.41e-05   0.00836        float32\n",
      "   68              model.22.cv3.2.0.conv.bias              Conv2d     False          64                [64]     -4.69      4.56        float32\n",
      "   69            model.22.cv3.2.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000434     0.138        float32\n",
      "   69              model.22.cv3.2.1.conv.bias              Conv2d     False          64                [64]     -2.83       5.7        float32\n",
      "   70                 model.22.cv3.2.2.weight              Conv2d     False         576       [9, 64, 1, 1]    -0.177     0.358        float32\n",
      "   70                   model.22.cv3.2.2.bias              Conv2d     False           9                 [9]     -3.89      1.22        float32\n",
      "   71                model.22.dfl.conv.weight              Conv2d     False          16       [1, 16, 1, 1]       7.5      4.76        float32\n",
      "Model summary (fused): 72 layers, 3,007,403 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "============================================================\n",
      "üöÄ STARTING EXPERIMENT FOR MODEL: yolov10n (Aug: True)\n",
      "============================================================\n",
      "\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov10n.pt to 'yolov10n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.6MB 77.9MB/s 0.1s\n",
      "New https://pypi.org/project/ultralytics/8.3.203 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=D:\\Virtual_Fahion\\GraduationThesis2\\data\\data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train_yolov10n_aug_True, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=D:\\Virtual_Fahion\\GraduationThesis2\\saveModels, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov10n_aug_True, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1      9856  ultralytics.nn.modules.block.SCDown          [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.PSA             [256, 256]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 20                  -1  1     18048  ultralytics.nn.modules.block.SCDown          [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    282624  ultralytics.nn.modules.block.C2fCIB          [384, 256, 1, True, True]     \n",
      " 23        [16, 19, 22]  1    864838  ultralytics.nn.modules.head.v10Detect        [9, [64, 128, 256]]           \n",
      "YOLOv10n summary: 223 layers, 2,710,550 parameters, 2,710,534 gradients, 8.4 GFLOPs\n",
      "\n",
      "Transferred 493/595 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 211.588.7 MB/s, size: 20.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2\\data\\train\\labels.cache... 64864 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 64864/64864 62.1Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 492.8328.2 MB/s, size: 83.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2\\data\\valid\\labels.cache... 1720 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1720/1720 1.7Mit/s 0.0s\n",
      "Plotting labels to D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov10n_aug_True\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 95 weight(decay=0.0), 108 weight(decay=0.0005), 107 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov10n_aug_True\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/30      2.78G      2.543      4.462      3.216         48        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 6.2it/s 10:59<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.8it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.364      0.323      0.179     0.0969\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/30      3.01G      2.395      3.949      3.065         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 6.7it/s 10:02<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.298      0.404      0.285      0.181\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/30      3.01G      2.309      3.759      2.996         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.0it/s 9:40<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.294       0.52      0.357      0.234\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/30      3.01G      2.235      3.576      2.942         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:32<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.419      0.437      0.401      0.266\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/30      3.01G      2.189      3.457      2.903         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:32<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.399      0.509      0.433      0.297\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/30      3.01G      2.135      3.374      2.873         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:32<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.437      0.521      0.466      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/30      3.01G      2.112      3.304      2.853         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:33<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.427      0.562      0.491       0.34\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/30      3.01G      2.099       3.23      2.845         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:32<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.2it/s 6.6s0.1s\n",
      "                   all       1720       1720      0.447      0.569      0.517      0.364\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/30      3.01G      2.083      3.179      2.832         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:31<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.504      0.561      0.541       0.38\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/30      3.01G      2.064      3.135      2.816         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:32<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.1it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.503      0.546      0.546      0.383\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/30      3.01G      2.054      3.087      2.815         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:31<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.484      0.574      0.554      0.391\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/30      3.01G      2.033      3.064      2.801         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:32<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.7it/s 7.0s0.1s\n",
      "                   all       1720       1720      0.524      0.569      0.568      0.402\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/30      3.01G      2.024      3.016      2.795         43        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:32<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.546      0.573      0.579      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/30      3.01G      2.014       2.98      2.785         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:32<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.1it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.545      0.576      0.588      0.419\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/30      3.01G      1.981      2.955      2.763         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:32<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.545      0.589      0.589       0.42\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/30      3.01G      1.977      2.929      2.763         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:32<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.539      0.591      0.595      0.425\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/30      3.01G       1.96      2.893      2.751         37        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:32<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.542      0.587      0.595      0.426\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/30      3.01G      1.947      2.861      2.743         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:31<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.558      0.587      0.599       0.43\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/30      3.01G      1.932      2.838      2.733         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:31<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.554      0.586      0.599       0.43\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/30      3.01G      1.927      2.813      2.726         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:32<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.558      0.591      0.604      0.434\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/30      3.01G      1.934      2.319       3.08         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:29<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.547       0.59      0.606      0.437\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/30      3.01G      1.866      2.232       3.01         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:29<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.1it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.554      0.602      0.613      0.443\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/30      3.01G      1.834      2.163       2.98         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:29<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.8it/s 6.9s0.1s\n",
      "                   all       1720       1720       0.57      0.594      0.617      0.447\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/30      3.01G      1.812       2.11      2.955         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:29<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.8s0.1s\n",
      "                   all       1720       1720       0.57      0.596       0.62       0.45\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/30      3.01G      1.777      2.068      2.925         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:30<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.562      0.599      0.626      0.456\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/30      3.01G      1.754      2.004      2.901         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.0it/s 9:38<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.571      0.599       0.63       0.46\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/30      3.01G      1.733      1.956      2.883         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:28<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.1it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.596      0.582      0.637      0.466\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/30      3.01G      1.706      1.911      2.854         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:29<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.585      0.587      0.641      0.471\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/30      3.01G      1.685      1.846       2.84         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:28<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.1it/s 6.6s0.1s\n",
      "                   all       1720       1720       0.58      0.602      0.644      0.475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/30      3.01G      1.658      1.811       2.81         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:29<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.586      0.604      0.651      0.481\n",
      "\n",
      "30 epochs completed in 4.859 hours.\n",
      "Optimizer stripped from D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov10n_aug_True\\weights\\last.pt, 5.7MB\n",
      "Optimizer stripped from D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov10n_aug_True\\weights\\best.pt, 5.7MB\n",
      "\n",
      "Validating D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov10n_aug_True\\weights\\best.pt...\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "YOLOv10n summary (fused): 102 layers, 2,266,923 parameters, 0 gradients, 6.5 GFLOPs\n",
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 2% ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 1/54 0.8it/s 0.4s<1:05WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 4% ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 2/54 2.0it/s 0.6s<25.5sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 6% ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 3/54 2.8it/s 0.8s<18.5sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 7% ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 4/54 3.7it/s 1.0s<13.5sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 9% ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 5/54 4.3it/s 1.1s<11.4sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 11% ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 6/54 5.4it/s 1.3s<9.0sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 13% ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 7/54 6.1it/s 1.4s<7.7sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 15% ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 8/54 6.7it/s 1.5s<6.9sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 17% ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 9/54 7.1it/s 1.6s<6.3sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 19% ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 10/54 7.3it/s 1.8s<6.1sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 20% ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 11/54 7.5it/s 1.9s<5.7sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 22% ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 12/54 7.7it/s 2.0s<5.5sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 24% ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 13/54 7.8it/s 2.1s<5.3sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 26% ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 14/54 7.9it/s 2.3s<5.1sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 28% ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 15/54 8.0it/s 2.4s<4.9sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 30% ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 16/54 8.0it/s 2.5s<4.7sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 31% ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 17/54 8.2it/s 2.6s<4.5sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 33% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 18/54 8.3it/s 2.8s<4.4sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 35% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 19/54 8.3it/s 2.9s<4.2sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 37% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 20/54 8.4it/s 3.0s<4.1sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 39% ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 21/54 8.4it/s 3.1s<3.9sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 41% ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 22/54 8.5it/s 3.2s<3.8sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 43% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 23/54 8.6it/s 3.3s<3.6sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 44% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 24/54 8.6it/s 3.5s<3.5sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 46% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 25/54 8.4it/s 3.6s<3.4sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 48% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 26/54 8.4it/s 3.7s<3.3sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 27/54 8.4it/s 3.8s<3.2sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 52% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 28/54 8.4it/s 3.9s<3.1sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 54% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 29/54 8.4it/s 4.1s<3.0sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 56% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 30/54 8.4it/s 4.2s<2.8sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 57% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 31/54 8.4it/s 4.3s<2.7sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 59% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 32/54 8.4it/s 4.4s<2.6sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 61% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 33/54 8.3it/s 4.5s<2.5sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 63% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ 34/54 8.3it/s 4.7s<2.4sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 65% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ 35/54 8.3it/s 4.8s<2.3sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 67% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ 36/54 8.3it/s 4.9s<2.2sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 69% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ 37/54 8.4it/s 5.0s<2.0sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 70% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ 38/54 8.4it/s 5.1s<1.9sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 72% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 39/54 8.4it/s 5.2s<1.8sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 74% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 40/54 8.4it/s 5.4s<1.7sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 76% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ 41/54 8.5it/s 5.5s<1.5sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 78% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ 42/54 8.4it/s 5.6s<1.4sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 80% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ 43/54 8.4it/s 5.7s<1.3sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 81% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ 44/54 8.5it/s 5.8s<1.2sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 83% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ 45/54 8.3it/s 6.0s<1.1sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 85% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ 46/54 8.2it/s 6.1s<1.0sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 87% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ 47/54 8.3it/s 6.2s<0.8sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 89% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 48/54 8.3it/s 6.3s<0.7sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 49/54 8.2it/s 6.5s<0.6sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 93% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ 50/54 8.2it/s 6.6s<0.5sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 94% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ 51/54 8.2it/s 6.7s<0.4sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 96% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏ 52/54 8.3it/s 6.8s<0.2sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 98% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏ 53/54 8.5it/s 6.9s<0.1sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.7it/s 7.0s\n",
      "                   all       1720       1720      0.585      0.604      0.651      0.481\n",
      "                 angry        258        258      0.488      0.694      0.677      0.511\n",
      "              contempt         82         82      0.485      0.537      0.585      0.472\n",
      "               disgust        108        108      0.621      0.639      0.688      0.583\n",
      "                  fear        107        107      0.517      0.701      0.654      0.521\n",
      "                 happy        387        387      0.757      0.845      0.886      0.667\n",
      "               natural        172        172       0.52      0.453      0.477      0.331\n",
      "                   sad        312        312      0.558       0.62      0.627      0.407\n",
      "                sleepy         38         38      0.656      0.316      0.518      0.274\n",
      "             surprised        256        256      0.665      0.635      0.746      0.566\n",
      "Speed: 0.2ms preprocess, 0.8ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov10n_aug_True\u001b[0m\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "YOLOv10n summary (fused): 102 layers, 2,266,923 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 399.195.6 MB/s, size: 36.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2\\data\\valid\\labels.cache... 1720 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1720/1720  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 108/108 15.3it/s 7.1s0.1s\n",
      "                   all       1720       1720      0.587      0.604       0.65       0.48\n",
      "                 angry        258        258      0.485       0.69      0.676       0.51\n",
      "              contempt         82         82      0.488      0.537      0.585      0.472\n",
      "               disgust        108        108      0.625      0.639      0.687      0.583\n",
      "                  fear        107        107      0.518      0.701      0.645      0.513\n",
      "                 happy        387        387      0.762      0.842      0.886      0.665\n",
      "               natural        172        172      0.515      0.453      0.478      0.332\n",
      "                   sad        312        312      0.561      0.619      0.625      0.405\n",
      "                sleepy         38         38      0.659      0.316      0.518      0.274\n",
      "             surprised        256        256      0.673      0.635      0.746      0.567\n",
      "Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2\\runs\\detect\\val5\u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "üìà VISUALIZING TRAINING & VALIDATION ANALYSIS FOR: yolov10n (Aug: True)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "üìä EXTRACTING PERFORMANCE INDICATORS FOR: yolov10n (Aug: True)\n",
      "--------------------------------------------------\n",
      "layer                                    name                type  gradient  parameters               shape        mu     sigma\n",
      "    0                     model.0.conv.weight              Conv2d     False         432       [16, 3, 3, 3]   -0.0638      4.83        float32\n",
      "    0                       model.0.conv.bias              Conv2d     False          16                [16]     0.991       7.3        float32\n",
      "    1                             model.0.act                SiLU     False           0                  []         -         -              -\n",
      "    2                     model.1.conv.weight              Conv2d     False        4608      [32, 16, 3, 3]   0.00096     0.136        float32\n",
      "    2                       model.1.conv.bias              Conv2d     False          32                [32]     -5.03       7.2        float32\n",
      "    3                 model.2.cv1.conv.weight              Conv2d     False        1024      [32, 32, 1, 1]  -0.00968     0.127        float32\n",
      "    3                   model.2.cv1.conv.bias              Conv2d     False          32                [32]    -0.246      3.52        float32\n",
      "    4                 model.2.cv2.conv.weight              Conv2d     False        1536      [32, 48, 1, 1]   -0.0112     0.124        float32\n",
      "    4                   model.2.cv2.conv.bias              Conv2d     False          32                [32]      0.42      5.08        float32\n",
      "    5             model.2.m.0.cv1.conv.weight              Conv2d     False        2304      [16, 16, 3, 3]   -0.0058     0.208        float32\n",
      "    5               model.2.m.0.cv1.conv.bias              Conv2d     False          16                [16]      1.48      4.67        float32\n",
      "    6             model.2.m.0.cv2.conv.weight              Conv2d     False        2304      [16, 16, 3, 3]  -0.00196    0.0844        float32\n",
      "    6               model.2.m.0.cv2.conv.bias              Conv2d     False          16                [16]     0.619      3.77        float32\n",
      "    7                     model.3.conv.weight              Conv2d     False       18432      [64, 32, 3, 3] -0.000964    0.0281        float32\n",
      "    7                       model.3.conv.bias              Conv2d     False          64                [64]    -0.379      3.39        float32\n",
      "    8                 model.4.cv1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  -0.00306     0.125        float32\n",
      "    8                   model.4.cv1.conv.bias              Conv2d     False          64                [64]    -0.804      4.48        float32\n",
      "    9                 model.4.cv2.conv.weight              Conv2d     False        8192     [64, 128, 1, 1] -0.000139    0.0502        float32\n",
      "    9                   model.4.cv2.conv.bias              Conv2d     False          64                [64]       1.2      4.26        float32\n",
      "   10             model.4.m.0.cv1.conv.weight              Conv2d     False        9216      [32, 32, 3, 3] -0.000663    0.0581        float32\n",
      "   10               model.4.m.0.cv1.conv.bias              Conv2d     False          32                [32]     -3.03      4.78        float32\n",
      "   11             model.4.m.0.cv2.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00206    0.0314        float32\n",
      "   11               model.4.m.0.cv2.conv.bias              Conv2d     False          32                [32]     -1.28      3.75        float32\n",
      "   12             model.4.m.1.cv1.conv.weight              Conv2d     False        9216      [32, 32, 3, 3] -0.000539    0.0333        float32\n",
      "   12               model.4.m.1.cv1.conv.bias              Conv2d     False          32                [32]      -3.6      4.29        float32\n",
      "   13             model.4.m.1.cv2.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00314    0.0771        float32\n",
      "   13               model.4.m.1.cv2.conv.bias              Conv2d     False          32                [32]     -0.22      4.78        float32\n",
      "   14                 model.5.cv1.conv.weight              Conv2d     False        8192     [128, 64, 1, 1]  -0.00123    0.0881        float32\n",
      "   14                   model.5.cv1.conv.bias              Conv2d     False         128               [128]     -1.27      4.02        float32\n",
      "   15                 model.5.cv2.conv.weight              Conv2d     False        1152      [128, 1, 3, 3]    0.0856     0.472        float32\n",
      "   15                   model.5.cv2.conv.bias              Conv2d     False         128               [128]    -0.301      5.43        float32\n",
      "   16                         model.5.cv2.act            Identity     False           0                  []         -         -              -\n",
      "   17                 model.6.cv1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1] -0.000262    0.0505        float32\n",
      "   17                   model.6.cv1.conv.bias              Conv2d     False         128               [128]     -1.37      4.76        float32\n",
      "   18                 model.6.cv2.conv.weight              Conv2d     False       32768    [128, 256, 1, 1] -0.000243    0.0245        float32\n",
      "   18                   model.6.cv2.conv.bias              Conv2d     False         128               [128]    -0.529      3.37        float32\n",
      "   19             model.6.m.0.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -0.00105    0.0329        float32\n",
      "   19               model.6.m.0.cv1.conv.bias              Conv2d     False          64                [64]        -5      4.28        float32\n",
      "   20             model.6.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -0.00165    0.0344        float32\n",
      "   20               model.6.m.0.cv2.conv.bias              Conv2d     False          64                [64]     -3.83      4.13        float32\n",
      "   21             model.6.m.1.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000725    0.0194        float32\n",
      "   21               model.6.m.1.cv1.conv.bias              Conv2d     False          64                [64]     -5.69      4.61        float32\n",
      "   22             model.6.m.1.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  0.000144    0.0618        float32\n",
      "   22               model.6.m.1.cv2.conv.bias              Conv2d     False          64                [64]     -1.22      3.46        float32\n",
      "   23                 model.7.cv1.conv.weight              Conv2d     False       32768    [256, 128, 1, 1]  0.000517    0.0358        float32\n",
      "   23                   model.7.cv1.conv.bias              Conv2d     False         256               [256]      -1.8      2.98        float32\n",
      "   24                 model.7.cv2.conv.weight              Conv2d     False        2304      [256, 1, 3, 3]    0.0233      0.34        float32\n",
      "   24                   model.7.cv2.conv.bias              Conv2d     False         256               [256]    -0.296      5.59        float32\n",
      "   25                         model.7.cv2.act            Identity     False           0                  []         -         -              -\n",
      "   26                 model.8.cv1.conv.weight              Conv2d     False       65536    [256, 256, 1, 1] -3.17e-05    0.0134        float32\n",
      "   26                   model.8.cv1.conv.bias              Conv2d     False         256               [256]     -5.16      4.99        float32\n",
      "   27                 model.8.cv2.conv.weight              Conv2d     False       98304    [256, 384, 1, 1] -6.43e-05     0.018        float32\n",
      "   27                   model.8.cv2.conv.bias              Conv2d     False         256               [256]     -2.88      3.49        float32\n",
      "   28             model.8.m.0.cv1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -9.18e-05    0.0168        float32\n",
      "   28               model.8.m.0.cv1.conv.bias              Conv2d     False         128               [128]     -7.42      4.07        float32\n",
      "   29             model.8.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -8.34e-05    0.0118        float32\n",
      "   29               model.8.m.0.cv2.conv.bias              Conv2d     False         128               [128]     -4.29      4.13        float32\n",
      "   30                 model.9.cv1.conv.weight              Conv2d     False       32768    [128, 256, 1, 1]  -0.00115    0.0267        float32\n",
      "   30                   model.9.cv1.conv.bias              Conv2d     False         128               [128]     0.512      5.01        float32\n",
      "   31                 model.9.cv2.conv.weight              Conv2d     False      131072    [256, 512, 1, 1]  5.86e-05    0.0127        float32\n",
      "   31                   model.9.cv2.conv.bias              Conv2d     False         256               [256]     -3.48      3.93        float32\n",
      "   32                               model.9.m           MaxPool2d     False           0                  []         -         -              -\n",
      "   33                model.10.cv1.conv.weight              Conv2d     False       65536    [256, 256, 1, 1] -0.000783    0.0748        float32\n",
      "   33                  model.10.cv1.conv.bias              Conv2d     False         256               [256]     -2.34      4.08        float32\n",
      "   34                model.10.cv2.conv.weight              Conv2d     False       65536    [256, 256, 1, 1] -0.000404    0.0216        float32\n",
      "   34                  model.10.cv2.conv.bias              Conv2d     False         256               [256]     -4.64       4.6        float32\n",
      "   35           model.10.attn.qkv.conv.weight              Conv2d     False       32768    [256, 128, 1, 1] -0.000139    0.0285        float32\n",
      "   35             model.10.attn.qkv.conv.bias              Conv2d     False         256               [256]     0.185      4.05        float32\n",
      "   36                   model.10.attn.qkv.act            Identity     False           0                  []         -         -              -\n",
      "   37          model.10.attn.proj.conv.weight              Conv2d     False       16384    [128, 128, 1, 1] -1.35e-05     0.018        float32\n",
      "   37            model.10.attn.proj.conv.bias              Conv2d     False         128               [128]      1.03      5.95        float32\n",
      "   38                  model.10.attn.proj.act            Identity     False           0                  []         -         -              -\n",
      "   39            model.10.attn.pe.conv.weight              Conv2d     False        1152      [128, 1, 3, 3]  -0.00652    0.0936        float32\n",
      "   39              model.10.attn.pe.conv.bias              Conv2d     False         128               [128]     -0.43      5.27        float32\n",
      "   40                    model.10.attn.pe.act            Identity     False           0                  []         -         -              -\n",
      "   41              model.10.ffn.0.conv.weight              Conv2d     False       32768    [256, 128, 1, 1]  8.65e-05    0.0145        float32\n",
      "   41                model.10.ffn.0.conv.bias              Conv2d     False         256               [256]     -4.74      1.82        float32\n",
      "   42              model.10.ffn.1.conv.weight              Conv2d     False       32768    [128, 256, 1, 1] -3.79e-05   0.00585        float32\n",
      "   42                model.10.ffn.1.conv.bias              Conv2d     False         128               [128]      1.47      5.65        float32\n",
      "   43                      model.10.ffn.1.act            Identity     False           0                  []         -         -              -\n",
      "   44                                model.11            Upsample     False           0                  []         -         -              -\n",
      "   45                                model.12              Concat     False           0                  []         -         -              -\n",
      "   46                model.13.cv1.conv.weight              Conv2d     False       49152    [128, 384, 1, 1] -0.000352    0.0275        float32\n",
      "   46                  model.13.cv1.conv.bias              Conv2d     False         128               [128]     -3.03      4.23        float32\n",
      "   47                model.13.cv2.conv.weight              Conv2d     False       24576    [128, 192, 1, 1]  -0.00089    0.0448        float32\n",
      "   47                  model.13.cv2.conv.bias              Conv2d     False         128               [128]      -2.9      3.93        float32\n",
      "   48            model.13.m.0.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000473     0.022        float32\n",
      "   48              model.13.m.0.cv1.conv.bias              Conv2d     False          64                [64]     -6.42      4.08        float32\n",
      "   49            model.13.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -0.00018    0.0187        float32\n",
      "   49              model.13.m.0.cv2.conv.bias              Conv2d     False          64                [64]     -2.27      2.84        float32\n",
      "   50                                model.14            Upsample     False           0                  []         -         -              -\n",
      "   51                                model.15              Concat     False           0                  []         -         -              -\n",
      "   52                model.16.cv1.conv.weight              Conv2d     False       12288     [64, 192, 1, 1] -0.000254    0.0351        float32\n",
      "   52                  model.16.cv1.conv.bias              Conv2d     False          64                [64]     -2.01      4.44        float32\n",
      "   53                model.16.cv2.conv.weight              Conv2d     False        6144      [64, 96, 1, 1]  0.000633    0.0634        float32\n",
      "   53                  model.16.cv2.conv.bias              Conv2d     False          64                [64]     -3.52      4.35        float32\n",
      "   54            model.16.m.0.cv1.conv.weight              Conv2d     False        9216      [32, 32, 3, 3] -0.000407     0.029        float32\n",
      "   54              model.16.m.0.cv1.conv.bias              Conv2d     False          32                [32]     -4.37      4.61        float32\n",
      "   55            model.16.m.0.cv2.conv.weight              Conv2d     False        9216      [32, 32, 3, 3] -0.000321     0.029        float32\n",
      "   55              model.16.m.0.cv2.conv.bias              Conv2d     False          32                [32]   -0.0802      3.58        float32\n",
      "   56                    model.17.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  0.000192    0.0119        float32\n",
      "   56                      model.17.conv.bias              Conv2d     False          64                [64]        -2      3.23        float32\n",
      "   57                                model.18              Concat     False           0                  []         -         -              -\n",
      "   58                model.19.cv1.conv.weight              Conv2d     False       24576    [128, 192, 1, 1]  0.000359    0.0507        float32\n",
      "   58                  model.19.cv1.conv.bias              Conv2d     False         128               [128]     -3.86      4.51        float32\n",
      "   59                model.19.cv2.conv.weight              Conv2d     False       24576    [128, 192, 1, 1] -0.000179    0.0373        float32\n",
      "   59                  model.19.cv2.conv.bias              Conv2d     False         128               [128]     -3.37      3.98        float32\n",
      "   60            model.19.m.0.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -0.00041    0.0178        float32\n",
      "   60              model.19.m.0.cv1.conv.bias              Conv2d     False          64                [64]     -5.28      4.68        float32\n",
      "   61            model.19.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000241    0.0277        float32\n",
      "   61              model.19.m.0.cv2.conv.bias              Conv2d     False          64                [64]     -1.31      2.58        float32\n",
      "   62                model.20.cv1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1] -0.000125    0.0584        float32\n",
      "   62                  model.20.cv1.conv.bias              Conv2d     False         128               [128]    -0.672      3.97        float32\n",
      "   63                model.20.cv2.conv.weight              Conv2d     False        1152      [128, 1, 3, 3]    0.0149     0.372        float32\n",
      "   63                  model.20.cv2.conv.bias              Conv2d     False         128               [128]    0.0943      6.48        float32\n",
      "   64                        model.20.cv2.act            Identity     False           0                  []         -         -              -\n",
      "   65                                model.21              Concat     False           0                  []         -         -              -\n",
      "   66                model.22.cv1.conv.weight              Conv2d     False       98304    [256, 384, 1, 1] -0.000155     0.029        float32\n",
      "   66                  model.22.cv1.conv.bias              Conv2d     False         256               [256]     -3.84      5.09        float32\n",
      "   67                model.22.cv2.conv.weight              Conv2d     False       98304    [256, 384, 1, 1] -0.000167    0.0288        float32\n",
      "   67                  model.22.cv2.conv.bias              Conv2d     False         256               [256]     -4.88      4.39        float32\n",
      "   68          model.22.m.0.cv1.0.conv.weight              Conv2d     False        1152      [128, 1, 3, 3]      0.13      2.41        float32\n",
      "   68            model.22.m.0.cv1.0.conv.bias              Conv2d     False         128               [128]   -0.0646      2.15        float32\n",
      "   69          model.22.m.0.cv1.1.conv.weight              Conv2d     False       32768    [256, 128, 1, 1]   0.00106    0.0646        float32\n",
      "   69            model.22.m.0.cv1.1.conv.bias              Conv2d     False         256               [256]    -0.762      2.71        float32\n",
      "   70          model.22.m.0.cv1.2.conv.weight              Conv2d     False       12544      [256, 1, 7, 7]    0.0049     0.264        float32\n",
      "   70            model.22.m.0.cv1.2.conv.bias              Conv2d     False         256               [256]     -1.24       5.9        float32\n",
      "   71                  model.22.m.0.cv1.2.act                SiLU     False           0                  []         -         -              -\n",
      "   72          model.22.m.0.cv1.3.conv.weight              Conv2d     False       32768    [128, 256, 1, 1] -0.000803    0.0392        float32\n",
      "   72            model.22.m.0.cv1.3.conv.bias              Conv2d     False         128               [128]    -0.919      3.26        float32\n",
      "   73          model.22.m.0.cv1.4.conv.weight              Conv2d     False        1152      [128, 1, 3, 3]    0.0229     0.616        float32\n",
      "   73            model.22.m.0.cv1.4.conv.bias              Conv2d     False         128               [128]     0.958      3.66        float32\n",
      "   74                          model.23.cv2.0            Identity     False           0                  []         -         -              -\n",
      "   75                model.23.dfl.conv.weight              Conv2d     False          16       [1, 16, 1, 1]       7.5      4.76        float32\n",
      "   76    model.23.one2one_cv2.0.0.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000321    0.0132        float32\n",
      "   76      model.23.one2one_cv2.0.0.conv.bias              Conv2d     False          64                [64]     -3.43      4.74        float32\n",
      "   77            model.23.one2one_cv2.0.0.act                SiLU     False           0                  []         -         -              -\n",
      "   78    model.23.one2one_cv2.0.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000113   0.00608        float32\n",
      "   78      model.23.one2one_cv2.0.1.conv.bias              Conv2d     False          64                [64]     -7.08      4.35        float32\n",
      "   79         model.23.one2one_cv2.0.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   0.00491    0.0822        float32\n",
      "   79           model.23.one2one_cv2.0.2.bias              Conv2d     False          64                [64]      2.04      2.34        float32\n",
      "   80    model.23.one2one_cv2.1.0.conv.weight              Conv2d     False       73728     [64, 128, 3, 3] -0.000138   0.00581        float32\n",
      "   80      model.23.one2one_cv2.1.0.conv.bias              Conv2d     False          64                [64]     -3.25      4.63        float32\n",
      "   81    model.23.one2one_cv2.1.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -3.67e-05   0.00587        float32\n",
      "   81      model.23.one2one_cv2.1.1.conv.bias              Conv2d     False          64                [64]     -7.07      4.62        float32\n",
      "   82         model.23.one2one_cv2.1.2.weight              Conv2d     False        4096      [64, 64, 1, 1]    0.0026     0.111        float32\n",
      "   82           model.23.one2one_cv2.1.2.bias              Conv2d     False          64                [64]   -0.0417      2.99        float32\n",
      "   83    model.23.one2one_cv2.2.0.conv.weight              Conv2d     False      147456     [64, 256, 3, 3] -0.000201    0.0062        float32\n",
      "   83      model.23.one2one_cv2.2.0.conv.bias              Conv2d     False          64                [64]     -2.54      4.73        float32\n",
      "   84    model.23.one2one_cv2.2.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000403   0.00859        float32\n",
      "   84      model.23.one2one_cv2.2.1.conv.bias              Conv2d     False          64                [64]     -1.92      4.31        float32\n",
      "   85         model.23.one2one_cv2.2.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   -0.0316     0.319        float32\n",
      "   85           model.23.one2one_cv2.2.2.bias              Conv2d     False          64                [64]     0.119      2.67        float32\n",
      "   86  model.23.one2one_cv3.0.0.0.conv.weight              Conv2d     False         576       [64, 1, 3, 3]     0.251      2.62        float32\n",
      "   86    model.23.one2one_cv3.0.0.0.conv.bias              Conv2d     False          64                [64]       2.9      5.62        float32\n",
      "   87          model.23.one2one_cv3.0.0.0.act                SiLU     False           0                  []         -         -              -\n",
      "   88  model.23.one2one_cv3.0.0.1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1] -0.000689     0.108        float32\n",
      "   88    model.23.one2one_cv3.0.0.1.conv.bias              Conv2d     False          64                [64]      1.04      8.72        float32\n",
      "   89  model.23.one2one_cv3.0.1.0.conv.weight              Conv2d     False         576       [64, 1, 3, 3]  -0.00201     0.114        float32\n",
      "   89    model.23.one2one_cv3.0.1.0.conv.bias              Conv2d     False          64                [64]     -1.71      6.69        float32\n",
      "   90  model.23.one2one_cv3.0.1.1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  -0.00195    0.0337        float32\n",
      "   90    model.23.one2one_cv3.0.1.1.conv.bias              Conv2d     False          64                [64]     -2.44      6.86        float32\n",
      "   91         model.23.one2one_cv3.0.2.weight              Conv2d     False         576       [9, 64, 1, 1]   -0.0256      0.11        float32\n",
      "   91           model.23.one2one_cv3.0.2.bias              Conv2d     False           9                 [9]     -11.1      4.85        float32\n",
      "   92  model.23.one2one_cv3.1.0.0.conv.weight              Conv2d     False        1152      [128, 1, 3, 3]     0.051     0.616        float32\n",
      "   92    model.23.one2one_cv3.1.0.0.conv.bias              Conv2d     False         128               [128]    0.0874      5.15        float32\n",
      "   93  model.23.one2one_cv3.1.0.1.conv.weight              Conv2d     False        8192     [64, 128, 1, 1]  0.000336    0.0524        float32\n",
      "   93    model.23.one2one_cv3.1.0.1.conv.bias              Conv2d     False          64                [64]      1.71      5.34        float32\n",
      "   94  model.23.one2one_cv3.1.1.0.conv.weight              Conv2d     False         576       [64, 1, 3, 3]   -0.0206     0.429        float32\n",
      "   94    model.23.one2one_cv3.1.1.0.conv.bias              Conv2d     False          64                [64]     -1.17      6.44        float32\n",
      "   95  model.23.one2one_cv3.1.1.1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1] -0.000214    0.0514        float32\n",
      "   95    model.23.one2one_cv3.1.1.1.conv.bias              Conv2d     False          64                [64]     -3.38      5.93        float32\n",
      "   96         model.23.one2one_cv3.1.2.weight              Conv2d     False         576       [9, 64, 1, 1]   -0.0365     0.149        float32\n",
      "   96           model.23.one2one_cv3.1.2.bias              Conv2d     False           9                 [9]     -9.16      5.27        float32\n",
      "   97  model.23.one2one_cv3.2.0.0.conv.weight              Conv2d     False        2304      [256, 1, 3, 3]     0.107      1.16        float32\n",
      "   97    model.23.one2one_cv3.2.0.0.conv.bias              Conv2d     False         256               [256]     -1.59       4.7        float32\n",
      "   98  model.23.one2one_cv3.2.0.1.conv.weight              Conv2d     False       16384     [64, 256, 1, 1]  -0.00015    0.0348        float32\n",
      "   98    model.23.one2one_cv3.2.0.1.conv.bias              Conv2d     False          64                [64]      1.63      4.03        float32\n",
      "   99  model.23.one2one_cv3.2.1.0.conv.weight              Conv2d     False         576       [64, 1, 3, 3]    0.0046     0.384        float32\n",
      "   99    model.23.one2one_cv3.2.1.0.conv.bias              Conv2d     False          64                [64]     -2.92      5.51        float32\n",
      "  100  model.23.one2one_cv3.2.1.1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  -0.00736       0.3        float32\n",
      "  100    model.23.one2one_cv3.2.1.1.conv.bias              Conv2d     False          64                [64]      2.03       9.5        float32\n",
      "  101         model.23.one2one_cv3.2.2.weight              Conv2d     False         576       [9, 64, 1, 1]    -0.166     0.347        float32\n",
      "  101           model.23.one2one_cv3.2.2.bias              Conv2d     False           9                 [9]     -4.35      1.13        float32\n",
      "YOLOv10n summary (fused): 102 layers, 2,266,923 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\n",
      "============================================================\n",
      "üöÄ STARTING EXPERIMENT FOR MODEL: yolov10n (Aug: False)\n",
      "============================================================\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.203 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=D:\\Virtual_Fahion\\GraduationThesis2\\data\\data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train_yolov10n_aug_False, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=D:\\Virtual_Fahion\\GraduationThesis2\\saveModels, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov10n_aug_False, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1      9856  ultralytics.nn.modules.block.SCDown          [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.PSA             [256, 256]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 20                  -1  1     18048  ultralytics.nn.modules.block.SCDown          [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    282624  ultralytics.nn.modules.block.C2fCIB          [384, 256, 1, True, True]     \n",
      " 23        [16, 19, 22]  1    864838  ultralytics.nn.modules.head.v10Detect        [9, [64, 128, 256]]           \n",
      "YOLOv10n summary: 223 layers, 2,710,550 parameters, 2,710,534 gradients, 8.4 GFLOPs\n",
      "\n",
      "Transferred 493/595 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 221.991.3 MB/s, size: 20.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2\\data\\train\\labels.cache... 64864 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 64864/64864 64.9Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 449.4258.2 MB/s, size: 83.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2\\data\\valid\\labels.cache... 1720 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1720/1720 1.7Mit/s 0.0s\n",
      "Plotting labels to D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov10n_aug_False\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 95 weight(decay=0.0), 108 weight(decay=0.0005), 107 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov10n_aug_False\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/30      2.78G      2.543      4.462      3.216         48        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 6.2it/s 10:58<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.364      0.323      0.179     0.0969\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/30      3.09G      2.395      3.949      3.065         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 6.7it/s 10:03<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.8it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.298      0.404      0.285      0.181\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/30      3.09G      2.309      3.759      2.996         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.0it/s 9:42<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.292      0.526      0.357      0.234\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/30      3.09G      2.232      3.583      2.939         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:30<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.432      0.469      0.411      0.274\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/30      3.09G       2.18      3.462      2.898         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:31<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.406       0.52      0.448        0.3\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/30      3.09G      2.135      3.367      2.874         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:30<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.8it/s 6.9s0.1s\n",
      "                   all       1720       1720       0.44       0.52      0.464      0.313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/30      3.09G      2.109      3.274      2.853         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:29<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.454      0.508      0.484      0.332\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/30      3.09G      2.098      3.211      2.845         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:30<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.8it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.489       0.54      0.519      0.357\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/30      3.09G      2.078      3.159       2.83         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:31<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.501      0.556      0.535      0.377\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/30      3.09G      2.063      3.122      2.818         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:29<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720       0.52      0.552      0.547      0.385\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/30      3.09G      2.047      3.076       2.81         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:30<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.512       0.57       0.56      0.396\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/30      3.09G       2.03      3.046      2.798         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:31<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.532      0.542       0.57      0.405\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/30      3.09G       2.02      3.003      2.791         43        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:30<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.532      0.561      0.579      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/30      3.09G      2.006      2.966       2.78         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:31<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.545      0.563      0.584      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/30      3.09G      1.992      2.936      2.772         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:29<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.1it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.532       0.56      0.586      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/30      3.09G      1.979      2.917      2.765         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:29<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.531      0.569      0.592      0.423\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/30      3.09G      1.958      2.887      2.748         37        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:29<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.556      0.559      0.596      0.427\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/30      3.09G      1.945      2.857      2.742         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:29<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.9s0.1s\n",
      "                   all       1720       1720       0.53      0.577      0.594      0.426\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/30      3.09G      1.939      2.818      2.738         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.1it/s 9:30<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.542      0.571        0.6      0.431\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/30      3.09G      1.922      2.805      2.723         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.2it/s 9:27<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.1it/s 6.7s0.1s\n",
      "                   all       1720       1720      0.543      0.589      0.602      0.433\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/30      3.09G      1.913      2.335      3.063         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.2it/s 9:20<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.558      0.591      0.606      0.437\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/30      3.09G      1.863       2.24      3.011         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.3it/s 9:17<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.9s0.1s\n",
      "                   all       1720       1720       0.55      0.603      0.611      0.442\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/30      3.09G      1.837      2.162      2.982         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.3it/s 9:18<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.569      0.593      0.618      0.448\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/30      3.09G      1.816      2.104      2.959         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.3it/s 9:18<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.9s0.1s\n",
      "                   all       1720       1720      0.541      0.617      0.626      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/30      3.09G      1.792      2.051      2.937         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.3it/s 9:18<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.538       0.63      0.629      0.458\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/30      3.09G      1.761      2.007       2.91         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.3it/s 9:18<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.546      0.626      0.637      0.466\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/30      3.09G      1.743      1.947      2.892         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.3it/s 9:18<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.553      0.626      0.642      0.472\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/30      3.09G      1.709      1.904      2.856         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.3it/s 9:18<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.7it/s 7.0s0.1s\n",
      "                   all       1720       1720      0.609      0.592      0.648      0.477\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/30      3.09G      1.676      1.845      2.832         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.3it/s 9:18<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.9it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.574      0.623       0.65       0.48\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/30      3.09G      1.658      1.805      2.812         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 7.3it/s 9:17<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.0it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.592      0.612      0.655      0.485\n",
      "\n",
      "30 epochs completed in 4.817 hours.\n",
      "Optimizer stripped from D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov10n_aug_False\\weights\\last.pt, 5.7MB\n",
      "Optimizer stripped from D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov10n_aug_False\\weights\\best.pt, 5.7MB\n",
      "\n",
      "Validating D:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov10n_aug_False\\weights\\best.pt...\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "YOLOv10n summary (fused): 102 layers, 2,266,923 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 7.6it/s 7.1s0.1s\n",
      "                   all       1720       1720      0.587      0.616      0.654      0.484\n",
      "                 angry        258        258      0.548      0.636      0.687       0.52\n",
      "              contempt         82         82      0.447      0.695      0.594      0.484\n",
      "               disgust        108        108      0.624      0.546      0.661      0.555\n",
      "                  fear        107        107      0.492      0.729      0.684      0.544\n",
      "                 happy        387        387      0.828      0.821      0.894      0.668\n",
      "               natural        172        172      0.526      0.453      0.475      0.333\n",
      "                   sad        312        312      0.475      0.673      0.625      0.402\n",
      "                sleepy         38         38       0.65      0.342      0.512       0.28\n",
      "             surprised        256        256      0.694      0.652      0.752       0.57\n",
      "Speed: 0.2ms preprocess, 0.8ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2\\saveModels\\train_yolov10n_aug_False\u001b[0m\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "YOLOv10n summary (fused): 102 layers, 2,266,923 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 387.3119.7 MB/s, size: 36.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2\\data\\valid\\labels.cache... 1720 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1720/1720 1.7Mit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 108/108 15.9it/s 6.8s0.1s\n",
      "                   all       1720       1720      0.592      0.611      0.654      0.485\n",
      "                 angry        258        258      0.546       0.62      0.683      0.516\n",
      "              contempt         82         82       0.45      0.695        0.6       0.49\n",
      "               disgust        108        108      0.638      0.546      0.664      0.557\n",
      "                  fear        107        107      0.494       0.72      0.684      0.545\n",
      "                 happy        387        387      0.834       0.82      0.896      0.668\n",
      "               natural        172        172      0.531      0.448      0.474      0.333\n",
      "                   sad        312        312       0.48      0.666      0.622      0.402\n",
      "                sleepy         38         38      0.654      0.342      0.514      0.281\n",
      "             surprised        256        256        0.7      0.645      0.753       0.57\n",
      "Speed: 0.1ms preprocess, 0.8ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2\\runs\\detect\\val6\u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "üìà VISUALIZING TRAINING & VALIDATION ANALYSIS FOR: yolov10n (Aug: False)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "üìä EXTRACTING PERFORMANCE INDICATORS FOR: yolov10n (Aug: False)\n",
      "--------------------------------------------------\n",
      "layer                                    name                type  gradient  parameters               shape        mu     sigma\n",
      "    0                     model.0.conv.weight              Conv2d     False         432       [16, 3, 3, 3]   -0.0526      4.75        float32\n",
      "    0                       model.0.conv.bias              Conv2d     False          16                [16]     0.853      7.14        float32\n",
      "    1                             model.0.act                SiLU     False           0                  []         -         -              -\n",
      "    2                     model.1.conv.weight              Conv2d     False        4608      [32, 16, 3, 3]  0.000556     0.138        float32\n",
      "    2                       model.1.conv.bias              Conv2d     False          32                [32]     -5.01      6.38        float32\n",
      "    3                 model.2.cv1.conv.weight              Conv2d     False        1024      [32, 32, 1, 1]   -0.0106     0.129        float32\n",
      "    3                   model.2.cv1.conv.bias              Conv2d     False          32                [32]   -0.0694      3.35        float32\n",
      "    4                 model.2.cv2.conv.weight              Conv2d     False        1536      [32, 48, 1, 1]   -0.0132     0.127        float32\n",
      "    4                   model.2.cv2.conv.bias              Conv2d     False          32                [32]     0.776      4.67        float32\n",
      "    5             model.2.m.0.cv1.conv.weight              Conv2d     False        2304      [16, 16, 3, 3]  -0.00617     0.204        float32\n",
      "    5               model.2.m.0.cv1.conv.bias              Conv2d     False          16                [16]      1.67       4.6        float32\n",
      "    6             model.2.m.0.cv2.conv.weight              Conv2d     False        2304      [16, 16, 3, 3]  -7.9e-06    0.0845        float32\n",
      "    6               model.2.m.0.cv2.conv.bias              Conv2d     False          16                [16]     0.237      4.23        float32\n",
      "    7                     model.3.conv.weight              Conv2d     False       18432      [64, 32, 3, 3] -0.000666    0.0277        float32\n",
      "    7                       model.3.conv.bias              Conv2d     False          64                [64]    -0.726      3.41        float32\n",
      "    8                 model.4.cv1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  -0.00092     0.122        float32\n",
      "    8                   model.4.cv1.conv.bias              Conv2d     False          64                [64]     -1.05      4.73        float32\n",
      "    9                 model.4.cv2.conv.weight              Conv2d     False        8192     [64, 128, 1, 1]  0.000267    0.0521        float32\n",
      "    9                   model.4.cv2.conv.bias              Conv2d     False          64                [64]     0.878      4.34        float32\n",
      "   10             model.4.m.0.cv1.conv.weight              Conv2d     False        9216      [32, 32, 3, 3] -0.000862    0.0558        float32\n",
      "   10               model.4.m.0.cv1.conv.bias              Conv2d     False          32                [32]      -3.2      4.77        float32\n",
      "   11             model.4.m.0.cv2.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00163    0.0302        float32\n",
      "   11               model.4.m.0.cv2.conv.bias              Conv2d     False          32                [32]     -1.32      3.62        float32\n",
      "   12             model.4.m.1.cv1.conv.weight              Conv2d     False        9216      [32, 32, 3, 3] -0.000232    0.0348        float32\n",
      "   12               model.4.m.1.cv1.conv.bias              Conv2d     False          32                [32]     -3.79      4.26        float32\n",
      "   13             model.4.m.1.cv2.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00326    0.0812        float32\n",
      "   13               model.4.m.1.cv2.conv.bias              Conv2d     False          32                [32]    0.0478      5.07        float32\n",
      "   14                 model.5.cv1.conv.weight              Conv2d     False        8192     [128, 64, 1, 1] -0.000532    0.0868        float32\n",
      "   14                   model.5.cv1.conv.bias              Conv2d     False         128               [128]     -1.29      3.87        float32\n",
      "   15                 model.5.cv2.conv.weight              Conv2d     False        1152      [128, 1, 3, 3]    0.0853     0.519        float32\n",
      "   15                   model.5.cv2.conv.bias              Conv2d     False         128               [128]    -0.329       5.5        float32\n",
      "   16                         model.5.cv2.act            Identity     False           0                  []         -         -              -\n",
      "   17                 model.6.cv1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1] -0.000355      0.05        float32\n",
      "   17                   model.6.cv1.conv.bias              Conv2d     False         128               [128]     -1.38      4.87        float32\n",
      "   18                 model.6.cv2.conv.weight              Conv2d     False       32768    [128, 256, 1, 1] -0.000128    0.0249        float32\n",
      "   18                   model.6.cv2.conv.bias              Conv2d     False         128               [128]    -0.591      3.29        float32\n",
      "   19             model.6.m.0.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -0.00102    0.0333        float32\n",
      "   19               model.6.m.0.cv1.conv.bias              Conv2d     False          64                [64]     -4.86      4.25        float32\n",
      "   20             model.6.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -0.00139    0.0327        float32\n",
      "   20               model.6.m.0.cv2.conv.bias              Conv2d     False          64                [64]     -3.91      4.16        float32\n",
      "   21             model.6.m.1.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -0.00072    0.0193        float32\n",
      "   21               model.6.m.1.cv1.conv.bias              Conv2d     False          64                [64]     -5.46      4.55        float32\n",
      "   22             model.6.m.1.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000391    0.0648        float32\n",
      "   22               model.6.m.1.cv2.conv.bias              Conv2d     False          64                [64]     -1.18      3.54        float32\n",
      "   23                 model.7.cv1.conv.weight              Conv2d     False       32768    [256, 128, 1, 1]  9.27e-05    0.0262        float32\n",
      "   23                   model.7.cv1.conv.bias              Conv2d     False         256               [256]     -1.72       2.8        float32\n",
      "   24                 model.7.cv2.conv.weight              Conv2d     False        2304      [256, 1, 3, 3]   0.00643     0.311        float32\n",
      "   24                   model.7.cv2.conv.bias              Conv2d     False         256               [256]    -0.205      5.42        float32\n",
      "   25                         model.7.cv2.act            Identity     False           0                  []         -         -              -\n",
      "   26                 model.8.cv1.conv.weight              Conv2d     False       65536    [256, 256, 1, 1] -1.68e-05    0.0136        float32\n",
      "   26                   model.8.cv1.conv.bias              Conv2d     False         256               [256]     -5.14      4.81        float32\n",
      "   27                 model.8.cv2.conv.weight              Conv2d     False       98304    [256, 384, 1, 1] -8.83e-05    0.0182        float32\n",
      "   27                   model.8.cv2.conv.bias              Conv2d     False         256               [256]     -2.86      3.49        float32\n",
      "   28             model.8.m.0.cv1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -9.88e-05     0.016        float32\n",
      "   28               model.8.m.0.cv1.conv.bias              Conv2d     False         128               [128]      -7.4         4        float32\n",
      "   29             model.8.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -0.000187    0.0126        float32\n",
      "   29               model.8.m.0.cv2.conv.bias              Conv2d     False         128               [128]     -4.19      4.42        float32\n",
      "   30                 model.9.cv1.conv.weight              Conv2d     False       32768    [128, 256, 1, 1]  -0.00128    0.0266        float32\n",
      "   30                   model.9.cv1.conv.bias              Conv2d     False         128               [128]      0.64      5.09        float32\n",
      "   31                 model.9.cv2.conv.weight              Conv2d     False      131072    [256, 512, 1, 1]  4.77e-05    0.0131        float32\n",
      "   31                   model.9.cv2.conv.bias              Conv2d     False         256               [256]     -3.38      3.84        float32\n",
      "   32                               model.9.m           MaxPool2d     False           0                  []         -         -              -\n",
      "   33                model.10.cv1.conv.weight              Conv2d     False       65536    [256, 256, 1, 1]  -0.00095    0.0773        float32\n",
      "   33                  model.10.cv1.conv.bias              Conv2d     False         256               [256]     -2.23      4.04        float32\n",
      "   34                model.10.cv2.conv.weight              Conv2d     False       65536    [256, 256, 1, 1] -0.000302    0.0205        float32\n",
      "   34                  model.10.cv2.conv.bias              Conv2d     False         256               [256]     -4.64      4.72        float32\n",
      "   35           model.10.attn.qkv.conv.weight              Conv2d     False       32768    [256, 128, 1, 1] -0.000139    0.0273        float32\n",
      "   35             model.10.attn.qkv.conv.bias              Conv2d     False         256               [256]     0.206      3.99        float32\n",
      "   36                   model.10.attn.qkv.act            Identity     False           0                  []         -         -              -\n",
      "   37          model.10.attn.proj.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]  1.67e-05     0.018        float32\n",
      "   37            model.10.attn.proj.conv.bias              Conv2d     False         128               [128]      1.17      6.23        float32\n",
      "   38                  model.10.attn.proj.act            Identity     False           0                  []         -         -              -\n",
      "   39            model.10.attn.pe.conv.weight              Conv2d     False        1152      [128, 1, 3, 3]  -0.00635    0.0909        float32\n",
      "   39              model.10.attn.pe.conv.bias              Conv2d     False         128               [128]    -0.444      5.31        float32\n",
      "   40                    model.10.attn.pe.act            Identity     False           0                  []         -         -              -\n",
      "   41              model.10.ffn.0.conv.weight              Conv2d     False       32768    [256, 128, 1, 1]  0.000112    0.0163        float32\n",
      "   41                model.10.ffn.0.conv.bias              Conv2d     False         256               [256]     -4.59       2.1        float32\n",
      "   42              model.10.ffn.1.conv.weight              Conv2d     False       32768    [128, 256, 1, 1] -2.72e-05   0.00495        float32\n",
      "   42                model.10.ffn.1.conv.bias              Conv2d     False         128               [128]      1.48      5.57        float32\n",
      "   43                      model.10.ffn.1.act            Identity     False           0                  []         -         -              -\n",
      "   44                                model.11            Upsample     False           0                  []         -         -              -\n",
      "   45                                model.12              Concat     False           0                  []         -         -              -\n",
      "   46                model.13.cv1.conv.weight              Conv2d     False       49152    [128, 384, 1, 1] -0.000427    0.0264        float32\n",
      "   46                  model.13.cv1.conv.bias              Conv2d     False         128               [128]     -2.95      4.15        float32\n",
      "   47                model.13.cv2.conv.weight              Conv2d     False       24576    [128, 192, 1, 1]  -0.00107    0.0477        float32\n",
      "   47                  model.13.cv2.conv.bias              Conv2d     False         128               [128]     -2.96      3.84        float32\n",
      "   48            model.13.m.0.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -0.00034    0.0229        float32\n",
      "   48              model.13.m.0.cv1.conv.bias              Conv2d     False          64                [64]     -6.39      4.07        float32\n",
      "   49            model.13.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -5.66e-05    0.0181        float32\n",
      "   49              model.13.m.0.cv2.conv.bias              Conv2d     False          64                [64]     -2.33      2.87        float32\n",
      "   50                                model.14            Upsample     False           0                  []         -         -              -\n",
      "   51                                model.15              Concat     False           0                  []         -         -              -\n",
      "   52                model.16.cv1.conv.weight              Conv2d     False       12288     [64, 192, 1, 1] -0.000224    0.0357        float32\n",
      "   52                  model.16.cv1.conv.bias              Conv2d     False          64                [64]     -2.07      4.67        float32\n",
      "   53                model.16.cv2.conv.weight              Conv2d     False        6144      [64, 96, 1, 1]  0.000616      0.06        float32\n",
      "   53                  model.16.cv2.conv.bias              Conv2d     False          64                [64]     -3.56      4.32        float32\n",
      "   54            model.16.m.0.cv1.conv.weight              Conv2d     False        9216      [32, 32, 3, 3] -0.000605    0.0289        float32\n",
      "   54              model.16.m.0.cv1.conv.bias              Conv2d     False          32                [32]     -4.12      4.79        float32\n",
      "   55            model.16.m.0.cv2.conv.weight              Conv2d     False        9216      [32, 32, 3, 3] -0.000106    0.0296        float32\n",
      "   55              model.16.m.0.cv2.conv.bias              Conv2d     False          32                [32]   -0.0327      3.66        float32\n",
      "   56                    model.17.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  0.000111    0.0104        float32\n",
      "   56                      model.17.conv.bias              Conv2d     False          64                [64]     -1.91      3.28        float32\n",
      "   57                                model.18              Concat     False           0                  []         -         -              -\n",
      "   58                model.19.cv1.conv.weight              Conv2d     False       24576    [128, 192, 1, 1]  0.000267    0.0533        float32\n",
      "   58                  model.19.cv1.conv.bias              Conv2d     False         128               [128]     -3.97      4.57        float32\n",
      "   59                model.19.cv2.conv.weight              Conv2d     False       24576    [128, 192, 1, 1] -0.000169    0.0377        float32\n",
      "   59                  model.19.cv2.conv.bias              Conv2d     False         128               [128]     -3.28      4.11        float32\n",
      "   60            model.19.m.0.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000333    0.0174        float32\n",
      "   60              model.19.m.0.cv1.conv.bias              Conv2d     False          64                [64]     -5.12      4.68        float32\n",
      "   61            model.19.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -0.00026    0.0268        float32\n",
      "   61              model.19.m.0.cv2.conv.bias              Conv2d     False          64                [64]     -1.33      2.53        float32\n",
      "   62                model.20.cv1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]  0.000253    0.0592        float32\n",
      "   62                  model.20.cv1.conv.bias              Conv2d     False         128               [128]    -0.667      4.19        float32\n",
      "   63                model.20.cv2.conv.weight              Conv2d     False        1152      [128, 1, 3, 3]    0.0113     0.223        float32\n",
      "   63                  model.20.cv2.conv.bias              Conv2d     False         128               [128]     0.151      6.29        float32\n",
      "   64                        model.20.cv2.act            Identity     False           0                  []         -         -              -\n",
      "   65                                model.21              Concat     False           0                  []         -         -              -\n",
      "   66                model.22.cv1.conv.weight              Conv2d     False       98304    [256, 384, 1, 1] -0.000151    0.0293        float32\n",
      "   66                  model.22.cv1.conv.bias              Conv2d     False         256               [256]     -3.87      4.81        float32\n",
      "   67                model.22.cv2.conv.weight              Conv2d     False       98304    [256, 384, 1, 1] -0.000182    0.0288        float32\n",
      "   67                  model.22.cv2.conv.bias              Conv2d     False         256               [256]     -4.81      4.42        float32\n",
      "   68          model.22.m.0.cv1.0.conv.weight              Conv2d     False        1152      [128, 1, 3, 3]     0.106      2.19        float32\n",
      "   68            model.22.m.0.cv1.0.conv.bias              Conv2d     False         128               [128]   -0.0337      2.17        float32\n",
      "   69          model.22.m.0.cv1.1.conv.weight              Conv2d     False       32768    [256, 128, 1, 1]  0.000546    0.0621        float32\n",
      "   69            model.22.m.0.cv1.1.conv.bias              Conv2d     False         256               [256]    -0.693      2.72        float32\n",
      "   70          model.22.m.0.cv1.2.conv.weight              Conv2d     False       12544      [256, 1, 7, 7]   0.00633     0.253        float32\n",
      "   70            model.22.m.0.cv1.2.conv.bias              Conv2d     False         256               [256]     -1.16      6.16        float32\n",
      "   71                  model.22.m.0.cv1.2.act                SiLU     False           0                  []         -         -              -\n",
      "   72          model.22.m.0.cv1.3.conv.weight              Conv2d     False       32768    [128, 256, 1, 1] -0.000809     0.041        float32\n",
      "   72            model.22.m.0.cv1.3.conv.bias              Conv2d     False         128               [128]    -0.892      3.58        float32\n",
      "   73          model.22.m.0.cv1.4.conv.weight              Conv2d     False        1152      [128, 1, 3, 3]    0.0236     0.605        float32\n",
      "   73            model.22.m.0.cv1.4.conv.bias              Conv2d     False         128               [128]      0.93      3.57        float32\n",
      "   74                          model.23.cv2.0            Identity     False           0                  []         -         -              -\n",
      "   75                model.23.dfl.conv.weight              Conv2d     False          16       [1, 16, 1, 1]       7.5      4.76        float32\n",
      "   76    model.23.one2one_cv2.0.0.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -0.00018     0.012        float32\n",
      "   76      model.23.one2one_cv2.0.0.conv.bias              Conv2d     False          64                [64]     -3.91      4.65        float32\n",
      "   77            model.23.one2one_cv2.0.0.act                SiLU     False           0                  []         -         -              -\n",
      "   78    model.23.one2one_cv2.0.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000124   0.00657        float32\n",
      "   78      model.23.one2one_cv2.0.1.conv.bias              Conv2d     False          64                [64]     -7.09      4.37        float32\n",
      "   79         model.23.one2one_cv2.0.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   0.00481    0.0853        float32\n",
      "   79           model.23.one2one_cv2.0.2.bias              Conv2d     False          64                [64]      2.04      2.27        float32\n",
      "   80    model.23.one2one_cv2.1.0.conv.weight              Conv2d     False       73728     [64, 128, 3, 3] -8.89e-05    0.0058        float32\n",
      "   80      model.23.one2one_cv2.1.0.conv.bias              Conv2d     False          64                [64]     -3.39      4.46        float32\n",
      "   81    model.23.one2one_cv2.1.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -6.99e-05   0.00617        float32\n",
      "   81      model.23.one2one_cv2.1.1.conv.bias              Conv2d     False          64                [64]     -7.07      4.66        float32\n",
      "   82         model.23.one2one_cv2.1.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   0.00316     0.113        float32\n",
      "   82           model.23.one2one_cv2.1.2.bias              Conv2d     False          64                [64]   -0.0492      2.98        float32\n",
      "   83    model.23.one2one_cv2.2.0.conv.weight              Conv2d     False      147456     [64, 256, 3, 3] -0.000195   0.00615        float32\n",
      "   83      model.23.one2one_cv2.2.0.conv.bias              Conv2d     False          64                [64]      -2.5      4.85        float32\n",
      "   84    model.23.one2one_cv2.2.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000362   0.00873        float32\n",
      "   84      model.23.one2one_cv2.2.1.conv.bias              Conv2d     False          64                [64]     -1.91      4.26        float32\n",
      "   85         model.23.one2one_cv2.2.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   -0.0316      0.32        float32\n",
      "   85           model.23.one2one_cv2.2.2.bias              Conv2d     False          64                [64]    0.0695      2.77        float32\n",
      "   86  model.23.one2one_cv3.0.0.0.conv.weight              Conv2d     False         576       [64, 1, 3, 3]   0.00761     0.649        float32\n",
      "   86    model.23.one2one_cv3.0.0.0.conv.bias              Conv2d     False          64                [64]      2.82       5.3        float32\n",
      "   87          model.23.one2one_cv3.0.0.0.act                SiLU     False           0                  []         -         -              -\n",
      "   88  model.23.one2one_cv3.0.0.1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  9.08e-05    0.0772        float32\n",
      "   88    model.23.one2one_cv3.0.0.1.conv.bias              Conv2d     False          64                [64]      0.86      5.81        float32\n",
      "   89  model.23.one2one_cv3.0.1.0.conv.weight              Conv2d     False         576       [64, 1, 3, 3]   -0.0102    0.0959        float32\n",
      "   89    model.23.one2one_cv3.0.1.0.conv.bias              Conv2d     False          64                [64]     -1.28      7.25        float32\n",
      "   90  model.23.one2one_cv3.0.1.1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  -0.00178    0.0325        float32\n",
      "   90    model.23.one2one_cv3.0.1.1.conv.bias              Conv2d     False          64                [64]     -2.64      6.37        float32\n",
      "   91         model.23.one2one_cv3.0.2.weight              Conv2d     False         576       [9, 64, 1, 1]   -0.0239     0.116        float32\n",
      "   91           model.23.one2one_cv3.0.2.bias              Conv2d     False           9                 [9]     -11.1      4.79        float32\n",
      "   92  model.23.one2one_cv3.1.0.0.conv.weight              Conv2d     False        1152      [128, 1, 3, 3]    0.0542     0.709        float32\n",
      "   92    model.23.one2one_cv3.1.0.0.conv.bias              Conv2d     False         128               [128]    0.0892      5.22        float32\n",
      "   93  model.23.one2one_cv3.1.0.1.conv.weight              Conv2d     False        8192     [64, 128, 1, 1] -0.000423    0.0492        float32\n",
      "   93    model.23.one2one_cv3.1.0.1.conv.bias              Conv2d     False          64                [64]      1.75       4.8        float32\n",
      "   94  model.23.one2one_cv3.1.1.0.conv.weight              Conv2d     False         576       [64, 1, 3, 3]  -0.00277     0.426        float32\n",
      "   94    model.23.one2one_cv3.1.1.0.conv.bias              Conv2d     False          64                [64]     -1.09      6.39        float32\n",
      "   95  model.23.one2one_cv3.1.1.1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1] -0.000354    0.0528        float32\n",
      "   95    model.23.one2one_cv3.1.1.1.conv.bias              Conv2d     False          64                [64]     -3.54      5.36        float32\n",
      "   96         model.23.one2one_cv3.1.2.weight              Conv2d     False         576       [9, 64, 1, 1]   -0.0304     0.153        float32\n",
      "   96           model.23.one2one_cv3.1.2.bias              Conv2d     False           9                 [9]     -9.24       5.6        float32\n",
      "   97  model.23.one2one_cv3.2.0.0.conv.weight              Conv2d     False        2304      [256, 1, 3, 3]     0.135      1.25        float32\n",
      "   97    model.23.one2one_cv3.2.0.0.conv.bias              Conv2d     False         256               [256]     -1.55      4.69        float32\n",
      "   98  model.23.one2one_cv3.2.0.1.conv.weight              Conv2d     False       16384     [64, 256, 1, 1] -8.81e-05    0.0345        float32\n",
      "   98    model.23.one2one_cv3.2.0.1.conv.bias              Conv2d     False          64                [64]      1.81      4.01        float32\n",
      "   99  model.23.one2one_cv3.2.1.0.conv.weight              Conv2d     False         576       [64, 1, 3, 3]   0.00355     0.412        float32\n",
      "   99    model.23.one2one_cv3.2.1.0.conv.bias              Conv2d     False          64                [64]     -2.86      5.57        float32\n",
      "  100  model.23.one2one_cv3.2.1.1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]   -0.0087     0.253        float32\n",
      "  100    model.23.one2one_cv3.2.1.1.conv.bias              Conv2d     False          64                [64]      2.21      8.69        float32\n",
      "  101         model.23.one2one_cv3.2.2.weight              Conv2d     False         576       [9, 64, 1, 1]    -0.171     0.338        float32\n",
      "  101           model.23.one2one_cv3.2.2.bias              Conv2d     False           9                 [9]     -4.32      1.15        float32\n",
      "YOLOv10n summary (fused): 102 layers, 2,266,923 parameters, 0 gradients, 6.5 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# 3. Î™®Îç∏Î≥Ñ, Ï¶ùÍ∞ï ÏòµÏÖòÎ≥Ñ ÌïôÏäµ, Í≤ÄÏ¶ù Î∞è Í≤∞Í≥º Î∂ÑÏÑù\n",
    "# --------------------------------------------------------------------------\n",
    "all_results_summary = []\n",
    "\n",
    "for model_name in MODELS_TO_TEST:\n",
    "    for augment_status in AUGMENT_OPTIONS:\n",
    "        \n",
    "        run_name = f'train_{model_name}_aug_{augment_status}'\n",
    "        display_name = f'{model_name} (Aug: {augment_status})'\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"üöÄ STARTING EXPERIMENT FOR MODEL: {display_name}\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "        # 1. Î™®Îç∏ ÌïôÏäµ\n",
    "        model = YOLO(f\"{model_name}.pt\")\n",
    "        model.train(\n",
    "            data=data_yaml_path, epochs=EPOCHS, batch=BATCH_SIZE, imgsz=IMG_SIZE,\n",
    "            device=DEVICE, project=MODEL_SAVE_DIR, name=run_name,\n",
    "            exist_ok=True, save=True, pretrained=True, \n",
    "            augment=augment_status, plots=True, optimizer=OPTIMIZER\n",
    "        )\n",
    "\n",
    "        # 2. Í∞ÄÏû• ÏÑ±Îä• Ï¢ãÏùÄ Î™®Îç∏ Î°úÎìú\n",
    "        best_model_path = os.path.join(MODEL_SAVE_DIR, run_name, 'weights', 'best.pt')\n",
    "        best_model = YOLO(best_model_path)\n",
    "\n",
    "        # 3. Î™®Îç∏ ÏÑ±Îä• Í≤ÄÏ¶ù\n",
    "        val_results = best_model.val(\n",
    "            data=data_yaml_path, split='val', batch=BATCH_SIZE,\n",
    "            imgsz=IMG_SIZE, device=DEVICE, plots=True\n",
    "        )\n",
    "        \n",
    "        # ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ [ Ïã†Í∑ú Ï∂îÍ∞ÄÎêú Î∂ÄÎ∂Ñ ] ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ\n",
    "        # 4. ÌïôÏäµ Í≥ºÏ†ï Î∞è ÌÅ¥ÎûòÏä§Î≥Ñ ÏÑ±Îä• ÏãúÍ∞ÅÌôî\n",
    "        print(\"\\n\" + \"-\"*50)\n",
    "        print(f\"üìà VISUALIZING TRAINING & VALIDATION ANALYSIS FOR: {display_name}\")\n",
    "        print(\"-\"*50)\n",
    "        \n",
    "        # 2Í∞úÏùò Í∑∏ÎûòÌîÑÎ•º ÎÇòÎûÄÌûà Í∑∏Î¶¥ ÎèÑÌôîÏßÄ Ï§ÄÎπÑ\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "        fig.suptitle(f'Analysis for {display_name}', fontsize=16, weight='bold')\n",
    "\n",
    "        # 4-1. ÌïôÏäµ Í≥ºÏ†ï Í∑∏ÎûòÌîÑ (results.png) Î∂àÎü¨Ïò§Í∏∞\n",
    "        results_png_path = os.path.join(MODEL_SAVE_DIR, run_name, 'results.png')\n",
    "        if os.path.exists(results_png_path):\n",
    "            img_results = cv2.imread(results_png_path)\n",
    "            axes[0].imshow(cv2.cvtColor(img_results, cv2.COLOR_BGR2RGB))\n",
    "            axes[0].set_title('Training & Validation Curves')\n",
    "            axes[0].axis('off')\n",
    "        else:\n",
    "            axes[0].text(0.5, 0.5, 'results.png not found', ha='center'); axes[0].axis('off')\n",
    "\n",
    "        # 4-2. ÌÅ¥ÎûòÏä§Î≥Ñ ÌòºÎèô ÌñâÎ†¨ (confusion_matrix.png) Î∂àÎü¨Ïò§Í∏∞\n",
    "        cm_png_path = os.path.join(MODEL_SAVE_DIR, run_name, 'confusion_matrix.png')\n",
    "        if os.path.exists(cm_png_path):\n",
    "            img_cm = cv2.imread(cm_png_path)\n",
    "            axes[1].imshow(cv2.cvtColor(img_cm, cv2.COLOR_BGR2RGB))\n",
    "            axes[1].set_title('Confusion Matrix')\n",
    "            axes[1].axis('off')\n",
    "        else:\n",
    "            axes[1].text(0.5, 0.5, 'confusion_matrix.png not found', ha='center'); axes[1].axis('off')\n",
    "            \n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()        \n",
    "\n",
    "        # 5. ÏµúÏ¢Ö ÌèâÍ∞Ä ÏßÄÌëú Ï∂îÏ∂ú\n",
    "        print(\"\\n\" + \"-\"*50)\n",
    "        print(f\"üìä EXTRACTING PERFORMANCE INDICATORS FOR: {display_name}\")\n",
    "        print(\"-\"*50)\n",
    "        \n",
    "        map50 = val_results.box.map50\n",
    "        precision = val_results.box.p.mean()\n",
    "        recall = val_results.box.r.mean()\n",
    "        \n",
    "        speed = val_results.speed\n",
    "        latency_ms = speed['preprocess'] + speed['inference'] + speed['postprocess']\n",
    "        \n",
    "        info = model_info(best_model.model, detailed=True, imgsz=IMG_SIZE)\n",
    "        params_m = info[1] / 1e6 \n",
    "        gflops = info[3]\n",
    "\n",
    "        # 6. ÌÜµÌï© Í≤∞Í≥º Î¶¨Ïä§Ìä∏Ïóê Ï∂îÍ∞Ä\n",
    "        all_results_summary.append({\n",
    "            \"Model\": display_name, \"mAP@50\": map50, \"Precision\": precision,\n",
    "            \"Recall\": recall, \"Latency (ms)\": latency_ms,\n",
    "            \"Parameters (M)\": params_m, \"GFLOPs\": gflops\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8016889-c180-4ef9-a489-72cf0199b614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üèÜ FINAL RESULTS SUMMARY FOR ALL MODELS üèÜ\n",
      "============================================================\n",
      "\n",
      "                      mAP@50 Precision Recall Latency (ms) Parameters (M) GFLOPs\n",
      "Model                                                                           \n",
      "yolov8n (Aug: True)    0.712     0.668  0.636         2.00           3.01   8.09\n",
      "yolov8n (Aug: False)   0.709     0.677  0.619         2.04           3.01   8.09\n",
      "yolov5n (Aug: True)    0.683     0.650  0.621         2.17           2.50   7.07\n",
      "yolov5n (Aug: False)   0.683     0.650  0.621         2.02           2.50   7.07\n",
      "yolov10n (Aug: False)  0.654     0.592  0.611         1.15           2.27   6.54\n",
      "yolov10n (Aug: True)   0.650     0.587  0.604         1.38           2.27   6.54\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# 4. Î™®Îì† Î™®Îç∏ Ïã§Ìóò Í≤∞Í≥º ÌÜµÌï© ÎπÑÍµê Î∂ÑÏÑù\n",
    "# --------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üèÜ FINAL RESULTS SUMMARY FOR ALL MODELS üèÜ\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "summary_df = pd.DataFrame(all_results_summary).set_index(\"Model\")\n",
    "print(summary_df.sort_values(by=\"mAP@50\", ascending=False).to_string(formatters={\n",
    "    'mAP@50': '{:.3f}'.format, 'Precision': '{:.3f}'.format, 'Recall': '{:.3f}'.format,\n",
    "    'Latency (ms)': '{:.2f}'.format, 'Parameters (M)': '{:.2f}'.format, 'GFLOPs': '{:.2f}'.format\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e176afbd-68ad-4929-8789-cce9544ac615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================================================\n",
      "üìà VISUALIZING PERFORMANCE COMPARISON üìà\n",
      "============================================================\n",
      "\n",
      "\n",
      "Accuracy vs. Latency tradeoff plot saved to 'tradeoff_plot.png'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual performance comparison plots saved to 'comparison_plots.png'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "üéâ All experiments completed.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# 5. ÏÑ±Îä• ÏßÄÌëú ÏãúÍ∞ÅÌôî\n",
    "# --------------------------------------------------------------------------\n",
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"üìà VISUALIZING PERFORMANCE COMPARISON üìà\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# 1. Ï†ïÌôïÎèÑ/ÏÜçÎèÑ Ìä∏Î†àÏù¥ÎìúÏò§ÌîÑ ÏãúÍ∞ÅÌôî (Scatter Plot)\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    data=summary_df, x=\"Latency (ms)\", y=\"mAP@50\",\n",
    "    hue=\"Model\", size=\"Parameters (M)\", sizes=(100, 1000),\n",
    "    alpha=0.8, palette=\"viridis\", ax=ax\n",
    ")\n",
    "ax.set_title(\"Accuracy vs. Latency Trade-off\", fontsize=18, weight='bold')\n",
    "ax.set_xlabel(\"Latency (ms) - Lower is Faster\", fontsize=12)\n",
    "ax.set_ylabel(\"mAP@50 - Higher is Better\", fontsize=12)\n",
    "ax.legend(title=\"Model\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "for i, row in summary_df.iterrows():\n",
    "    ax.text(row['Latency (ms)']+0.1, row['mAP@50'], i, fontsize=9, ha='left')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ [ Ïã†Í∑ú Ï∂îÍ∞ÄÎêú Î∂ÄÎ∂Ñ ] ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ\n",
    "# ÌòÑÏû¨ Í∑∏Î¶ºÏùÑ ÌååÏùºÎ°ú Ï†ÄÏû• (plt.show() Ïù¥Ï†ÑÏóê Ìò∏Ï∂ú)\n",
    "plt.savefig('tradeoff_plot.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\nAccuracy vs. Latency tradeoff plot saved to 'tradeoff_plot.png'\")\n",
    "# ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ [ Ïó¨Í∏∞ÍπåÏßÄ Ïã†Í∑ú Ï∂îÍ∞ÄÎêú Î∂ÄÎ∂Ñ ] ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 2. Í∞úÎ≥Ñ ÏÑ±Îä• ÏßÄÌëú ÎπÑÍµê (Bar Plots)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
    "fig.suptitle('Individual Performance Indicator Comparison', fontsize=20, weight='bold')\n",
    "metrics_to_plot = [\"mAP@50\", \"Latency (ms)\", \"Parameters (M)\", \"GFLOPs\"]\n",
    "for ax, metric in zip(axes.flatten(), metrics_to_plot):\n",
    "    ascending = True if \"Latency\" in metric or \"Parameters\" in metric or \"GFLOPs\" in metric else False\n",
    "    sorted_df = summary_df.sort_values(by=metric, ascending=ascending)\n",
    "    colors = plt.cm.plasma(np.linspace(0, 1, len(sorted_df)))\n",
    "    bars = ax.barh(sorted_df.index, sorted_df[metric], color=colors)\n",
    "    ax.set_title(metric, fontsize=14)\n",
    "    ax.set_xlabel(\"Value\", fontsize=12)\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        ax.text(width * 1.01, bar.get_y() + bar.get_height()/2., f'{width:.2f}',\n",
    "                va='center', ha='left', fontsize=10)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "# ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ [ Ïã†Í∑ú Ï∂îÍ∞ÄÎêú Î∂ÄÎ∂Ñ ] ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ\n",
    "# ÌòÑÏû¨ Í∑∏Î¶ºÏùÑ ÌååÏùºÎ°ú Ï†ÄÏû• (plt.show() Ïù¥Ï†ÑÏóê Ìò∏Ï∂ú)\n",
    "plt.savefig('comparison_plots.png', dpi=300)\n",
    "print(\"Individual performance comparison plots saved to 'comparison_plots.png'\")\n",
    "# ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ [ Ïó¨Í∏∞ÍπåÏßÄ Ïã†Í∑ú Ï∂îÍ∞ÄÎêú Î∂ÄÎ∂Ñ ] ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\\nüéâ All experiments completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GraduationThesis",
   "language": "python",
   "name": "graduationthesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
