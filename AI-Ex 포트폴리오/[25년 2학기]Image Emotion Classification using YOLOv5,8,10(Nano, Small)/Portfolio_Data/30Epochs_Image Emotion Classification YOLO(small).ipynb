{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4920f6d-a0b9-48d9-9178-072a257a302f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: 0\n",
      "Dataset classes: ['angry', 'contempt', 'disgust', 'fear', 'happy', 'natural', 'sad', 'sleepy', 'surprised']\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# 1. ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏûÑÌè¨Ìä∏ Î∞è Í∏∞Î≥∏ ÏÑ§Ï†ï\n",
    "# --------------------------------------------------------------------------\n",
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics.utils.torch_utils import model_info\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 2. Ïã§Ìóò ÌôòÍ≤Ω Î∞è ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "# Ïã§Ìóò ÎåÄÏÉÅ Î™®Îç∏ Î¶¨Ïä§Ìä∏\n",
    "MODELS_TO_TEST = ['yolov5s', 'yolov8s', 'yolov10s']\n",
    "# Îç∞Ïù¥ÌÑ∞ Ï¶ùÍ∞ï ÏòµÏÖò Î¶¨Ïä§Ìä∏\n",
    "AUGMENT_OPTIONS = [True, False]\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î∞è Î™®Îç∏ Ï†ÄÏû• Í≤ΩÎ°ú (ÏÇ¨Ïö©Ïûê ÌôòÍ≤ΩÏóê ÎßûÍ≤å ÏàòÏ†ï)\n",
    "DATA_PATH = r\"D:\\Virtual_Fahion\\GraduationThesis2_NS\\data\"\n",
    "MODEL_SAVE_DIR = r\"D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\"\n",
    "\n",
    "# ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 16\n",
    "IMG_SIZE = 640\n",
    "OPTIMIZER = 'Adam'\n",
    "\n",
    "# GPU ÏÑ§Ï†ï\n",
    "DEVICE = '0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ YAML ÌååÏùº Î°úÎìú\n",
    "data_yaml_path = os.path.join(DATA_PATH, 'data.yaml')\n",
    "with open(data_yaml_path) as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "print(f\"Dataset classes: {data_config['names']}\")\n",
    "\n",
    "# F1-Score Í≥ÑÏÇ∞ Ìï®Ïàò\n",
    "def calculate_f1_score(precision, recall):\n",
    "    return 2 * (precision * recall) / (precision + recall + 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d4b8803-a1fd-4d69-8589-3ae79fd7533c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üöÄ STARTING EXPERIMENT FOR MODEL: yolov5s (Aug: True)\n",
      "============================================================\n",
      "\n",
      "PRO TIP  Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov5su.pt to 'yolov5su.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 17.7MB 49.2MB/s 0.4s0.3s<0.7s\n",
      "New https://pypi.org/project/ultralytics/8.3.204 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=D:\\Virtual_Fahion\\GraduationThesis2_NS\\data\\data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train_yolov5s_aug_True, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov5s_aug_True, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \n",
      " 24        [17, 20, 23]  1   2119531  ultralytics.nn.modules.head.Detect           [9, [128, 256, 512]]          \n",
      "YOLOv5s summary: 153 layers, 9,125,675 parameters, 9,125,659 gradients, 24.1 GFLOPs\n",
      "\n",
      "Transferred 421/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.4MB 68.6MB/s 0.1s\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 20.833.6 MB/s, size: 67.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2_NS\\data\\train\\labels.cache... 64864 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 64864/64864 64.9Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 7.71.4 MB/s, size: 43.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2_NS\\data\\valid\\labels.cache... 1720 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1720/1720 1.7Mit/s 0.0s\n",
      "Plotting labels to D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov5s_aug_True\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov5s_aug_True\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/30      3.53G      1.293       2.17      1.647         48        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 15.0it/s 4:30<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.7it/s 4.3s0.1s\n",
      "                   all       1720       1720      0.168      0.396      0.201     0.0921\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/30      4.28G      1.197       1.98      1.557         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 15.9it/s 4:15<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.289      0.411      0.304      0.187\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/30      4.28G      1.143      1.875      1.513         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.4it/s 4:07<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.1it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.339      0.483       0.37      0.235\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/30      4.28G      1.103      1.779      1.485         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:02<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.9it/s 4.2s0.2s\n",
      "                   all       1720       1720      0.426      0.452      0.436      0.283\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/30      4.28G      1.076      1.718      1.464         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.6it/s 4:04<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.4it/s 4.0s0.1s\n",
      "                   all       1720       1720      0.406      0.528      0.457      0.305\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/30      4.28G      1.048      1.668      1.446         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.6it/s 4:05<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.1s0.1s\n",
      "                   all       1720       1720      0.453      0.531        0.5      0.333\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/30      4.28G      1.035      1.632      1.437         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:01<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.4it/s 4.0s0.2s\n",
      "                   all       1720       1720      0.459      0.517      0.516      0.352\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/30      4.28G      1.029      1.602      1.433         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.6it/s 4:05<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.2it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.462      0.566      0.528      0.367\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/30      4.28G       1.02      1.576      1.425         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.6it/s 4:05<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.4it/s 4.0s0.1s\n",
      "                   all       1720       1720       0.49      0.569      0.549       0.38\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/30      4.28G       1.01       1.56      1.417         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:01<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.1it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.484      0.581      0.557      0.385\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/30      4.28G      1.004      1.537      1.416         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.6it/s 4:04<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.5it/s 4.0s0.1s\n",
      "                   all       1720       1720      0.526      0.569      0.571      0.398\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/30      4.28G     0.9937       1.52      1.408         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.6it/s 4:04<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.4it/s 4.0s0.2s\n",
      "                   all       1720       1720       0.53      0.572      0.585      0.406\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/30      4.28G     0.9876      1.501      1.403         43        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.7it/s 4:03<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.8it/s 4.2s0.1s\n",
      "                   all       1720       1720      0.526      0.583      0.589      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/30      4.28G     0.9817      1.482      1.398         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.7it/s 4:03<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.1s0.1s\n",
      "                   all       1720       1720      0.544      0.581      0.594      0.416\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/30      4.28G     0.9733      1.468      1.392         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.7it/s 4:03<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.551      0.593      0.599       0.42\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/30      4.28G     0.9681      1.458       1.39         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.6it/s 4:04<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.4it/s 4.0s0.2s\n",
      "                   all       1720       1720      0.557      0.589      0.605      0.425\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/30      4.28G     0.9642      1.444      1.386         37        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:01<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.6it/s 4.0s0.1s\n",
      "                   all       1720       1720      0.555      0.601      0.608      0.428\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/30      4.28G     0.9566      1.427      1.382         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.7it/s 4:03<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.1it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.565      0.595      0.611      0.431\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/30      4.28G     0.9503      1.409      1.377         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.7it/s 4:02<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.1it/s 4.1s0.1s\n",
      "                   all       1720       1720      0.566      0.594      0.614      0.434\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/30      4.28G      0.946      1.398      1.371         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:01<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.6it/s 4.0s0.1s\n",
      "                   all       1720       1720      0.574      0.594      0.617      0.436\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/30      4.28G      0.954      1.179      1.544         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:01<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.4it/s 4.0s0.1s\n",
      "                   all       1720       1720       0.58      0.588      0.621      0.441\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/30      4.28G     0.9283      1.132      1.517         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:01<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.4it/s 4.0s0.1s\n",
      "                   all       1720       1720      0.571      0.604      0.625      0.445\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/30      4.28G     0.9094      1.104      1.499         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 17.0it/s 3:59<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.4it/s 4.0s0.1s\n",
      "                   all       1720       1720      0.572      0.597       0.63      0.451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/30      4.28G     0.8975      1.077      1.486         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.7it/s 4:02<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.4it/s 4.0s0.1s\n",
      "                   all       1720       1720      0.575      0.606      0.635      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/30      4.28G     0.8835      1.054      1.472         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.7it/s 4:03<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.2it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.583      0.604      0.641       0.46\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/30      4.28G     0.8694      1.026      1.458         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.9it/s 3:60<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.1s0.1s\n",
      "                   all       1720       1720      0.586       0.61      0.644      0.465\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/30      4.28G     0.8615     0.9981      1.451         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.9it/s 4:00<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.1s0.1s\n",
      "                   all       1720       1720      0.595      0.614      0.647      0.469\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/30      4.28G     0.8484       0.97      1.436         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.9it/s 4:00<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.4it/s 4.0s0.1s\n",
      "                   all       1720       1720      0.598      0.625       0.65      0.474\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/30      4.28G      0.837     0.9418      1.426         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.9it/s 3:59<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.8it/s 4.2s0.1s\n",
      "                   all       1720       1720       0.61      0.617      0.655      0.479\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/30      4.28G     0.8253     0.9189      1.415         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.9it/s 4:00<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.4it/s 4.0s0.2s\n",
      "                   all       1720       1720      0.613      0.613      0.658      0.482\n",
      "\n",
      "30 epochs completed in 2.078 hours.\n",
      "Optimizer stripped from D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov5s_aug_True\\weights\\last.pt, 18.5MB\n",
      "Optimizer stripped from D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov5s_aug_True\\weights\\best.pt, 18.5MB\n",
      "\n",
      "Validating D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov5s_aug_True\\weights\\best.pt...\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "YOLOv5s summary (fused): 84 layers, 9,115,019 parameters, 0 gradients, 23.8 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.4it/s 6.5s0.1s\n",
      "                   all       1720       1720      0.615       0.61      0.671      0.502\n",
      "                 angry        258        258      0.543      0.585      0.664      0.509\n",
      "              contempt         82         82      0.566      0.561      0.656      0.546\n",
      "               disgust        108        108       0.66      0.444      0.656      0.567\n",
      "                  fear        107        107      0.525      0.753      0.651      0.524\n",
      "                 happy        387        387      0.796      0.824      0.891      0.672\n",
      "               natural        172        172      0.575      0.378      0.514      0.343\n",
      "                   sad        312        312      0.502      0.689       0.64      0.439\n",
      "                sleepy         38         38      0.696      0.526      0.601       0.34\n",
      "             surprised        256        256      0.671      0.725      0.767      0.577\n",
      "Speed: 0.2ms preprocess, 1.8ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov5s_aug_True\u001b[0m\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "YOLOv5s summary (fused): 84 layers, 9,115,019 parameters, 0 gradients, 23.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 1504.71350.7 MB/s, size: 80.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2_NS\\data\\valid\\labels.cache... 1720 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1720/1720 1.4Mit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 108/108 21.2it/s 5.1s0.1s\n",
      "                   all       1720       1720      0.615      0.613      0.659      0.483\n",
      "                 angry        258        258      0.543      0.593      0.664      0.493\n",
      "              contempt         82         82      0.502      0.542      0.602      0.502\n",
      "               disgust        108        108      0.685      0.484       0.63      0.525\n",
      "                  fear        107        107      0.517      0.757      0.631      0.502\n",
      "                 happy        387        387       0.79      0.832      0.895      0.662\n",
      "               natural        172        172      0.527      0.421      0.493      0.341\n",
      "                   sad        312        312      0.521      0.663      0.636      0.413\n",
      "                sleepy         38         38      0.804        0.5      0.611      0.333\n",
      "             surprised        256        256      0.646      0.723      0.768      0.572\n",
      "Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2_NS\\runs\\detect\\val\u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "üìà VISUALIZING TRAINING & VALIDATION ANALYSIS FOR: yolov5s (Aug: True)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "üìä EXTRACTING PERFORMANCE INDICATORS FOR: yolov5s (Aug: True)\n",
      "--------------------------------------------------\n",
      "layer                                    name                type  gradient  parameters               shape        mu     sigma\n",
      "    0                     model.0.conv.weight              Conv2d     False        3456       [32, 3, 6, 6]  -0.00412      1.48        float32\n",
      "    0                       model.0.conv.bias              Conv2d     False          32                [32]     -1.59      6.18        float32\n",
      "    1                             model.0.act                SiLU     False           0                  []         -         -              -\n",
      "    2                     model.1.conv.weight              Conv2d     False       18432      [64, 32, 3, 3] -0.000799    0.0663        float32\n",
      "    2                       model.1.conv.bias              Conv2d     False          64                [64]    -0.822      5.46        float32\n",
      "    3                 model.2.cv1.conv.weight              Conv2d     False        2048      [32, 64, 1, 1]  -0.00105    0.0565        float32\n",
      "    3                   model.2.cv1.conv.bias              Conv2d     False          32                [32]      0.95      4.63        float32\n",
      "    4                 model.2.cv2.conv.weight              Conv2d     False        2048      [32, 64, 1, 1]  -0.00727    0.0893        float32\n",
      "    4                   model.2.cv2.conv.bias              Conv2d     False          32                [32]     0.912      4.62        float32\n",
      "    5                 model.2.cv3.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  -0.00715    0.0902        float32\n",
      "    5                   model.2.cv3.conv.bias              Conv2d     False          64                [64]     -1.57      6.06        float32\n",
      "    6             model.2.m.0.cv1.conv.weight              Conv2d     False        1024      [32, 32, 1, 1]  -0.00969     0.179        float32\n",
      "    6               model.2.m.0.cv1.conv.bias              Conv2d     False          32                [32]     -1.07      4.11        float32\n",
      "    7             model.2.m.0.cv2.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00101    0.0693        float32\n",
      "    7               model.2.m.0.cv2.conv.bias              Conv2d     False          32                [32]     0.128      5.35        float32\n",
      "    8                     model.3.conv.weight              Conv2d     False       73728     [128, 64, 3, 3]  0.000196    0.0163        float32\n",
      "    8                       model.3.conv.bias              Conv2d     False         128               [128]    -0.983       3.3        float32\n",
      "    9                 model.4.cv1.conv.weight              Conv2d     False        8192     [64, 128, 1, 1] -0.000139    0.0287        float32\n",
      "    9                   model.4.cv1.conv.bias              Conv2d     False          64                [64]      1.17      4.72        float32\n",
      "   10                 model.4.cv2.conv.weight              Conv2d     False        8192     [64, 128, 1, 1]  -0.00103     0.104        float32\n",
      "   10                   model.4.cv2.conv.bias              Conv2d     False          64                [64]     0.108      4.13        float32\n",
      "   11                 model.4.cv3.conv.weight              Conv2d     False       16384    [128, 128, 1, 1] -0.000235    0.0604        float32\n",
      "   11                   model.4.cv3.conv.bias              Conv2d     False         128               [128]     -4.97      4.89        float32\n",
      "   12             model.4.m.0.cv1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1] -0.000138     0.109        float32\n",
      "   12               model.4.m.0.cv1.conv.bias              Conv2d     False          64                [64]     -3.57      5.36        float32\n",
      "   13             model.4.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -6.73e-05    0.0124        float32\n",
      "   13               model.4.m.0.cv2.conv.bias              Conv2d     False          64                [64]    -0.702      3.94        float32\n",
      "   14             model.4.m.1.cv1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]   -0.0046     0.114        float32\n",
      "   14               model.4.m.1.cv1.conv.bias              Conv2d     False          64                [64]     -2.93      6.21        float32\n",
      "   15             model.4.m.1.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000856    0.0398        float32\n",
      "   15               model.4.m.1.cv2.conv.bias              Conv2d     False          64                [64]    -0.551      3.74        float32\n",
      "   16                     model.5.conv.weight              Conv2d     False      294912    [256, 128, 3, 3]   4.1e-05   0.00935        float32\n",
      "   16                       model.5.conv.bias              Conv2d     False         256               [256]     -2.69      3.46        float32\n",
      "   17                 model.6.cv1.conv.weight              Conv2d     False       32768    [128, 256, 1, 1] -0.000201    0.0169        float32\n",
      "   17                   model.6.cv1.conv.bias              Conv2d     False         128               [128]     -0.38      4.34        float32\n",
      "   18                 model.6.cv2.conv.weight              Conv2d     False       32768    [128, 256, 1, 1]  0.000486    0.0505        float32\n",
      "   18                   model.6.cv2.conv.bias              Conv2d     False         128               [128]     -2.28      3.48        float32\n",
      "   19                 model.6.cv3.conv.weight              Conv2d     False       65536    [256, 256, 1, 1] -0.000563    0.0254        float32\n",
      "   19                   model.6.cv3.conv.bias              Conv2d     False         256               [256]     -6.48      5.13        float32\n",
      "   20             model.6.m.0.cv1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]  0.000399    0.0481        float32\n",
      "   20               model.6.m.0.cv1.conv.bias              Conv2d     False         128               [128]     -6.09      4.26        float32\n",
      "   21             model.6.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -6.64e-06   0.00535        float32\n",
      "   21               model.6.m.0.cv2.conv.bias              Conv2d     False         128               [128]     -2.02      3.66        float32\n",
      "   22             model.6.m.1.cv1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]  -0.00141     0.067        float32\n",
      "   22               model.6.m.1.cv1.conv.bias              Conv2d     False         128               [128]     -6.32      5.25        float32\n",
      "   23             model.6.m.1.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -6.59e-05    0.0174        float32\n",
      "   23               model.6.m.1.cv2.conv.bias              Conv2d     False         128               [128]     -2.34      3.42        float32\n",
      "   24             model.6.m.2.cv1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]  -0.00174    0.0556        float32\n",
      "   24               model.6.m.2.cv1.conv.bias              Conv2d     False         128               [128]     -6.29       5.5        float32\n",
      "   25             model.6.m.2.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -0.000315    0.0217        float32\n",
      "   25               model.6.m.2.cv2.conv.bias              Conv2d     False         128               [128]     -2.94      3.77        float32\n",
      "   26                     model.7.conv.weight              Conv2d     False 1.17965e+06    [512, 256, 3, 3]  1.24e-05    0.0046        float32\n",
      "   26                       model.7.conv.bias              Conv2d     False         512               [512]     -4.03      3.68        float32\n",
      "   27                 model.8.cv1.conv.weight              Conv2d     False      131072    [256, 512, 1, 1]     1e-05     0.006        float32\n",
      "   27                   model.8.cv1.conv.bias              Conv2d     False         256               [256]     -4.27      4.04        float32\n",
      "   28                 model.8.cv2.conv.weight              Conv2d     False      131072    [256, 512, 1, 1] -4.12e-06   0.00822        float32\n",
      "   28                   model.8.cv2.conv.bias              Conv2d     False         256               [256]     -4.98      3.84        float32\n",
      "   29                 model.8.cv3.conv.weight              Conv2d     False      262144    [512, 512, 1, 1] -0.000118    0.0176        float32\n",
      "   29                   model.8.cv3.conv.bias              Conv2d     False         512               [512]     -3.94      3.76        float32\n",
      "   30             model.8.m.0.cv1.conv.weight              Conv2d     False       65536    [256, 256, 1, 1] -0.000341    0.0456        float32\n",
      "   30               model.8.m.0.cv1.conv.bias              Conv2d     False         256               [256]      -7.2      4.57        float32\n",
      "   31             model.8.m.0.cv2.conv.weight              Conv2d     False      589824    [256, 256, 3, 3]  -3.6e-05   0.00447        float32\n",
      "   31               model.8.m.0.cv2.conv.bias              Conv2d     False         256               [256]     -4.69      3.72        float32\n",
      "   32                 model.9.cv1.conv.weight              Conv2d     False      131072    [256, 512, 1, 1] -0.000726    0.0179        float32\n",
      "   32                   model.9.cv1.conv.bias              Conv2d     False         256               [256]     -2.99      6.24        float32\n",
      "   33                 model.9.cv2.conv.weight              Conv2d     False      524288   [512, 1024, 1, 1]   2.1e-05   0.00982        float32\n",
      "   33                   model.9.cv2.conv.bias              Conv2d     False         512               [512]     -5.01       4.5        float32\n",
      "   34                               model.9.m           MaxPool2d     False           0                  []         -         -              -\n",
      "   35                    model.10.conv.weight              Conv2d     False      131072    [256, 512, 1, 1]  -0.00135    0.0525        float32\n",
      "   35                      model.10.conv.bias              Conv2d     False         256               [256]     -3.99      4.61        float32\n",
      "   36                                model.11            Upsample     False           0                  []         -         -              -\n",
      "   37                                model.12              Concat     False           0                  []         -         -              -\n",
      "   38                model.13.cv1.conv.weight              Conv2d     False       65536    [128, 512, 1, 1] -0.000139    0.0229        float32\n",
      "   38                  model.13.cv1.conv.bias              Conv2d     False         128               [128]     -2.92      4.27        float32\n",
      "   39                model.13.cv2.conv.weight              Conv2d     False       65536    [128, 512, 1, 1] -0.000234     0.026        float32\n",
      "   39                  model.13.cv2.conv.bias              Conv2d     False         128               [128]     -3.98      3.84        float32\n",
      "   40                model.13.cv3.conv.weight              Conv2d     False       65536    [256, 256, 1, 1]  -1.8e-05    0.0282        float32\n",
      "   40                  model.13.cv3.conv.bias              Conv2d     False         256               [256]     -3.87      4.05        float32\n",
      "   41            model.13.m.0.cv1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1] -0.000232      0.11        float32\n",
      "   41              model.13.m.0.cv1.conv.bias              Conv2d     False         128               [128]     -5.82      4.97        float32\n",
      "   42            model.13.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -2.14e-05   0.00344        float32\n",
      "   42              model.13.m.0.cv2.conv.bias              Conv2d     False         128               [128]     -3.54      3.47        float32\n",
      "   43                    model.14.conv.weight              Conv2d     False       32768    [128, 256, 1, 1] -4.21e-05   0.00916        float32\n",
      "   43                      model.14.conv.bias              Conv2d     False         128               [128]     -2.48      4.87        float32\n",
      "   44                                model.15            Upsample     False           0                  []         -         -              -\n",
      "   45                                model.16              Concat     False           0                  []         -         -              -\n",
      "   46                model.17.cv1.conv.weight              Conv2d     False       16384     [64, 256, 1, 1]  0.000454    0.0279        float32\n",
      "   46                  model.17.cv1.conv.bias              Conv2d     False          64                [64]     -1.87      3.87        float32\n",
      "   47                model.17.cv2.conv.weight              Conv2d     False       16384     [64, 256, 1, 1]  0.000248    0.0357        float32\n",
      "   47                  model.17.cv2.conv.bias              Conv2d     False          64                [64]      1.91      5.63        float32\n",
      "   48                model.17.cv3.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]  6.68e-05    0.0416        float32\n",
      "   48                  model.17.cv3.conv.bias              Conv2d     False         128               [128]     -4.58      4.47        float32\n",
      "   49            model.17.m.0.cv1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  0.000739    0.0471        float32\n",
      "   49              model.17.m.0.cv1.conv.bias              Conv2d     False          64                [64]     -5.43      4.92        float32\n",
      "   50            model.17.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -8.51e-05     0.012        float32\n",
      "   50              model.17.m.0.cv2.conv.bias              Conv2d     False          64                [64]     -0.89      3.91        float32\n",
      "   51                    model.18.conv.weight              Conv2d     False      147456    [128, 128, 3, 3]  1.69e-05   0.00497        float32\n",
      "   51                      model.18.conv.bias              Conv2d     False         128               [128]     -2.78         4        float32\n",
      "   52                                model.19              Concat     False           0                  []         -         -              -\n",
      "   53                model.20.cv1.conv.weight              Conv2d     False       32768    [128, 256, 1, 1]  0.000401    0.0371        float32\n",
      "   53                  model.20.cv1.conv.bias              Conv2d     False         128               [128]     -2.76      3.51        float32\n",
      "   54                model.20.cv2.conv.weight              Conv2d     False       32768    [128, 256, 1, 1]  0.000288    0.0321        float32\n",
      "   54                  model.20.cv2.conv.bias              Conv2d     False         128               [128]     -2.12      4.62        float32\n",
      "   55                model.20.cv3.conv.weight              Conv2d     False       65536    [256, 256, 1, 1] -1.07e-05    0.0197        float32\n",
      "   55                  model.20.cv3.conv.bias              Conv2d     False         256               [256]     -6.13      4.17        float32\n",
      "   56            model.20.m.0.cv1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]  0.000146    0.0348        float32\n",
      "   56              model.20.m.0.cv1.conv.bias              Conv2d     False         128               [128]     -4.34      4.78        float32\n",
      "   57            model.20.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -4.23e-05   0.00581        float32\n",
      "   57              model.20.m.0.cv2.conv.bias              Conv2d     False         128               [128]     -2.73      3.31        float32\n",
      "   58                    model.21.conv.weight              Conv2d     False      589824    [256, 256, 3, 3]  2.44e-05   0.00312        float32\n",
      "   58                      model.21.conv.bias              Conv2d     False         256               [256]     -5.98         3        float32\n",
      "   59                                model.22              Concat     False           0                  []         -         -              -\n",
      "   60                model.23.cv1.conv.weight              Conv2d     False      131072    [256, 512, 1, 1]  3.15e-05    0.0289        float32\n",
      "   60                  model.23.cv1.conv.bias              Conv2d     False         256               [256]      -3.2      4.59        float32\n",
      "   61                model.23.cv2.conv.weight              Conv2d     False      131072    [256, 512, 1, 1]  -0.00036    0.0304        float32\n",
      "   61                  model.23.cv2.conv.bias              Conv2d     False         256               [256]     -4.98      3.72        float32\n",
      "   62                model.23.cv3.conv.weight              Conv2d     False      262144    [512, 512, 1, 1] -0.000151    0.0197        float32\n",
      "   62                  model.23.cv3.conv.bias              Conv2d     False         512               [512]     -7.13       3.5        float32\n",
      "   63            model.23.m.0.cv1.conv.weight              Conv2d     False       65536    [256, 256, 1, 1]  0.000218    0.0228        float32\n",
      "   63              model.23.m.0.cv1.conv.bias              Conv2d     False         256               [256]     -6.95      4.06        float32\n",
      "   64            model.23.m.0.cv2.conv.weight              Conv2d     False      589824    [256, 256, 3, 3] -2.09e-05   0.00587        float32\n",
      "   64              model.23.m.0.cv2.conv.bias              Conv2d     False         256               [256]     -4.78         4        float32\n",
      "   65            model.24.cv2.0.0.conv.weight              Conv2d     False       73728     [64, 128, 3, 3] -5.68e-05   0.00748        float32\n",
      "   65              model.24.cv2.0.0.conv.bias              Conv2d     False          64                [64]     -3.44      5.23        float32\n",
      "   66            model.24.cv2.0.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000215   0.00757        float32\n",
      "   66              model.24.cv2.0.1.conv.bias              Conv2d     False          64                [64]     -6.53      5.09        float32\n",
      "   67                 model.24.cv2.0.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   0.00583    0.0865        float32\n",
      "   67                   model.24.cv2.0.2.bias              Conv2d     False          64                [64]      1.62      1.61        float32\n",
      "   68            model.24.cv2.1.0.conv.weight              Conv2d     False      147456     [64, 256, 3, 3] -9.98e-05   0.00617        float32\n",
      "   68              model.24.cv2.1.0.conv.bias              Conv2d     False          64                [64]     -3.61      5.06        float32\n",
      "   69            model.24.cv2.1.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000357   0.00999        float32\n",
      "   69              model.24.cv2.1.1.conv.bias              Conv2d     False          64                [64]      -5.2      5.57        float32\n",
      "   70                 model.24.cv2.1.2.weight              Conv2d     False        4096      [64, 64, 1, 1]     0.007     0.137        float32\n",
      "   70                   model.24.cv2.1.2.bias              Conv2d     False          64                [64]      1.09      1.84        float32\n",
      "   71            model.24.cv2.2.0.conv.weight              Conv2d     False      294912     [64, 512, 3, 3] -0.000142   0.00841        float32\n",
      "   71              model.24.cv2.2.0.conv.bias              Conv2d     False          64                [64]     -1.22      3.92        float32\n",
      "   72            model.24.cv2.2.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000721    0.0118        float32\n",
      "   72              model.24.cv2.2.1.conv.bias              Conv2d     False          64                [64]    -0.511      2.76        float32\n",
      "   73                 model.24.cv2.2.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   -0.0329     0.303        float32\n",
      "   73                   model.24.cv2.2.2.bias              Conv2d     False          64                [64]     0.637      2.36        float32\n",
      "   74            model.24.cv3.0.0.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -2.81e-05   0.00337        float32\n",
      "   74              model.24.cv3.0.0.conv.bias              Conv2d     False         128               [128]     -6.31      3.66        float32\n",
      "   75            model.24.cv3.0.1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3]  2.66e-05   0.00544        float32\n",
      "   75              model.24.cv3.0.1.conv.bias              Conv2d     False         128               [128]      -7.7      3.78        float32\n",
      "   76                 model.24.cv3.0.2.weight              Conv2d     False        1152      [9, 128, 1, 1]  -0.00879     0.082        float32\n",
      "   76                   model.24.cv3.0.2.bias              Conv2d     False           9                 [9]     -9.45      1.84        float32\n",
      "   77            model.24.cv3.1.0.conv.weight              Conv2d     False      294912    [128, 256, 3, 3] -2.09e-05   0.00406        float32\n",
      "   77              model.24.cv3.1.0.conv.bias              Conv2d     False         128               [128]     -6.51      3.78        float32\n",
      "   78            model.24.cv3.1.1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -2.47e-05   0.00512        float32\n",
      "   78              model.24.cv3.1.1.conv.bias              Conv2d     False         128               [128]     -7.54      3.75        float32\n",
      "   79                 model.24.cv3.1.2.weight              Conv2d     False        1152      [9, 128, 1, 1]   -0.0204     0.112        float32\n",
      "   79                   model.24.cv3.1.2.bias              Conv2d     False           9                 [9]     -5.47     0.802        float32\n",
      "   80            model.24.cv3.2.0.conv.weight              Conv2d     False      589824    [128, 512, 3, 3] -1.96e-05   0.00371        float32\n",
      "   80              model.24.cv3.2.0.conv.bias              Conv2d     False         128               [128]     -7.08      3.82        float32\n",
      "   81            model.24.cv3.2.1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -7.88e-05    0.0735        float32\n",
      "   81              model.24.cv3.2.1.conv.bias              Conv2d     False         128               [128]      -7.4      4.77        float32\n",
      "   82                 model.24.cv3.2.2.weight              Conv2d     False        1152      [9, 128, 1, 1]   -0.0698     0.249        float32\n",
      "   82                   model.24.cv3.2.2.bias              Conv2d     False           9                 [9]     -3.57       1.1        float32\n",
      "   83                model.24.dfl.conv.weight              Conv2d     False          16       [1, 16, 1, 1]       7.5      4.76        float32\n",
      "YOLOv5s summary (fused): 84 layers, 9,115,019 parameters, 0 gradients, 23.8 GFLOPs\n",
      "\n",
      "============================================================\n",
      "üöÄ STARTING EXPERIMENT FOR MODEL: yolov5s (Aug: False)\n",
      "============================================================\n",
      "\n",
      "PRO TIP  Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.204 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=D:\\Virtual_Fahion\\GraduationThesis2_NS\\data\\data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train_yolov5s_aug_False, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov5s_aug_False, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \n",
      " 24        [17, 20, 23]  1   2119531  ultralytics.nn.modules.head.Detect           [9, [128, 256, 512]]          \n",
      "YOLOv5s summary: 153 layers, 9,125,675 parameters, 9,125,659 gradients, 24.1 GFLOPs\n",
      "\n",
      "Transferred 421/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 502.8185.7 MB/s, size: 20.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2_NS\\data\\train\\labels.cache... 64864 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 64864/64864 64.8Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 1262.6847.8 MB/s, size: 83.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2_NS\\data\\valid\\labels.cache... 1720 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1720/1720 1.7Mit/s 0.0s\n",
      "Plotting labels to D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov5s_aug_False\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov5s_aug_False\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/30      3.42G      1.293       2.17      1.647         48        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 14.9it/s 4:32<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.0it/s 4.2s0.2s\n",
      "                   all       1720       1720      0.168      0.396      0.201     0.0921\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/30      3.72G      1.197       1.98      1.557         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.0it/s 4:14<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.2it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.289      0.411      0.304      0.187\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/30      4.02G      1.143      1.875      1.513         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.5it/s 4:06<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.1s0.1s\n",
      "                   all       1720       1720      0.339      0.483       0.37      0.235\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/30      4.02G      1.103      1.779      1.485         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.7it/s 4:03<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.5it/s 4.0s0.1s\n",
      "                   all       1720       1720      0.426      0.452      0.436      0.283\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/30      4.02G      1.076      1.718      1.464         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.7it/s 4:03<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.4it/s 4.0s0.1s\n",
      "                   all       1720       1720      0.406      0.528      0.457      0.305\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/30      4.02G      1.048      1.668      1.446         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.6it/s 4:05<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.2it/s 4.1s0.1s\n",
      "                   all       1720       1720      0.453      0.531        0.5      0.333\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/30      4.02G      1.035      1.632      1.437         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:02<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.6it/s 4.0s0.1s\n",
      "                   all       1720       1720      0.459      0.517      0.516      0.352\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/30      4.02G      1.029      1.602      1.433         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.7it/s 4:03<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.6it/s 4.0s0.1s\n",
      "                   all       1720       1720      0.462      0.566      0.528      0.367\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/30      4.02G       1.02      1.576      1.425         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.6it/s 4:04<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.5it/s 4.0s0.1s\n",
      "                   all       1720       1720       0.49      0.569      0.549       0.38\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/30      4.02G       1.01       1.56      1.417         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:01<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.6it/s 4.0s0.1s\n",
      "                   all       1720       1720      0.484      0.581      0.557      0.385\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/30      4.02G      1.004      1.537      1.416         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.7it/s 4:03<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.6it/s 4.0s0.1s\n",
      "                   all       1720       1720      0.526      0.569      0.571      0.398\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/30      4.02G     0.9937       1.52      1.408         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.6it/s 4:04<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.2it/s 4.1s0.2s\n",
      "                   all       1720       1720       0.53      0.572      0.585      0.406\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/30      4.02G     0.9876      1.501      1.403         43        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:02<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 11.9it/s 4.5s0.2s\n",
      "                   all       1720       1720      0.526      0.583      0.589      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/30      4.02G     0.9817      1.482      1.398         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.7it/s 4:03<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.4it/s 4.0s0.2s\n",
      "                   all       1720       1720      0.544      0.581      0.594      0.416\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/30      4.02G     0.9733      1.468      1.392         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.5it/s 4:05<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.551      0.593      0.599       0.42\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/30      4.02G     0.9681      1.458       1.39         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.7it/s 4:03<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.6it/s 4.3s0.1s\n",
      "                   all       1720       1720      0.557      0.589      0.605      0.425\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/30      4.02G     0.9642      1.444      1.386         37        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.7it/s 4:03<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.4it/s 4.0s0.1s\n",
      "                   all       1720       1720      0.555      0.601      0.608      0.428\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/30      4.02G     0.9566      1.427      1.382         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.7it/s 4:03<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.5it/s 4.0s0.1s\n",
      "                   all       1720       1720      0.565      0.595      0.611      0.431\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/30      4.02G     0.9503      1.409      1.377         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.7it/s 4:03<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.2it/s 4.1s0.1s\n",
      "                   all       1720       1720      0.566      0.594      0.614      0.434\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/30      4.02G      0.946      1.398      1.371         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.7it/s 4:02<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.4it/s 4.0s0.1s\n",
      "                   all       1720       1720      0.574      0.594      0.617      0.436\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/30      4.02G      0.954      1.179      1.544         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:02<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.0s0.2s\n",
      "                   all       1720       1720       0.58      0.588      0.621      0.441\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/30      4.02G     0.9283      1.132      1.517         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.5it/s 4:05<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.2it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.571      0.604      0.625      0.445\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/30      4.02G     0.9094      1.104      1.499         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.9it/s 3:60<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.4it/s 4.0s0.1s\n",
      "                   all       1720       1720      0.572      0.597       0.63      0.451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/30      4.02G     0.8975      1.077      1.486         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:02<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.0it/s 4.2s0.2s\n",
      "                   all       1720       1720      0.575      0.606      0.635      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/30      4.02G     0.8835      1.054      1.472         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:01<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.5it/s 4.0s0.2s\n",
      "                   all       1720       1720      0.583      0.604      0.641       0.46\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/30      4.02G     0.8694      1.026      1.458         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.9it/s 3:60<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.4it/s 4.0s0.1s\n",
      "                   all       1720       1720      0.586       0.61      0.644      0.465\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/30      4.02G     0.8615     0.9981      1.451         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:01<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.1s0.1s\n",
      "                   all       1720       1720      0.595      0.614      0.647      0.469\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/30      4.02G     0.8484       0.97      1.436         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:02<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.1s0.1s\n",
      "                   all       1720       1720      0.598      0.625       0.65      0.474\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/30      4.02G      0.837     0.9418      1.426         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 17.0it/s 3:59<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.0it/s 4.1s0.1s\n",
      "                   all       1720       1720       0.61      0.617      0.655      0.479\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/30      4.02G     0.8253     0.9189      1.415         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.9it/s 4:00<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.2it/s 4.1s0.1s\n",
      "                   all       1720       1720      0.613      0.613      0.658      0.482\n",
      "\n",
      "30 epochs completed in 2.079 hours.\n",
      "Optimizer stripped from D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov5s_aug_False\\weights\\last.pt, 18.5MB\n",
      "Optimizer stripped from D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov5s_aug_False\\weights\\best.pt, 18.5MB\n",
      "\n",
      "Validating D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov5s_aug_False\\weights\\best.pt...\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "YOLOv5s summary (fused): 84 layers, 9,115,019 parameters, 0 gradients, 23.8 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 11.6it/s 4.7s0.1s\n",
      "                   all       1720       1720      0.611      0.616      0.658      0.483\n",
      "                 angry        258        258      0.534      0.589      0.662      0.491\n",
      "              contempt         82         82      0.503      0.561      0.602      0.503\n",
      "               disgust        108        108      0.687      0.488      0.629      0.524\n",
      "                  fear        107        107      0.514      0.757      0.631      0.502\n",
      "                 happy        387        387      0.785      0.835      0.895      0.663\n",
      "               natural        172        172      0.524      0.429      0.493      0.341\n",
      "                   sad        312        312      0.517      0.666      0.636      0.414\n",
      "                sleepy         38         38      0.799        0.5      0.611      0.334\n",
      "             surprised        256        256      0.638      0.719      0.766      0.572\n",
      "Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov5s_aug_False\u001b[0m\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "YOLOv5s summary (fused): 84 layers, 9,115,019 parameters, 0 gradients, 23.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 1089.5281.3 MB/s, size: 36.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2_NS\\data\\valid\\labels.cache... 1720 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1720/1720 1.7Mit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 108/108 21.5it/s 5.0s0.1s\n",
      "                   all       1720       1720      0.615      0.613      0.659      0.483\n",
      "                 angry        258        258      0.543      0.593      0.664      0.493\n",
      "              contempt         82         82      0.502      0.542      0.602      0.502\n",
      "               disgust        108        108      0.685      0.484       0.63      0.525\n",
      "                  fear        107        107      0.517      0.757      0.631      0.502\n",
      "                 happy        387        387       0.79      0.832      0.895      0.662\n",
      "               natural        172        172      0.527      0.421      0.493      0.341\n",
      "                   sad        312        312      0.521      0.663      0.636      0.413\n",
      "                sleepy         38         38      0.804        0.5      0.611      0.333\n",
      "             surprised        256        256      0.646      0.723      0.768      0.572\n",
      "Speed: 0.1ms preprocess, 1.0ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2_NS\\runs\\detect\\val2\u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "üìà VISUALIZING TRAINING & VALIDATION ANALYSIS FOR: yolov5s (Aug: False)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "üìä EXTRACTING PERFORMANCE INDICATORS FOR: yolov5s (Aug: False)\n",
      "--------------------------------------------------\n",
      "layer                                    name                type  gradient  parameters               shape        mu     sigma\n",
      "    0                     model.0.conv.weight              Conv2d     False        3456       [32, 3, 6, 6]  -0.00412      1.48        float32\n",
      "    0                       model.0.conv.bias              Conv2d     False          32                [32]     -1.59      6.18        float32\n",
      "    1                             model.0.act                SiLU     False           0                  []         -         -              -\n",
      "    2                     model.1.conv.weight              Conv2d     False       18432      [64, 32, 3, 3] -0.000799    0.0663        float32\n",
      "    2                       model.1.conv.bias              Conv2d     False          64                [64]    -0.822      5.46        float32\n",
      "    3                 model.2.cv1.conv.weight              Conv2d     False        2048      [32, 64, 1, 1]  -0.00105    0.0565        float32\n",
      "    3                   model.2.cv1.conv.bias              Conv2d     False          32                [32]      0.95      4.63        float32\n",
      "    4                 model.2.cv2.conv.weight              Conv2d     False        2048      [32, 64, 1, 1]  -0.00727    0.0893        float32\n",
      "    4                   model.2.cv2.conv.bias              Conv2d     False          32                [32]     0.912      4.62        float32\n",
      "    5                 model.2.cv3.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  -0.00715    0.0902        float32\n",
      "    5                   model.2.cv3.conv.bias              Conv2d     False          64                [64]     -1.57      6.06        float32\n",
      "    6             model.2.m.0.cv1.conv.weight              Conv2d     False        1024      [32, 32, 1, 1]  -0.00969     0.179        float32\n",
      "    6               model.2.m.0.cv1.conv.bias              Conv2d     False          32                [32]     -1.07      4.11        float32\n",
      "    7             model.2.m.0.cv2.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00101    0.0693        float32\n",
      "    7               model.2.m.0.cv2.conv.bias              Conv2d     False          32                [32]     0.128      5.35        float32\n",
      "    8                     model.3.conv.weight              Conv2d     False       73728     [128, 64, 3, 3]  0.000196    0.0163        float32\n",
      "    8                       model.3.conv.bias              Conv2d     False         128               [128]    -0.983       3.3        float32\n",
      "    9                 model.4.cv1.conv.weight              Conv2d     False        8192     [64, 128, 1, 1] -0.000139    0.0287        float32\n",
      "    9                   model.4.cv1.conv.bias              Conv2d     False          64                [64]      1.17      4.72        float32\n",
      "   10                 model.4.cv2.conv.weight              Conv2d     False        8192     [64, 128, 1, 1]  -0.00103     0.104        float32\n",
      "   10                   model.4.cv2.conv.bias              Conv2d     False          64                [64]     0.108      4.13        float32\n",
      "   11                 model.4.cv3.conv.weight              Conv2d     False       16384    [128, 128, 1, 1] -0.000235    0.0604        float32\n",
      "   11                   model.4.cv3.conv.bias              Conv2d     False         128               [128]     -4.97      4.89        float32\n",
      "   12             model.4.m.0.cv1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1] -0.000138     0.109        float32\n",
      "   12               model.4.m.0.cv1.conv.bias              Conv2d     False          64                [64]     -3.57      5.36        float32\n",
      "   13             model.4.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -6.73e-05    0.0124        float32\n",
      "   13               model.4.m.0.cv2.conv.bias              Conv2d     False          64                [64]    -0.702      3.94        float32\n",
      "   14             model.4.m.1.cv1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]   -0.0046     0.114        float32\n",
      "   14               model.4.m.1.cv1.conv.bias              Conv2d     False          64                [64]     -2.93      6.21        float32\n",
      "   15             model.4.m.1.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000856    0.0398        float32\n",
      "   15               model.4.m.1.cv2.conv.bias              Conv2d     False          64                [64]    -0.551      3.74        float32\n",
      "   16                     model.5.conv.weight              Conv2d     False      294912    [256, 128, 3, 3]   4.1e-05   0.00935        float32\n",
      "   16                       model.5.conv.bias              Conv2d     False         256               [256]     -2.69      3.46        float32\n",
      "   17                 model.6.cv1.conv.weight              Conv2d     False       32768    [128, 256, 1, 1] -0.000201    0.0169        float32\n",
      "   17                   model.6.cv1.conv.bias              Conv2d     False         128               [128]     -0.38      4.34        float32\n",
      "   18                 model.6.cv2.conv.weight              Conv2d     False       32768    [128, 256, 1, 1]  0.000486    0.0505        float32\n",
      "   18                   model.6.cv2.conv.bias              Conv2d     False         128               [128]     -2.28      3.48        float32\n",
      "   19                 model.6.cv3.conv.weight              Conv2d     False       65536    [256, 256, 1, 1] -0.000563    0.0254        float32\n",
      "   19                   model.6.cv3.conv.bias              Conv2d     False         256               [256]     -6.48      5.13        float32\n",
      "   20             model.6.m.0.cv1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]  0.000399    0.0481        float32\n",
      "   20               model.6.m.0.cv1.conv.bias              Conv2d     False         128               [128]     -6.09      4.26        float32\n",
      "   21             model.6.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -6.64e-06   0.00535        float32\n",
      "   21               model.6.m.0.cv2.conv.bias              Conv2d     False         128               [128]     -2.02      3.66        float32\n",
      "   22             model.6.m.1.cv1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]  -0.00141     0.067        float32\n",
      "   22               model.6.m.1.cv1.conv.bias              Conv2d     False         128               [128]     -6.32      5.25        float32\n",
      "   23             model.6.m.1.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -6.59e-05    0.0174        float32\n",
      "   23               model.6.m.1.cv2.conv.bias              Conv2d     False         128               [128]     -2.34      3.42        float32\n",
      "   24             model.6.m.2.cv1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]  -0.00174    0.0556        float32\n",
      "   24               model.6.m.2.cv1.conv.bias              Conv2d     False         128               [128]     -6.29       5.5        float32\n",
      "   25             model.6.m.2.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -0.000315    0.0217        float32\n",
      "   25               model.6.m.2.cv2.conv.bias              Conv2d     False         128               [128]     -2.94      3.77        float32\n",
      "   26                     model.7.conv.weight              Conv2d     False 1.17965e+06    [512, 256, 3, 3]  1.24e-05    0.0046        float32\n",
      "   26                       model.7.conv.bias              Conv2d     False         512               [512]     -4.03      3.68        float32\n",
      "   27                 model.8.cv1.conv.weight              Conv2d     False      131072    [256, 512, 1, 1]     1e-05     0.006        float32\n",
      "   27                   model.8.cv1.conv.bias              Conv2d     False         256               [256]     -4.27      4.04        float32\n",
      "   28                 model.8.cv2.conv.weight              Conv2d     False      131072    [256, 512, 1, 1] -4.12e-06   0.00822        float32\n",
      "   28                   model.8.cv2.conv.bias              Conv2d     False         256               [256]     -4.98      3.84        float32\n",
      "   29                 model.8.cv3.conv.weight              Conv2d     False      262144    [512, 512, 1, 1] -0.000118    0.0176        float32\n",
      "   29                   model.8.cv3.conv.bias              Conv2d     False         512               [512]     -3.94      3.76        float32\n",
      "   30             model.8.m.0.cv1.conv.weight              Conv2d     False       65536    [256, 256, 1, 1] -0.000341    0.0456        float32\n",
      "   30               model.8.m.0.cv1.conv.bias              Conv2d     False         256               [256]      -7.2      4.57        float32\n",
      "   31             model.8.m.0.cv2.conv.weight              Conv2d     False      589824    [256, 256, 3, 3]  -3.6e-05   0.00447        float32\n",
      "   31               model.8.m.0.cv2.conv.bias              Conv2d     False         256               [256]     -4.69      3.72        float32\n",
      "   32                 model.9.cv1.conv.weight              Conv2d     False      131072    [256, 512, 1, 1] -0.000726    0.0179        float32\n",
      "   32                   model.9.cv1.conv.bias              Conv2d     False         256               [256]     -2.99      6.24        float32\n",
      "   33                 model.9.cv2.conv.weight              Conv2d     False      524288   [512, 1024, 1, 1]   2.1e-05   0.00982        float32\n",
      "   33                   model.9.cv2.conv.bias              Conv2d     False         512               [512]     -5.01       4.5        float32\n",
      "   34                               model.9.m           MaxPool2d     False           0                  []         -         -              -\n",
      "   35                    model.10.conv.weight              Conv2d     False      131072    [256, 512, 1, 1]  -0.00135    0.0525        float32\n",
      "   35                      model.10.conv.bias              Conv2d     False         256               [256]     -3.99      4.61        float32\n",
      "   36                                model.11            Upsample     False           0                  []         -         -              -\n",
      "   37                                model.12              Concat     False           0                  []         -         -              -\n",
      "   38                model.13.cv1.conv.weight              Conv2d     False       65536    [128, 512, 1, 1] -0.000139    0.0229        float32\n",
      "   38                  model.13.cv1.conv.bias              Conv2d     False         128               [128]     -2.92      4.27        float32\n",
      "   39                model.13.cv2.conv.weight              Conv2d     False       65536    [128, 512, 1, 1] -0.000234     0.026        float32\n",
      "   39                  model.13.cv2.conv.bias              Conv2d     False         128               [128]     -3.98      3.84        float32\n",
      "   40                model.13.cv3.conv.weight              Conv2d     False       65536    [256, 256, 1, 1]  -1.8e-05    0.0282        float32\n",
      "   40                  model.13.cv3.conv.bias              Conv2d     False         256               [256]     -3.87      4.05        float32\n",
      "   41            model.13.m.0.cv1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1] -0.000232      0.11        float32\n",
      "   41              model.13.m.0.cv1.conv.bias              Conv2d     False         128               [128]     -5.82      4.97        float32\n",
      "   42            model.13.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -2.14e-05   0.00344        float32\n",
      "   42              model.13.m.0.cv2.conv.bias              Conv2d     False         128               [128]     -3.54      3.47        float32\n",
      "   43                    model.14.conv.weight              Conv2d     False       32768    [128, 256, 1, 1] -4.21e-05   0.00916        float32\n",
      "   43                      model.14.conv.bias              Conv2d     False         128               [128]     -2.48      4.87        float32\n",
      "   44                                model.15            Upsample     False           0                  []         -         -              -\n",
      "   45                                model.16              Concat     False           0                  []         -         -              -\n",
      "   46                model.17.cv1.conv.weight              Conv2d     False       16384     [64, 256, 1, 1]  0.000454    0.0279        float32\n",
      "   46                  model.17.cv1.conv.bias              Conv2d     False          64                [64]     -1.87      3.87        float32\n",
      "   47                model.17.cv2.conv.weight              Conv2d     False       16384     [64, 256, 1, 1]  0.000248    0.0357        float32\n",
      "   47                  model.17.cv2.conv.bias              Conv2d     False          64                [64]      1.91      5.63        float32\n",
      "   48                model.17.cv3.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]  6.68e-05    0.0416        float32\n",
      "   48                  model.17.cv3.conv.bias              Conv2d     False         128               [128]     -4.58      4.47        float32\n",
      "   49            model.17.m.0.cv1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  0.000739    0.0471        float32\n",
      "   49              model.17.m.0.cv1.conv.bias              Conv2d     False          64                [64]     -5.43      4.92        float32\n",
      "   50            model.17.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -8.51e-05     0.012        float32\n",
      "   50              model.17.m.0.cv2.conv.bias              Conv2d     False          64                [64]     -0.89      3.91        float32\n",
      "   51                    model.18.conv.weight              Conv2d     False      147456    [128, 128, 3, 3]  1.69e-05   0.00497        float32\n",
      "   51                      model.18.conv.bias              Conv2d     False         128               [128]     -2.78         4        float32\n",
      "   52                                model.19              Concat     False           0                  []         -         -              -\n",
      "   53                model.20.cv1.conv.weight              Conv2d     False       32768    [128, 256, 1, 1]  0.000401    0.0371        float32\n",
      "   53                  model.20.cv1.conv.bias              Conv2d     False         128               [128]     -2.76      3.51        float32\n",
      "   54                model.20.cv2.conv.weight              Conv2d     False       32768    [128, 256, 1, 1]  0.000288    0.0321        float32\n",
      "   54                  model.20.cv2.conv.bias              Conv2d     False         128               [128]     -2.12      4.62        float32\n",
      "   55                model.20.cv3.conv.weight              Conv2d     False       65536    [256, 256, 1, 1] -1.07e-05    0.0197        float32\n",
      "   55                  model.20.cv3.conv.bias              Conv2d     False         256               [256]     -6.13      4.17        float32\n",
      "   56            model.20.m.0.cv1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]  0.000146    0.0348        float32\n",
      "   56              model.20.m.0.cv1.conv.bias              Conv2d     False         128               [128]     -4.34      4.78        float32\n",
      "   57            model.20.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -4.23e-05   0.00581        float32\n",
      "   57              model.20.m.0.cv2.conv.bias              Conv2d     False         128               [128]     -2.73      3.31        float32\n",
      "   58                    model.21.conv.weight              Conv2d     False      589824    [256, 256, 3, 3]  2.44e-05   0.00312        float32\n",
      "   58                      model.21.conv.bias              Conv2d     False         256               [256]     -5.98         3        float32\n",
      "   59                                model.22              Concat     False           0                  []         -         -              -\n",
      "   60                model.23.cv1.conv.weight              Conv2d     False      131072    [256, 512, 1, 1]  3.15e-05    0.0289        float32\n",
      "   60                  model.23.cv1.conv.bias              Conv2d     False         256               [256]      -3.2      4.59        float32\n",
      "   61                model.23.cv2.conv.weight              Conv2d     False      131072    [256, 512, 1, 1]  -0.00036    0.0304        float32\n",
      "   61                  model.23.cv2.conv.bias              Conv2d     False         256               [256]     -4.98      3.72        float32\n",
      "   62                model.23.cv3.conv.weight              Conv2d     False      262144    [512, 512, 1, 1] -0.000151    0.0197        float32\n",
      "   62                  model.23.cv3.conv.bias              Conv2d     False         512               [512]     -7.13       3.5        float32\n",
      "   63            model.23.m.0.cv1.conv.weight              Conv2d     False       65536    [256, 256, 1, 1]  0.000218    0.0228        float32\n",
      "   63              model.23.m.0.cv1.conv.bias              Conv2d     False         256               [256]     -6.95      4.06        float32\n",
      "   64            model.23.m.0.cv2.conv.weight              Conv2d     False      589824    [256, 256, 3, 3] -2.09e-05   0.00587        float32\n",
      "   64              model.23.m.0.cv2.conv.bias              Conv2d     False         256               [256]     -4.78         4        float32\n",
      "   65            model.24.cv2.0.0.conv.weight              Conv2d     False       73728     [64, 128, 3, 3] -5.68e-05   0.00748        float32\n",
      "   65              model.24.cv2.0.0.conv.bias              Conv2d     False          64                [64]     -3.44      5.23        float32\n",
      "   66            model.24.cv2.0.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000215   0.00757        float32\n",
      "   66              model.24.cv2.0.1.conv.bias              Conv2d     False          64                [64]     -6.53      5.09        float32\n",
      "   67                 model.24.cv2.0.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   0.00583    0.0865        float32\n",
      "   67                   model.24.cv2.0.2.bias              Conv2d     False          64                [64]      1.62      1.61        float32\n",
      "   68            model.24.cv2.1.0.conv.weight              Conv2d     False      147456     [64, 256, 3, 3] -9.98e-05   0.00617        float32\n",
      "   68              model.24.cv2.1.0.conv.bias              Conv2d     False          64                [64]     -3.61      5.06        float32\n",
      "   69            model.24.cv2.1.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000357   0.00999        float32\n",
      "   69              model.24.cv2.1.1.conv.bias              Conv2d     False          64                [64]      -5.2      5.57        float32\n",
      "   70                 model.24.cv2.1.2.weight              Conv2d     False        4096      [64, 64, 1, 1]     0.007     0.137        float32\n",
      "   70                   model.24.cv2.1.2.bias              Conv2d     False          64                [64]      1.09      1.84        float32\n",
      "   71            model.24.cv2.2.0.conv.weight              Conv2d     False      294912     [64, 512, 3, 3] -0.000142   0.00841        float32\n",
      "   71              model.24.cv2.2.0.conv.bias              Conv2d     False          64                [64]     -1.22      3.92        float32\n",
      "   72            model.24.cv2.2.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000721    0.0118        float32\n",
      "   72              model.24.cv2.2.1.conv.bias              Conv2d     False          64                [64]    -0.511      2.76        float32\n",
      "   73                 model.24.cv2.2.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   -0.0329     0.303        float32\n",
      "   73                   model.24.cv2.2.2.bias              Conv2d     False          64                [64]     0.637      2.36        float32\n",
      "   74            model.24.cv3.0.0.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -2.81e-05   0.00337        float32\n",
      "   74              model.24.cv3.0.0.conv.bias              Conv2d     False         128               [128]     -6.31      3.66        float32\n",
      "   75            model.24.cv3.0.1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3]  2.66e-05   0.00544        float32\n",
      "   75              model.24.cv3.0.1.conv.bias              Conv2d     False         128               [128]      -7.7      3.78        float32\n",
      "   76                 model.24.cv3.0.2.weight              Conv2d     False        1152      [9, 128, 1, 1]  -0.00879     0.082        float32\n",
      "   76                   model.24.cv3.0.2.bias              Conv2d     False           9                 [9]     -9.45      1.84        float32\n",
      "   77            model.24.cv3.1.0.conv.weight              Conv2d     False      294912    [128, 256, 3, 3] -2.09e-05   0.00406        float32\n",
      "   77              model.24.cv3.1.0.conv.bias              Conv2d     False         128               [128]     -6.51      3.78        float32\n",
      "   78            model.24.cv3.1.1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -2.47e-05   0.00512        float32\n",
      "   78              model.24.cv3.1.1.conv.bias              Conv2d     False         128               [128]     -7.54      3.75        float32\n",
      "   79                 model.24.cv3.1.2.weight              Conv2d     False        1152      [9, 128, 1, 1]   -0.0204     0.112        float32\n",
      "   79                   model.24.cv3.1.2.bias              Conv2d     False           9                 [9]     -5.47     0.802        float32\n",
      "   80            model.24.cv3.2.0.conv.weight              Conv2d     False      589824    [128, 512, 3, 3] -1.96e-05   0.00371        float32\n",
      "   80              model.24.cv3.2.0.conv.bias              Conv2d     False         128               [128]     -7.08      3.82        float32\n",
      "   81            model.24.cv3.2.1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -7.88e-05    0.0735        float32\n",
      "   81              model.24.cv3.2.1.conv.bias              Conv2d     False         128               [128]      -7.4      4.77        float32\n",
      "   82                 model.24.cv3.2.2.weight              Conv2d     False        1152      [9, 128, 1, 1]   -0.0698     0.249        float32\n",
      "   82                   model.24.cv3.2.2.bias              Conv2d     False           9                 [9]     -3.57       1.1        float32\n",
      "   83                model.24.dfl.conv.weight              Conv2d     False          16       [1, 16, 1, 1]       7.5      4.76        float32\n",
      "YOLOv5s summary (fused): 84 layers, 9,115,019 parameters, 0 gradients, 23.8 GFLOPs\n",
      "\n",
      "============================================================\n",
      "üöÄ STARTING EXPERIMENT FOR MODEL: yolov8s (Aug: True)\n",
      "============================================================\n",
      "\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21.5MB 87.2MB/s 0.2s0.2s<0.0s\n",
      "New https://pypi.org/project/ultralytics/8.3.205 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=D:\\Virtual_Fahion\\GraduationThesis2_NS\\data\\data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train_yolov8s_aug_True, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov8s_aug_True, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2119531  ultralytics.nn.modules.head.Detect           [9, [128, 256, 512]]          \n",
      "Model summary: 129 layers, 11,139,083 parameters, 11,139,067 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 534.9207.3 MB/s, size: 20.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2_NS\\data\\train\\labels.cache... 64864 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 64864/64864 64.9Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 537.2262.3 MB/s, size: 83.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2_NS\\data\\valid\\labels.cache... 1720 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1720/1720  0.0s\n",
      "Plotting labels to D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov8s_aug_True\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov8s_aug_True\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/30      3.67G      1.254      2.125      1.627         48        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 15.1it/s 4:28<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.7it/s 4.3s0.2s\n",
      "                   all       1720       1720      0.207      0.505      0.246      0.135\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/30      3.88G      1.162      1.927      1.541         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.1it/s 4:12<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.6it/s 4.3s0.2s\n",
      "                   all       1720       1720       0.32      0.496      0.311        0.2\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/30      3.88G      1.116      1.826      1.503         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.6it/s 4:04<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.0it/s 4.2s0.1s\n",
      "                   all       1720       1720      0.383      0.484      0.419      0.269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/30      3.88G      1.078       1.74      1.475         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.7it/s 4:03<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.0it/s 4.2s0.2s\n",
      "                   all       1720       1720      0.398      0.494      0.448      0.302\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/30      3.88G      1.056      1.677      1.454         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.7it/s 4:03<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.439       0.55      0.488      0.331\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/30      3.88G      1.031      1.632       1.44         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.7it/s 4:02<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.7it/s 4.2s0.2s\n",
      "                   all       1720       1720      0.464      0.535      0.509      0.348\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/30      3.88G      1.015      1.592      1.426         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:01<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.2it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.478      0.566      0.533      0.368\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/30      3.88G       1.01      1.566      1.424         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:02<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.506      0.569      0.554       0.39\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/30      3.88G          1      1.542      1.415         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:02<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.1it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.515       0.58      0.573        0.4\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/30      3.88G     0.9921      1.524      1.408         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.9it/s 4:00<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.2it/s 4.1s0.1s\n",
      "                   all       1720       1720      0.522      0.577      0.577      0.408\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/30      3.88G      0.983      1.503      1.405         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:01<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.4it/s 4.0s0.1s\n",
      "                   all       1720       1720      0.525      0.588      0.586      0.415\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/30      3.88G     0.9749      1.486      1.398         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.7it/s 4:02<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.4it/s 4.0s0.2s\n",
      "                   all       1720       1720      0.522       0.59      0.596      0.424\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/30      3.88G     0.9702      1.469      1.393         43        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.9it/s 3:60<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.543      0.592      0.607      0.433\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/30      3.88G     0.9632       1.45      1.388         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:01<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.1it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.569      0.594      0.616       0.44\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/30      3.88G     0.9538      1.433      1.381         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:02<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.575      0.583      0.622      0.444\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/30      3.88G     0.9518      1.422       1.38         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.9it/s 3:60<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.8it/s 4.2s0.1s\n",
      "                   all       1720       1720      0.569      0.598      0.626      0.448\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/30      3.88G     0.9447      1.406      1.374         37        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:01<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.2it/s 4.1s0.1s\n",
      "                   all       1720       1720      0.562      0.608      0.628      0.451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/30      3.88G     0.9351      1.393       1.37         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:01<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.582      0.603      0.631      0.454\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/30      3.88G     0.9307      1.375      1.366         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:01<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.0it/s 4.2s0.2s\n",
      "                   all       1720       1720      0.581        0.6      0.634      0.456\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/30      3.88G     0.9255      1.362       1.36         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:01<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.2it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.585        0.6      0.638      0.459\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/30      3.88G     0.9345      1.127      1.531         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.9it/s 4:00<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.586      0.607      0.645      0.465\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/30      3.88G     0.9106      1.077      1.506         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 17.0it/s 3:58<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.1it/s 4.1s0.1s\n",
      "                   all       1720       1720      0.595      0.599      0.652      0.472\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/30      3.88G     0.8947      1.049      1.491         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 17.1it/s 3:58<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.1s0.2s\n",
      "                   all       1720       1720       0.61        0.6      0.659      0.479\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/30      3.88G     0.8819       1.02      1.476         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 17.0it/s 3:59<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.1s0.1s\n",
      "                   all       1720       1720      0.612      0.594      0.665      0.484\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/30      3.88G     0.8677     0.9994      1.462         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 17.0it/s 3:58<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.2it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.625      0.597      0.672       0.49\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/30      3.88G     0.8512     0.9742      1.446         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 17.1it/s 3:57<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.625      0.608      0.677      0.497\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/30      3.88G     0.8433     0.9397      1.439         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 17.0it/s 3:59<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.4it/s 4.0s0.2s\n",
      "                   all       1720       1720      0.638      0.606      0.683      0.502\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/30      3.88G     0.8321     0.9153      1.426         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 17.0it/s 3:59<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.9it/s 4.2s0.1s\n",
      "                   all       1720       1720      0.651      0.598      0.686      0.508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/30      3.88G     0.8178     0.8882      1.415         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 17.1it/s 3:57<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.1s0.1s\n",
      "                   all       1720       1720      0.664        0.6      0.691      0.511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/30      3.88G     0.8076     0.8652      1.404         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 17.0it/s 3:58<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.2it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.658       0.61      0.698      0.516\n",
      "\n",
      "30 epochs completed in 2.062 hours.\n",
      "Optimizer stripped from D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov8s_aug_True\\weights\\last.pt, 22.5MB\n",
      "Optimizer stripped from D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov8s_aug_True\\weights\\best.pt, 22.5MB\n",
      "\n",
      "Validating D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov8s_aug_True\\weights\\best.pt...\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "Model summary (fused): 72 layers, 11,129,067 parameters, 0 gradients, 28.5 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 8.4it/s 6.4s0.2s\n",
      "                   all       1720       1720      0.637      0.651      0.711      0.535\n",
      "                 angry        258        258      0.597      0.663      0.711      0.546\n",
      "              contempt         82         82      0.601       0.61      0.693      0.573\n",
      "               disgust        108        108      0.642      0.593      0.686      0.592\n",
      "                  fear        107        107      0.644      0.726      0.719      0.579\n",
      "                 happy        387        387      0.786      0.842      0.888      0.682\n",
      "               natural        172        172      0.555      0.414       0.55      0.379\n",
      "                   sad        312        312      0.657      0.625      0.713      0.494\n",
      "                sleepy         38         38      0.546      0.658      0.656      0.369\n",
      "             surprised        256        256      0.706       0.73      0.785      0.601\n",
      "Speed: 0.2ms preprocess, 1.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov8s_aug_True\u001b[0m\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "Model summary (fused): 72 layers, 11,129,067 parameters, 0 gradients, 28.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 1040.1252.1 MB/s, size: 36.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2_NS\\data\\valid\\labels.cache... 1720 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1720/1720  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 108/108 20.9it/s 5.2s0.1s\n",
      "                   all       1720       1720      0.652      0.616      0.697      0.516\n",
      "                 angry        258        258        0.6      0.612      0.705      0.529\n",
      "              contempt         82         82      0.672      0.561      0.653      0.538\n",
      "               disgust        108        108      0.686      0.537      0.662      0.558\n",
      "                  fear        107        107      0.585      0.692      0.698      0.551\n",
      "                 happy        387        387       0.79      0.837      0.894      0.681\n",
      "               natural        172        172      0.564      0.429      0.523      0.357\n",
      "                   sad        312        312      0.661      0.574      0.702      0.471\n",
      "                sleepy         38         38      0.604      0.579      0.656      0.366\n",
      "             surprised        256        256      0.709      0.719      0.777      0.596\n",
      "Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2_NS\\runs\\detect\\val3\u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "üìà VISUALIZING TRAINING & VALIDATION ANALYSIS FOR: yolov8s (Aug: True)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "üìä EXTRACTING PERFORMANCE INDICATORS FOR: yolov8s (Aug: True)\n",
      "--------------------------------------------------\n",
      "layer                                    name                type  gradient  parameters               shape        mu     sigma\n",
      "    0                     model.0.conv.weight              Conv2d     False         864       [32, 3, 3, 3]   -0.0283      4.98        float32\n",
      "    0                       model.0.conv.bias              Conv2d     False          32                [32]     -3.01      9.28        float32\n",
      "    1                             model.0.act                SiLU     False           0                  []         -         -              -\n",
      "    2                     model.1.conv.weight              Conv2d     False       18432      [64, 32, 3, 3] -0.000422      0.07        float32\n",
      "    2                       model.1.conv.bias              Conv2d     False          64                [64]     -1.74      7.97        float32\n",
      "    3                 model.2.cv1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  -0.00717     0.102        float32\n",
      "    3                   model.2.cv1.conv.bias              Conv2d     False          64                [64]     0.433      3.96        float32\n",
      "    4                 model.2.cv2.conv.weight              Conv2d     False        6144      [64, 96, 1, 1]  -0.00436    0.0619        float32\n",
      "    4                   model.2.cv2.conv.bias              Conv2d     False          64                [64]     -2.06      4.89        float32\n",
      "    5             model.2.m.0.cv1.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00246    0.0735        float32\n",
      "    5               model.2.m.0.cv1.conv.bias              Conv2d     False          32                [32]     -1.79       6.2        float32\n",
      "    6             model.2.m.0.cv2.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]   -0.0042    0.0626        float32\n",
      "    6               model.2.m.0.cv2.conv.bias              Conv2d     False          32                [32]      2.09      4.86        float32\n",
      "    7                     model.3.conv.weight              Conv2d     False       73728     [128, 64, 3, 3]  1.58e-05    0.0146        float32\n",
      "    7                       model.3.conv.bias              Conv2d     False         128               [128]      -1.2      3.71        float32\n",
      "    8                 model.4.cv1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1] -0.000562    0.0801        float32\n",
      "    8                   model.4.cv1.conv.bias              Conv2d     False         128               [128]     -1.62      4.44        float32\n",
      "    9                 model.4.cv2.conv.weight              Conv2d     False       32768    [128, 256, 1, 1] -0.000115     0.032        float32\n",
      "    9                   model.4.cv2.conv.bias              Conv2d     False         128               [128]     -4.81      4.41        float32\n",
      "   10             model.4.m.0.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000273    0.0386        float32\n",
      "   10               model.4.m.0.cv1.conv.bias              Conv2d     False          64                [64]     -5.02      4.43        float32\n",
      "   11             model.4.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000934    0.0233        float32\n",
      "   11               model.4.m.0.cv2.conv.bias              Conv2d     False          64                [64]     -1.53      3.34        float32\n",
      "   12             model.4.m.1.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -9.66e-05    0.0134        float32\n",
      "   12               model.4.m.1.cv1.conv.bias              Conv2d     False          64                [64]     -5.25      4.06        float32\n",
      "   13             model.4.m.1.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000184     0.037        float32\n",
      "   13               model.4.m.1.cv2.conv.bias              Conv2d     False          64                [64]     -2.02      4.02        float32\n",
      "   14                     model.5.conv.weight              Conv2d     False      294912    [256, 128, 3, 3]  4.44e-05    0.0079        float32\n",
      "   14                       model.5.conv.bias              Conv2d     False         256               [256]     -2.95      3.37        float32\n",
      "   15                 model.6.cv1.conv.weight              Conv2d     False       65536    [256, 256, 1, 1]  0.000299    0.0381        float32\n",
      "   15                   model.6.cv1.conv.bias              Conv2d     False         256               [256]     -4.01      4.71        float32\n",
      "   16                 model.6.cv2.conv.weight              Conv2d     False      131072    [256, 512, 1, 1] -0.000148    0.0108        float32\n",
      "   16                   model.6.cv2.conv.bias              Conv2d     False         256               [256]     -7.55      3.78        float32\n",
      "   17             model.6.m.0.cv1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -0.000153    0.0154        float32\n",
      "   17               model.6.m.0.cv1.conv.bias              Conv2d     False         128               [128]     -6.78      3.82        float32\n",
      "   18             model.6.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -0.000502    0.0167        float32\n",
      "   18               model.6.m.0.cv2.conv.bias              Conv2d     False         128               [128]     -5.17      4.29        float32\n",
      "   19             model.6.m.1.cv1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -0.000312     0.012        float32\n",
      "   19               model.6.m.1.cv1.conv.bias              Conv2d     False         128               [128]     -7.27         4        float32\n",
      "   20             model.6.m.1.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3]  -0.00114    0.0441        float32\n",
      "   20               model.6.m.1.cv2.conv.bias              Conv2d     False         128               [128]        -3      3.58        float32\n",
      "   21                     model.7.conv.weight              Conv2d     False 1.17965e+06    [512, 256, 3, 3] -3.23e-06   0.00441        float32\n",
      "   21                       model.7.conv.bias              Conv2d     False         512               [512]      -4.3      3.59        float32\n",
      "   22                 model.8.cv1.conv.weight              Conv2d     False      262144    [512, 512, 1, 1] -2.11e-05   0.00872        float32\n",
      "   22                   model.8.cv1.conv.bias              Conv2d     False         512               [512]     -6.76      4.24        float32\n",
      "   23                 model.8.cv2.conv.weight              Conv2d     False      393216    [512, 768, 1, 1] -8.61e-05    0.0126        float32\n",
      "   23                   model.8.cv2.conv.bias              Conv2d     False         512               [512]     -4.22      3.76        float32\n",
      "   24             model.8.m.0.cv1.conv.weight              Conv2d     False      589824    [256, 256, 3, 3] -6.38e-05    0.0111        float32\n",
      "   24               model.8.m.0.cv1.conv.bias              Conv2d     False         256               [256]     -8.23      3.51        float32\n",
      "   25             model.8.m.0.cv2.conv.weight              Conv2d     False      589824    [256, 256, 3, 3] -5.22e-05    0.0087        float32\n",
      "   25               model.8.m.0.cv2.conv.bias              Conv2d     False         256               [256]     -5.28      4.19        float32\n",
      "   26                 model.9.cv1.conv.weight              Conv2d     False      131072    [256, 512, 1, 1] -0.000637    0.0165        float32\n",
      "   26                   model.9.cv1.conv.bias              Conv2d     False         256               [256]     -2.59      5.94        float32\n",
      "   27                 model.9.cv2.conv.weight              Conv2d     False      524288   [512, 1024, 1, 1] -1.17e-05    0.0104        float32\n",
      "   27                   model.9.cv2.conv.bias              Conv2d     False         512               [512]     -5.24      4.19        float32\n",
      "   28                               model.9.m           MaxPool2d     False           0                  []         -         -              -\n",
      "   29                                model.10            Upsample     False           0                  []         -         -              -\n",
      "   30                                model.11              Concat     False           0                  []         -         -              -\n",
      "   31                model.12.cv1.conv.weight              Conv2d     False      196608    [256, 768, 1, 1]  -0.00045    0.0342        float32\n",
      "   31                  model.12.cv1.conv.bias              Conv2d     False         256               [256]     -5.23      3.85        float32\n",
      "   32                model.12.cv2.conv.weight              Conv2d     False       98304    [256, 384, 1, 1]  -0.00031    0.0275        float32\n",
      "   32                  model.12.cv2.conv.bias              Conv2d     False         256               [256]     -4.66      3.81        float32\n",
      "   33            model.12.m.0.cv1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -0.000138    0.0145        float32\n",
      "   33              model.12.m.0.cv1.conv.bias              Conv2d     False         128               [128]     -7.54      3.68        float32\n",
      "   34            model.12.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -7.94e-05   0.00823        float32\n",
      "   34              model.12.m.0.cv2.conv.bias              Conv2d     False         128               [128]     -3.82      3.81        float32\n",
      "   35                                model.13            Upsample     False           0                  []         -         -              -\n",
      "   36                                model.14              Concat     False           0                  []         -         -              -\n",
      "   37                model.15.cv1.conv.weight              Conv2d     False       49152    [128, 384, 1, 1] -0.000178    0.0227        float32\n",
      "   37                  model.15.cv1.conv.bias              Conv2d     False         128               [128]     -3.74      4.86        float32\n",
      "   38                model.15.cv2.conv.weight              Conv2d     False       24576    [128, 192, 1, 1]  7.62e-05    0.0282        float32\n",
      "   38                  model.15.cv2.conv.bias              Conv2d     False         128               [128]     -4.37      4.18        float32\n",
      "   39            model.15.m.0.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000313     0.028        float32\n",
      "   39              model.15.m.0.cv1.conv.bias              Conv2d     False          64                [64]     -5.07      4.58        float32\n",
      "   40            model.15.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -6.72e-05    0.0225        float32\n",
      "   40              model.15.m.0.cv2.conv.bias              Conv2d     False          64                [64]     -1.76      3.57        float32\n",
      "   41                    model.16.conv.weight              Conv2d     False      147456    [128, 128, 3, 3]  6.64e-05   0.00544        float32\n",
      "   41                      model.16.conv.bias              Conv2d     False         128               [128]     -3.45      3.97        float32\n",
      "   42                                model.17              Concat     False           0                  []         -         -              -\n",
      "   43                model.18.cv1.conv.weight              Conv2d     False       98304    [256, 384, 1, 1]  0.000134    0.0282        float32\n",
      "   43                  model.18.cv1.conv.bias              Conv2d     False         256               [256]     -4.82      4.27        float32\n",
      "   44                model.18.cv2.conv.weight              Conv2d     False       98304    [256, 384, 1, 1]  1.27e-05    0.0114        float32\n",
      "   44                  model.18.cv2.conv.bias              Conv2d     False         256               [256]     -7.28      3.18        float32\n",
      "   45            model.18.m.0.cv1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -4.81e-05   0.00612        float32\n",
      "   45              model.18.m.0.cv1.conv.bias              Conv2d     False         128               [128]     -7.46      3.35        float32\n",
      "   46            model.18.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3]  3.25e-05    0.0144        float32\n",
      "   46              model.18.m.0.cv2.conv.bias              Conv2d     False         128               [128]     -2.32      3.96        float32\n",
      "   47                    model.19.conv.weight              Conv2d     False      589824    [256, 256, 3, 3]  7.67e-06   0.00263        float32\n",
      "   47                      model.19.conv.bias              Conv2d     False         256               [256]     -5.03      3.53        float32\n",
      "   48                                model.20              Concat     False           0                  []         -         -              -\n",
      "   49                model.21.cv1.conv.weight              Conv2d     False      393216    [512, 768, 1, 1] -0.000308    0.0278        float32\n",
      "   49                  model.21.cv1.conv.bias              Conv2d     False         512               [512]     -6.59      3.87        float32\n",
      "   50                model.21.cv2.conv.weight              Conv2d     False      393216    [512, 768, 1, 1] -9.71e-05    0.0138        float32\n",
      "   50                  model.21.cv2.conv.bias              Conv2d     False         512               [512]     -7.23      3.42        float32\n",
      "   51            model.21.m.0.cv1.conv.weight              Conv2d     False      589824    [256, 256, 3, 3]  -2.8e-05   0.00848        float32\n",
      "   51              model.21.m.0.cv1.conv.bias              Conv2d     False         256               [256]     -7.55       3.1        float32\n",
      "   52            model.21.m.0.cv2.conv.weight              Conv2d     False      589824    [256, 256, 3, 3] -6.53e-05   0.00865        float32\n",
      "   52              model.21.m.0.cv2.conv.bias              Conv2d     False         256               [256]     -4.54      3.69        float32\n",
      "   53            model.22.cv2.0.0.conv.weight              Conv2d     False       73728     [64, 128, 3, 3] -4.79e-05    0.0071        float32\n",
      "   53              model.22.cv2.0.0.conv.bias              Conv2d     False          64                [64]     -3.72      4.79        float32\n",
      "   54            model.22.cv2.0.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000258   0.00694        float32\n",
      "   54              model.22.cv2.0.1.conv.bias              Conv2d     False          64                [64]     -6.33       5.3        float32\n",
      "   55                 model.22.cv2.0.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   0.00531    0.0857        float32\n",
      "   55                   model.22.cv2.0.2.bias              Conv2d     False          64                [64]      2.17      1.66        float32\n",
      "   56            model.22.cv2.1.0.conv.weight              Conv2d     False      147456     [64, 256, 3, 3] -0.000182   0.00639        float32\n",
      "   56              model.22.cv2.1.0.conv.bias              Conv2d     False          64                [64]     -2.79      5.52        float32\n",
      "   57            model.22.cv2.1.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -0.00022   0.00889        float32\n",
      "   57              model.22.cv2.1.1.conv.bias              Conv2d     False          64                [64]      -4.6      5.37        float32\n",
      "   58                 model.22.cv2.1.2.weight              Conv2d     False        4096      [64, 64, 1, 1]    0.0067     0.136        float32\n",
      "   58                   model.22.cv2.1.2.bias              Conv2d     False          64                [64]      1.08      1.92        float32\n",
      "   59            model.22.cv2.2.0.conv.weight              Conv2d     False      294912     [64, 512, 3, 3] -6.23e-05    0.0078        float32\n",
      "   59              model.22.cv2.2.0.conv.bias              Conv2d     False          64                [64]     -2.37      4.29        float32\n",
      "   60            model.22.cv2.2.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000744    0.0109        float32\n",
      "   60              model.22.cv2.2.1.conv.bias              Conv2d     False          64                [64]    -0.396      2.78        float32\n",
      "   61                 model.22.cv2.2.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   -0.0306     0.302        float32\n",
      "   61                   model.22.cv2.2.2.bias              Conv2d     False          64                [64]     0.709      2.39        float32\n",
      "   62            model.22.cv3.0.0.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -1.38e-05   0.00286        float32\n",
      "   62              model.22.cv3.0.0.conv.bias              Conv2d     False         128               [128]     -6.45      3.66        float32\n",
      "   63            model.22.cv3.0.1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3]  0.000103   0.00592        float32\n",
      "   63              model.22.cv3.0.1.conv.bias              Conv2d     False         128               [128]     -7.28       3.6        float32\n",
      "   64                 model.22.cv3.0.2.weight              Conv2d     False        1152      [9, 128, 1, 1]  -0.00818    0.0753        float32\n",
      "   64                   model.22.cv3.0.2.bias              Conv2d     False           9                 [9]     -9.74      2.51        float32\n",
      "   65            model.22.cv3.1.0.conv.weight              Conv2d     False      294912    [128, 256, 3, 3] -9.82e-06   0.00373        float32\n",
      "   65              model.22.cv3.1.0.conv.bias              Conv2d     False         128               [128]     -6.82      3.83        float32\n",
      "   66            model.22.cv3.1.1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3]  4.68e-05   0.00607        float32\n",
      "   66              model.22.cv3.1.1.conv.bias              Conv2d     False         128               [128]     -7.65      3.33        float32\n",
      "   67                 model.22.cv3.1.2.weight              Conv2d     False        1152      [9, 128, 1, 1]   -0.0206     0.111        float32\n",
      "   67                   model.22.cv3.1.2.bias              Conv2d     False           9                 [9]     -5.84      1.02        float32\n",
      "   68            model.22.cv3.2.0.conv.weight              Conv2d     False      589824    [128, 512, 3, 3] -1.51e-05   0.00355        float32\n",
      "   68              model.22.cv3.2.0.conv.bias              Conv2d     False         128               [128]      -7.2      3.74        float32\n",
      "   69            model.22.cv3.2.1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -1.23e-05    0.0561        float32\n",
      "   69              model.22.cv3.2.1.conv.bias              Conv2d     False         128               [128]     -7.45      4.92        float32\n",
      "   70                 model.22.cv3.2.2.weight              Conv2d     False        1152      [9, 128, 1, 1]   -0.0682     0.259        float32\n",
      "   70                   model.22.cv3.2.2.bias              Conv2d     False           9                 [9]     -3.66     0.998        float32\n",
      "   71                model.22.dfl.conv.weight              Conv2d     False          16       [1, 16, 1, 1]       7.5      4.76        float32\n",
      "Model summary (fused): 72 layers, 11,129,067 parameters, 0 gradients, 28.5 GFLOPs\n",
      "\n",
      "============================================================\n",
      "üöÄ STARTING EXPERIMENT FOR MODEL: yolov8s (Aug: False)\n",
      "============================================================\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.205 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=D:\\Virtual_Fahion\\GraduationThesis2_NS\\data\\data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train_yolov8s_aug_False, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov8s_aug_False, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2119531  ultralytics.nn.modules.head.Detect           [9, [128, 256, 512]]          \n",
      "Model summary: 129 layers, 11,139,083 parameters, 11,139,067 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 529.3239.1 MB/s, size: 20.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2_NS\\data\\train\\labels.cache... 64864 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 64864/64864  0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 664.7406.6 MB/s, size: 83.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2_NS\\data\\valid\\labels.cache... 1720 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1720/1720  0.0s\n",
      "Plotting labels to D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov8s_aug_False\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov8s_aug_False\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/30      3.64G      1.254      2.125      1.627         48        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 15.2it/s 4:27<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.1s0.1s\n",
      "                   all       1720       1720      0.207      0.505      0.246      0.135\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/30      3.86G      1.162      1.927      1.541         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.2it/s 4:10<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.7it/s 4.2s0.2s\n",
      "                   all       1720       1720       0.32      0.496      0.311        0.2\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/30      3.86G      1.116      1.826      1.503         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.6it/s 4:04<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.2it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.383      0.484      0.419      0.269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/30      3.86G      1.078       1.74      1.475         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.7it/s 4:03<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.4it/s 4.0s0.2s\n",
      "                   all       1720       1720      0.398      0.494      0.448      0.302\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/30      3.86G      1.056      1.677      1.454         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.7it/s 4:02<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.1it/s 4.1s0.1s\n",
      "                   all       1720       1720      0.439       0.55      0.488      0.331\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/30      3.86G      1.031      1.632       1.44         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.9it/s 4:00<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.464      0.535      0.509      0.348\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/30      3.86G      1.015      1.592      1.426         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:02<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.4it/s 4.0s0.1s\n",
      "                   all       1720       1720      0.478      0.566      0.533      0.368\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/30      3.86G       1.01      1.566      1.424         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.7it/s 4:03<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.1it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.506      0.569      0.554       0.39\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/30      3.86G          1      1.542      1.415         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.9it/s 4:00<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.0it/s 4.2s0.2s\n",
      "                   all       1720       1720      0.515       0.58      0.573        0.4\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/30      3.86G      0.991      1.526      1.408         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:02<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.0it/s 4.2s0.1s\n",
      "                   all       1720       1720      0.517      0.584      0.577      0.407\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/30      3.86G     0.9824      1.507      1.404         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.7it/s 4:03<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.2it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.545      0.573      0.588      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/30      3.86G     0.9723      1.489      1.396         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:01<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.4it/s 4.3s0.1s\n",
      "                   all       1720       1720      0.537      0.579        0.6      0.427\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/30      3.86G     0.9682      1.468      1.392         43        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:02<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.9it/s 4.2s0.2s\n",
      "                   all       1720       1720      0.536      0.594      0.607      0.432\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/30      3.86G     0.9628      1.449      1.388         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.7it/s 4:02<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.2it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.541      0.607      0.613      0.437\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/30      3.86G     0.9528      1.432      1.381         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:01<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.7it/s 4.3s0.1s\n",
      "                   all       1720       1720      0.542      0.609      0.619      0.443\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/30      3.86G     0.9507      1.424       1.38         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:01<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.9it/s 4.2s0.1s\n",
      "                   all       1720       1720      0.572      0.587      0.625      0.448\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/30      3.86G     0.9423      1.408      1.373         37        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:02<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.5it/s 4.0s0.1s\n",
      "                   all       1720       1720      0.573      0.586      0.631      0.453\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/30      3.86G     0.9355      1.392       1.37         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:01<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.6it/s 4.3s0.2s\n",
      "                   all       1720       1720      0.576      0.592      0.636      0.457\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/30      3.86G     0.9321      1.377      1.366         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:01<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.0s0.2s\n",
      "                   all       1720       1720      0.571      0.607       0.64      0.461\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/30      3.86G     0.9271      1.409       1.36         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.8it/s 4:02<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.574      0.608      0.644      0.463\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/30      3.86G      0.939      1.127      1.535         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 17.0it/s 3:59<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.7it/s 4.2s0.2s\n",
      "                   all       1720       1720      0.587      0.609      0.651       0.47\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/30      3.86G     0.9099       1.08      1.506         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 17.1it/s 3:57<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.4it/s 4.0s0.1s\n",
      "                   all       1720       1720      0.598      0.596       0.66      0.478\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/30      3.86G     0.8949      1.049       1.49         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 17.0it/s 3:59<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.2it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.609      0.604      0.666      0.483\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/30      3.86G     0.8812      1.027      1.475         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.9it/s 3:59<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.9it/s 4.2s0.2s\n",
      "                   all       1720       1720      0.624      0.597      0.672       0.49\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/30      3.86G     0.8667     0.9995      1.461         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 17.1it/s 3:57<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.616      0.608      0.678      0.495\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/30      3.86G     0.8542     0.9724      1.449         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 16.9it/s 3:59<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.631      0.596      0.683      0.501\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/30      3.86G     0.8443     0.9433       1.44         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 17.0it/s 3:59<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.644      0.592      0.687      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/30      3.86G     0.8297     0.9189      1.424         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 17.1it/s 3:57<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.0it/s 4.2s0.2s\n",
      "                   all       1720       1720      0.635      0.605      0.692       0.51\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/30      3.86G     0.8178     0.8931      1.414         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 17.0it/s 3:59<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.4it/s 4.0s0.1s\n",
      "                   all       1720       1720      0.649        0.6      0.697      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/30      3.86G      0.807     0.8713      1.403         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 17.0it/s 3:58<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.1it/s 4.1s0.2s\n",
      "                   all       1720       1720      0.662      0.606      0.702      0.519\n",
      "\n",
      "30 epochs completed in 2.062 hours.\n",
      "Optimizer stripped from D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov8s_aug_False\\weights\\last.pt, 22.5MB\n",
      "Optimizer stripped from D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov8s_aug_False\\weights\\best.pt, 22.5MB\n",
      "\n",
      "Validating D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov8s_aug_False\\weights\\best.pt...\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "Model summary (fused): 72 layers, 11,129,067 parameters, 0 gradients, 28.5 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 11.6it/s 4.7s0.1s\n",
      "                   all       1720       1720       0.65      0.612      0.702       0.52\n",
      "                 angry        258        258      0.578      0.643      0.706      0.534\n",
      "              contempt         82         82      0.613      0.561      0.671      0.549\n",
      "               disgust        108        108      0.625      0.572       0.67      0.564\n",
      "                  fear        107        107      0.588      0.682      0.686      0.546\n",
      "                 happy        387        387      0.813      0.842      0.898      0.679\n",
      "               natural        172        172      0.567      0.384      0.531      0.361\n",
      "                   sad        312        312      0.634      0.587      0.702      0.464\n",
      "                sleepy         38         38      0.739      0.521      0.671      0.384\n",
      "             surprised        256        256      0.694      0.715      0.783      0.594\n",
      "Speed: 0.2ms preprocess, 0.6ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov8s_aug_False\u001b[0m\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "Model summary (fused): 72 layers, 11,129,067 parameters, 0 gradients, 28.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 1003.8248.7 MB/s, size: 36.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2_NS\\data\\valid\\labels.cache... 1720 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1720/1720 1.7Mit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 108/108 20.6it/s 5.2s0.1s\n",
      "                   all       1720       1720      0.661      0.606      0.702       0.52\n",
      "                 angry        258        258      0.596      0.636      0.706      0.535\n",
      "              contempt         82         82      0.654      0.561      0.671      0.549\n",
      "               disgust        108        108      0.623      0.566       0.67      0.564\n",
      "                  fear        107        107      0.593      0.666      0.686      0.545\n",
      "                 happy        387        387      0.817      0.842      0.898      0.678\n",
      "               natural        172        172       0.59      0.384      0.531      0.362\n",
      "                   sad        312        312      0.644      0.571      0.702      0.466\n",
      "                sleepy         38         38      0.737      0.517      0.671      0.384\n",
      "             surprised        256        256      0.699      0.708      0.782      0.595\n",
      "Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2_NS\\runs\\detect\\val4\u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "üìà VISUALIZING TRAINING & VALIDATION ANALYSIS FOR: yolov8s (Aug: False)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "üìä EXTRACTING PERFORMANCE INDICATORS FOR: yolov8s (Aug: False)\n",
      "--------------------------------------------------\n",
      "layer                                    name                type  gradient  parameters               shape        mu     sigma\n",
      "    0                     model.0.conv.weight              Conv2d     False         864       [32, 3, 3, 3]   -0.0164      5.05        float32\n",
      "    0                       model.0.conv.bias              Conv2d     False          32                [32]     -3.18      9.22        float32\n",
      "    1                             model.0.act                SiLU     False           0                  []         -         -              -\n",
      "    2                     model.1.conv.weight              Conv2d     False       18432      [64, 32, 3, 3] -0.000272    0.0686        float32\n",
      "    2                       model.1.conv.bias              Conv2d     False          64                [64]     -1.48      7.88        float32\n",
      "    3                 model.2.cv1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  -0.00713    0.0995        float32\n",
      "    3                   model.2.cv1.conv.bias              Conv2d     False          64                [64]      0.41      3.97        float32\n",
      "    4                 model.2.cv2.conv.weight              Conv2d     False        6144      [64, 96, 1, 1]  -0.00414    0.0611        float32\n",
      "    4                   model.2.cv2.conv.bias              Conv2d     False          64                [64]     -1.97       4.8        float32\n",
      "    5             model.2.m.0.cv1.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00266    0.0718        float32\n",
      "    5               model.2.m.0.cv1.conv.bias              Conv2d     False          32                [32]     -1.86       6.2        float32\n",
      "    6             model.2.m.0.cv2.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00439    0.0621        float32\n",
      "    6               model.2.m.0.cv2.conv.bias              Conv2d     False          32                [32]       1.9      4.89        float32\n",
      "    7                     model.3.conv.weight              Conv2d     False       73728     [128, 64, 3, 3] -3.39e-06    0.0148        float32\n",
      "    7                       model.3.conv.bias              Conv2d     False         128               [128]     -1.23      3.68        float32\n",
      "    8                 model.4.cv1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1] -0.000415    0.0813        float32\n",
      "    8                   model.4.cv1.conv.bias              Conv2d     False         128               [128]     -1.66      4.45        float32\n",
      "    9                 model.4.cv2.conv.weight              Conv2d     False       32768    [128, 256, 1, 1]  3.01e-05    0.0321        float32\n",
      "    9                   model.4.cv2.conv.bias              Conv2d     False         128               [128]     -4.88      4.43        float32\n",
      "   10             model.4.m.0.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000271    0.0398        float32\n",
      "   10               model.4.m.0.cv1.conv.bias              Conv2d     False          64                [64]     -4.81      4.38        float32\n",
      "   11             model.4.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000858    0.0227        float32\n",
      "   11               model.4.m.0.cv2.conv.bias              Conv2d     False          64                [64]     -1.65      3.43        float32\n",
      "   12             model.4.m.1.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -0.00023    0.0135        float32\n",
      "   12               model.4.m.1.cv1.conv.bias              Conv2d     False          64                [64]     -5.23      3.93        float32\n",
      "   13             model.4.m.1.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000122    0.0365        float32\n",
      "   13               model.4.m.1.cv2.conv.bias              Conv2d     False          64                [64]     -2.06      4.11        float32\n",
      "   14                     model.5.conv.weight              Conv2d     False      294912    [256, 128, 3, 3]  5.47e-05   0.00769        float32\n",
      "   14                       model.5.conv.bias              Conv2d     False         256               [256]     -2.93      3.35        float32\n",
      "   15                 model.6.cv1.conv.weight              Conv2d     False       65536    [256, 256, 1, 1]  0.000291    0.0382        float32\n",
      "   15                   model.6.cv1.conv.bias              Conv2d     False         256               [256]     -4.02      4.63        float32\n",
      "   16                 model.6.cv2.conv.weight              Conv2d     False      131072    [256, 512, 1, 1] -0.000136    0.0108        float32\n",
      "   16                   model.6.cv2.conv.bias              Conv2d     False         256               [256]     -7.59      3.79        float32\n",
      "   17             model.6.m.0.cv1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -0.000143    0.0154        float32\n",
      "   17               model.6.m.0.cv1.conv.bias              Conv2d     False         128               [128]     -6.71      3.83        float32\n",
      "   18             model.6.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -0.000537     0.017        float32\n",
      "   18               model.6.m.0.cv2.conv.bias              Conv2d     False         128               [128]     -5.02       4.3        float32\n",
      "   19             model.6.m.1.cv1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -0.000315    0.0116        float32\n",
      "   19               model.6.m.1.cv1.conv.bias              Conv2d     False         128               [128]      -7.2      4.02        float32\n",
      "   20             model.6.m.1.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3]  -0.00122     0.044        float32\n",
      "   20               model.6.m.1.cv2.conv.bias              Conv2d     False         128               [128]     -3.02      3.57        float32\n",
      "   21                     model.7.conv.weight              Conv2d     False 1.17965e+06    [512, 256, 3, 3] -5.46e-06   0.00447        float32\n",
      "   21                       model.7.conv.bias              Conv2d     False         512               [512]     -4.29      3.59        float32\n",
      "   22                 model.8.cv1.conv.weight              Conv2d     False      262144    [512, 512, 1, 1] -1.17e-05   0.00872        float32\n",
      "   22                   model.8.cv1.conv.bias              Conv2d     False         512               [512]     -6.78      4.25        float32\n",
      "   23                 model.8.cv2.conv.weight              Conv2d     False      393216    [512, 768, 1, 1] -9.32e-05    0.0126        float32\n",
      "   23                   model.8.cv2.conv.bias              Conv2d     False         512               [512]     -4.21      3.77        float32\n",
      "   24             model.8.m.0.cv1.conv.weight              Conv2d     False      589824    [256, 256, 3, 3] -7.41e-05    0.0112        float32\n",
      "   24               model.8.m.0.cv1.conv.bias              Conv2d     False         256               [256]     -8.26      3.54        float32\n",
      "   25             model.8.m.0.cv2.conv.weight              Conv2d     False      589824    [256, 256, 3, 3] -5.19e-05   0.00898        float32\n",
      "   25               model.8.m.0.cv2.conv.bias              Conv2d     False         256               [256]     -5.26      4.17        float32\n",
      "   26                 model.9.cv1.conv.weight              Conv2d     False      131072    [256, 512, 1, 1] -0.000645    0.0165        float32\n",
      "   26                   model.9.cv1.conv.bias              Conv2d     False         256               [256]     -2.63      5.92        float32\n",
      "   27                 model.9.cv2.conv.weight              Conv2d     False      524288   [512, 1024, 1, 1] -9.54e-06    0.0104        float32\n",
      "   27                   model.9.cv2.conv.bias              Conv2d     False         512               [512]     -5.22      4.18        float32\n",
      "   28                               model.9.m           MaxPool2d     False           0                  []         -         -              -\n",
      "   29                                model.10            Upsample     False           0                  []         -         -              -\n",
      "   30                                model.11              Concat     False           0                  []         -         -              -\n",
      "   31                model.12.cv1.conv.weight              Conv2d     False      196608    [256, 768, 1, 1] -0.000477    0.0341        float32\n",
      "   31                  model.12.cv1.conv.bias              Conv2d     False         256               [256]     -5.24      3.85        float32\n",
      "   32                model.12.cv2.conv.weight              Conv2d     False       98304    [256, 384, 1, 1]  -0.00026    0.0271        float32\n",
      "   32                  model.12.cv2.conv.bias              Conv2d     False         256               [256]     -4.69      3.81        float32\n",
      "   33            model.12.m.0.cv1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3]  -0.00012    0.0149        float32\n",
      "   33              model.12.m.0.cv1.conv.bias              Conv2d     False         128               [128]     -7.43      3.69        float32\n",
      "   34            model.12.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -6.79e-05   0.00814        float32\n",
      "   34              model.12.m.0.cv2.conv.bias              Conv2d     False         128               [128]      -3.8      3.79        float32\n",
      "   35                                model.13            Upsample     False           0                  []         -         -              -\n",
      "   36                                model.14              Concat     False           0                  []         -         -              -\n",
      "   37                model.15.cv1.conv.weight              Conv2d     False       49152    [128, 384, 1, 1] -0.000107    0.0229        float32\n",
      "   37                  model.15.cv1.conv.bias              Conv2d     False         128               [128]     -3.76      4.87        float32\n",
      "   38                model.15.cv2.conv.weight              Conv2d     False       24576    [128, 192, 1, 1]   6.2e-05    0.0289        float32\n",
      "   38                  model.15.cv2.conv.bias              Conv2d     False         128               [128]     -4.39      4.19        float32\n",
      "   39            model.15.m.0.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000321    0.0282        float32\n",
      "   39              model.15.m.0.cv1.conv.bias              Conv2d     False          64                [64]     -5.06      4.56        float32\n",
      "   40            model.15.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -8.52e-05    0.0227        float32\n",
      "   40              model.15.m.0.cv2.conv.bias              Conv2d     False          64                [64]     -1.77      3.56        float32\n",
      "   41                    model.16.conv.weight              Conv2d     False      147456    [128, 128, 3, 3]  7.65e-05   0.00553        float32\n",
      "   41                      model.16.conv.bias              Conv2d     False         128               [128]     -3.48      3.97        float32\n",
      "   42                                model.17              Concat     False           0                  []         -         -              -\n",
      "   43                model.18.cv1.conv.weight              Conv2d     False       98304    [256, 384, 1, 1]  9.69e-05    0.0277        float32\n",
      "   43                  model.18.cv1.conv.bias              Conv2d     False         256               [256]      -4.8      4.26        float32\n",
      "   44                model.18.cv2.conv.weight              Conv2d     False       98304    [256, 384, 1, 1]  4.64e-06    0.0113        float32\n",
      "   44                  model.18.cv2.conv.bias              Conv2d     False         256               [256]     -7.25      3.19        float32\n",
      "   45            model.18.m.0.cv1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -4.88e-05    0.0061        float32\n",
      "   45              model.18.m.0.cv1.conv.bias              Conv2d     False         128               [128]      -7.5       3.4        float32\n",
      "   46            model.18.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3]  3.17e-05    0.0149        float32\n",
      "   46              model.18.m.0.cv2.conv.bias              Conv2d     False         128               [128]     -2.33      3.94        float32\n",
      "   47                    model.19.conv.weight              Conv2d     False      589824    [256, 256, 3, 3]  5.06e-06   0.00263        float32\n",
      "   47                      model.19.conv.bias              Conv2d     False         256               [256]     -5.04      3.53        float32\n",
      "   48                                model.20              Concat     False           0                  []         -         -              -\n",
      "   49                model.21.cv1.conv.weight              Conv2d     False      393216    [512, 768, 1, 1] -0.000288    0.0278        float32\n",
      "   49                  model.21.cv1.conv.bias              Conv2d     False         512               [512]     -6.61      3.84        float32\n",
      "   50                model.21.cv2.conv.weight              Conv2d     False      393216    [512, 768, 1, 1] -0.000105    0.0138        float32\n",
      "   50                  model.21.cv2.conv.bias              Conv2d     False         512               [512]     -7.23      3.42        float32\n",
      "   51            model.21.m.0.cv1.conv.weight              Conv2d     False      589824    [256, 256, 3, 3] -3.66e-05   0.00865        float32\n",
      "   51              model.21.m.0.cv1.conv.bias              Conv2d     False         256               [256]     -7.54      3.15        float32\n",
      "   52            model.21.m.0.cv2.conv.weight              Conv2d     False      589824    [256, 256, 3, 3] -6.89e-05   0.00891        float32\n",
      "   52              model.21.m.0.cv2.conv.bias              Conv2d     False         256               [256]     -4.53      3.73        float32\n",
      "   53            model.22.cv2.0.0.conv.weight              Conv2d     False       73728     [64, 128, 3, 3] -5.53e-05   0.00714        float32\n",
      "   53              model.22.cv2.0.0.conv.bias              Conv2d     False          64                [64]     -3.74      4.86        float32\n",
      "   54            model.22.cv2.0.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000261   0.00693        float32\n",
      "   54              model.22.cv2.0.1.conv.bias              Conv2d     False          64                [64]     -6.36      5.21        float32\n",
      "   55                 model.22.cv2.0.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   0.00526    0.0849        float32\n",
      "   55                   model.22.cv2.0.2.bias              Conv2d     False          64                [64]      2.14      1.69        float32\n",
      "   56            model.22.cv2.1.0.conv.weight              Conv2d     False      147456     [64, 256, 3, 3] -0.000184   0.00647        float32\n",
      "   56              model.22.cv2.1.0.conv.bias              Conv2d     False          64                [64]     -2.79      5.54        float32\n",
      "   57            model.22.cv2.1.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000207   0.00881        float32\n",
      "   57              model.22.cv2.1.1.conv.bias              Conv2d     False          64                [64]     -4.63      5.39        float32\n",
      "   58                 model.22.cv2.1.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   0.00671     0.135        float32\n",
      "   58                   model.22.cv2.1.2.bias              Conv2d     False          64                [64]      1.09      1.91        float32\n",
      "   59            model.22.cv2.2.0.conv.weight              Conv2d     False      294912     [64, 512, 3, 3] -5.95e-05   0.00781        float32\n",
      "   59              model.22.cv2.2.0.conv.bias              Conv2d     False          64                [64]     -2.36      4.29        float32\n",
      "   60            model.22.cv2.2.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000748    0.0108        float32\n",
      "   60              model.22.cv2.2.1.conv.bias              Conv2d     False          64                [64]    -0.393      2.82        float32\n",
      "   61                 model.22.cv2.2.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   -0.0307     0.303        float32\n",
      "   61                   model.22.cv2.2.2.bias              Conv2d     False          64                [64]     0.714      2.38        float32\n",
      "   62            model.22.cv3.0.0.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -4.37e-06   0.00284        float32\n",
      "   62              model.22.cv3.0.0.conv.bias              Conv2d     False         128               [128]     -6.51      3.62        float32\n",
      "   63            model.22.cv3.0.1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3]  0.000107   0.00559        float32\n",
      "   63              model.22.cv3.0.1.conv.bias              Conv2d     False         128               [128]      -7.2      3.74        float32\n",
      "   64                 model.22.cv3.0.2.weight              Conv2d     False        1152      [9, 128, 1, 1]  -0.00842    0.0759        float32\n",
      "   64                   model.22.cv3.0.2.bias              Conv2d     False           9                 [9]     -9.95      3.01        float32\n",
      "   65            model.22.cv3.1.0.conv.weight              Conv2d     False      294912    [128, 256, 3, 3] -9.31e-06   0.00368        float32\n",
      "   65              model.22.cv3.1.0.conv.bias              Conv2d     False         128               [128]     -6.85      3.77        float32\n",
      "   66            model.22.cv3.1.1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3]  5.28e-05   0.00593        float32\n",
      "   66              model.22.cv3.1.1.conv.bias              Conv2d     False         128               [128]     -7.68      3.38        float32\n",
      "   67                 model.22.cv3.1.2.weight              Conv2d     False        1152      [9, 128, 1, 1]   -0.0205     0.112        float32\n",
      "   67                   model.22.cv3.1.2.bias              Conv2d     False           9                 [9]     -5.86      1.05        float32\n",
      "   68            model.22.cv3.2.0.conv.weight              Conv2d     False      589824    [128, 512, 3, 3] -1.56e-05   0.00354        float32\n",
      "   68              model.22.cv3.2.0.conv.bias              Conv2d     False         128               [128]     -7.18      3.76        float32\n",
      "   69            model.22.cv3.2.1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -1.26e-05    0.0546        float32\n",
      "   69              model.22.cv3.2.1.conv.bias              Conv2d     False         128               [128]      -7.4      4.91        float32\n",
      "   70                 model.22.cv3.2.2.weight              Conv2d     False        1152      [9, 128, 1, 1]   -0.0693     0.258        float32\n",
      "   70                   model.22.cv3.2.2.bias              Conv2d     False           9                 [9]     -3.65     0.948        float32\n",
      "   71                model.22.dfl.conv.weight              Conv2d     False          16       [1, 16, 1, 1]       7.5      4.76        float32\n",
      "Model summary (fused): 72 layers, 11,129,067 parameters, 0 gradients, 28.5 GFLOPs\n",
      "\n",
      "============================================================\n",
      "üöÄ STARTING EXPERIMENT FOR MODEL: yolov10s (Aug: True)\n",
      "============================================================\n",
      "\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov10s.pt to 'yolov10s.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 15.9MB 23.1MB/s 0.7s.6s<2.6s\n",
      "New https://pypi.org/project/ultralytics/8.3.205 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=D:\\Virtual_Fahion\\GraduationThesis2_NS\\data\\data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train_yolov10s_aug_True, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov10s_aug_True, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1645766  ultralytics.nn.modules.head.v10Detect        [9, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,073,318 parameters, 8,073,302 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 534.8273.0 MB/s, size: 20.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2_NS\\data\\train\\labels.cache... 64864 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 64864/64864  0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 653.7379.4 MB/s, size: 83.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2_NS\\data\\valid\\labels.cache... 1720 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1720/1720 1.7Mit/s 0.0s\n",
      "Plotting labels to D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov10s_aug_True\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov10s_aug_True\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/30      4.77G      2.606       4.48      3.257         48        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.7it/s 6:17<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.5it/s 4.3s0.2s\n",
      "                   all       1720       1720      0.235      0.368      0.166     0.0911\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/30      5.03G      2.419      3.996      3.071         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.5it/s 5:52<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.6it/s 4.3s0.2s\n",
      "                   all       1720       1720      0.284       0.36      0.239      0.144\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/30      5.03G      2.316      3.806      2.989         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.8it/s 5:43<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.8it/s 4.2s0.2s\n",
      "                   all       1720       1720          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/30      5.03G      2.226      3.621      2.926         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.0it/s 5:39<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.7it/s 4.2s0.2s\n",
      "                   all       1720       1720      0.271       0.48      0.219      0.152\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/30      5.03G       2.17      3.465       2.88         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.0it/s 5:38<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.6it/s 4.3s0.2s\n",
      "                   all       1720       1720       0.45       0.48      0.448      0.306\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/30      5.03G      2.118      3.364       2.85         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.0it/s 5:37<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.6it/s 4.3s0.2s\n",
      "                   all       1720       1720      0.464      0.506      0.466      0.324\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/30      5.03G      2.093      3.278       2.83         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.0it/s 5:38<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.8it/s 4.2s0.2s\n",
      "                   all       1720       1720      0.465      0.528      0.489      0.339\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/30      5.03G      2.077      3.209       2.82         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.0it/s 5:37<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.4it/s 4.4s0.1s\n",
      "                   all       1720       1720      0.476      0.553      0.514      0.363\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/30      5.03G      2.061      3.159      2.807         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.0it/s 5:37<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.5it/s 4.3s0.2s\n",
      "                   all       1720       1720      0.511      0.545      0.531      0.379\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/30      5.03G      2.041      3.126      2.792         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.1it/s 5:36<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.5it/s 4.3s0.2s\n",
      "                   all       1720       1720      0.493      0.536      0.533      0.381\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/30      5.03G      2.035      3.077      2.789         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.1it/s 5:36<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.5it/s 4.3s0.2s\n",
      "                   all       1720       1720      0.524      0.553      0.553      0.398\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/30      5.03G      2.012      3.046      2.775         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.1it/s 5:35<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.8it/s 4.2s0.2s\n",
      "                   all       1720       1720      0.531      0.529      0.555      0.402\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/30      5.03G      1.999      3.011      2.768         43        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.0it/s 5:38<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.7it/s 4.2s0.2s\n",
      "                   all       1720       1720       0.54      0.525      0.562      0.407\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/30      5.03G      1.986      2.975      2.757         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.0it/s 5:38<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.8it/s 4.2s0.2s\n",
      "                   all       1720       1720      0.543       0.52      0.558      0.404\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/30      5.03G      1.967      2.933      2.745         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.0it/s 5:37<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.8it/s 4.2s0.2s\n",
      "                   all       1720       1720      0.536      0.527      0.557      0.403\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/30      5.03G      1.962      2.907      2.742         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.0it/s 5:38<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.8it/s 4.2s0.2s\n",
      "                   all       1720       1720       0.54      0.543      0.567      0.412\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/30      5.03G       1.94      2.875      2.726         37        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.0it/s 5:37<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.6it/s 4.3s0.2s\n",
      "                   all       1720       1720      0.542      0.547      0.572      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/30      5.03G      1.934       2.84      2.726         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.0it/s 5:39<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.5it/s 4.3s0.2s\n",
      "                   all       1720       1720      0.543      0.543      0.577      0.421\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/30      5.03G       1.92      2.803      2.715         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.0it/s 5:39<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.6it/s 4.3s0.2s\n",
      "                   all       1720       1720      0.553      0.534       0.58      0.423\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/30      5.03G      1.909      2.789      2.705         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.0it/s 5:38<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.7it/s 4.3s0.2s\n",
      "                   all       1720       1720      0.543      0.564      0.586      0.428\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/30      5.03G      1.866      2.318      3.011         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.1it/s 5:35<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.6it/s 4.3s0.2s\n",
      "                   all       1720       1720      0.538      0.567      0.591      0.434\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/30      5.03G      1.816       2.22       2.96         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.1it/s 5:36<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.7it/s 4.3s0.2s\n",
      "                   all       1720       1720       0.54      0.569      0.598       0.44\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/30      5.03G       1.79      2.153      2.933         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.1it/s 5:34<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.7it/s 4.2s0.2s\n",
      "                   all       1720       1720      0.544      0.576      0.602      0.444\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/30      5.03G      1.776      2.083      2.916         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.1it/s 5:36<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.7it/s 4.2s0.2s\n",
      "                   all       1720       1720      0.562      0.557      0.606      0.446\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/30      5.03G      1.749      2.034      2.892         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.1it/s 5:34<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.8it/s 4.2s0.2s\n",
      "                   all       1720       1720      0.562      0.583      0.611      0.452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/30      5.03G      1.724      1.976      2.868         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.2it/s 5:33<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.6it/s 4.3s0.2s\n",
      "                   all       1720       1720      0.577      0.589      0.618      0.456\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/30      5.03G      1.705      1.922       2.85         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.1it/s 5:35<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.2it/s 4.4s0.1s\n",
      "                   all       1720       1720      0.579      0.598      0.623      0.461\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/30      5.03G      1.679      1.874      2.823         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.2it/s 5:34<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.2it/s 4.4s0.1s\n",
      "                   all       1720       1720      0.596      0.597      0.629      0.465\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/30      5.03G      1.651      1.817      2.802         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.2it/s 5:34<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.3it/s 4.4s0.2s\n",
      "                   all       1720       1720      0.603      0.603      0.633      0.468\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/30      5.03G       1.63      1.769      2.782         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.2it/s 5:32<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.1it/s 4.5s0.2s\n",
      "                   all       1720       1720      0.615      0.604      0.637      0.471\n",
      "\n",
      "30 epochs completed in 2.867 hours.\n",
      "Optimizer stripped from D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov10s_aug_True\\weights\\last.pt, 16.5MB\n",
      "Optimizer stripped from D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov10s_aug_True\\weights\\best.pt, 16.5MB\n",
      "\n",
      "Validating D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov10s_aug_True\\weights\\best.pt...\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "YOLOv10s summary (fused): 106 layers, 7,221,483 parameters, 0 gradients, 21.4 GFLOPs\n",
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 2% ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 1/54 1.4it/s 0.2s<36.8sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 6% ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 3/54 3.3it/s 0.5s<15.7sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 7% ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 4/54 4.2it/s 0.6s<11.9sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 9% ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 5/54 5.4it/s 0.8s<9.1sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 13% ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 7/54 7.1it/s 0.9s<6.6sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 17% ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 9/54 8.1it/s 1.1s<5.5sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 20% ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 11/54 9.9it/s 1.3s<4.4sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 24% ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 13/54 11.1it/s 1.4s<3.7sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 28% ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 15/54 12.1it/s 1.6s<3.2sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 31% ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 17/54 12.7it/s 1.7s<2.9sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 35% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 19/54 13.3it/s 1.8s<2.6sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 39% ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 21/54 13.9it/s 2.0s<2.4sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 43% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 23/54 14.1it/s 2.1s<2.2sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 46% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 25/54 14.2it/s 2.2s<2.0sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 27/54 14.1it/s 2.4s<1.9sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 54% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 29/54 13.9it/s 2.5s<1.8sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 57% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 31/54 14.2it/s 2.7s<1.6sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 61% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 33/54 14.1it/s 2.8s<1.5sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 65% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ 35/54 14.3it/s 2.9s<1.3sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 69% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ 37/54 13.9it/s 3.1s<1.2sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 72% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 39/54 13.9it/s 3.2s<1.1sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 76% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ 41/54 13.8it/s 3.4s<0.9sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 80% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ 43/54 13.9it/s 3.5s<0.8sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 83% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ 45/54 14.1it/s 3.7s<0.6sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 87% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ 47/54 14.0it/s 3.8s<0.5sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 49/54 13.7it/s 4.0s<0.4sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 94% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ 51/54 13.9it/s 4.1s<0.2sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 98% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏ 53/54 14.9it/s 4.2s<0.1sWARNING Model does not support 'augment=True', reverting to single-scale prediction.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.7it/s 4.3s\n",
      "                   all       1720       1720      0.615      0.605      0.637      0.472\n",
      "                 angry        258        258      0.525      0.686      0.697      0.526\n",
      "              contempt         82         82      0.534      0.561      0.569      0.446\n",
      "               disgust        108        108      0.603      0.593      0.657       0.56\n",
      "                  fear        107        107      0.605      0.673       0.65      0.522\n",
      "                 happy        387        387      0.824      0.799      0.873      0.644\n",
      "               natural        172        172      0.483      0.547      0.464      0.323\n",
      "                   sad        312        312      0.491      0.624      0.604      0.409\n",
      "                sleepy         38         38      0.787      0.342      0.483      0.244\n",
      "             surprised        256        256      0.683      0.621      0.739      0.571\n",
      "Speed: 0.2ms preprocess, 0.8ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov10s_aug_True\u001b[0m\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "YOLOv10s summary (fused): 106 layers, 7,221,483 parameters, 0 gradients, 21.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 1043.7255.7 MB/s, size: 36.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2_NS\\data\\valid\\labels.cache... 1720 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1720/1720  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 108/108 22.2it/s 4.9s0.1s\n",
      "                   all       1720       1720      0.615      0.605      0.637      0.471\n",
      "                 angry        258        258      0.527       0.69      0.696      0.525\n",
      "              contempt         82         82      0.537      0.552       0.57      0.446\n",
      "               disgust        108        108      0.604      0.593      0.657       0.56\n",
      "                  fear        107        107      0.606      0.673      0.649      0.521\n",
      "                 happy        387        387       0.82      0.801      0.873      0.643\n",
      "               natural        172        172      0.483      0.547      0.463      0.323\n",
      "                   sad        312        312      0.491      0.622        0.6      0.408\n",
      "                sleepy         38         38      0.788      0.342      0.484      0.243\n",
      "             surprised        256        256      0.682      0.621      0.738      0.571\n",
      "Speed: 0.1ms preprocess, 1.2ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2_NS\\runs\\detect\\val5\u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "üìà VISUALIZING TRAINING & VALIDATION ANALYSIS FOR: yolov10s (Aug: True)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "üìä EXTRACTING PERFORMANCE INDICATORS FOR: yolov10s (Aug: True)\n",
      "--------------------------------------------------\n",
      "layer                                    name                type  gradient  parameters               shape        mu     sigma\n",
      "    0                     model.0.conv.weight              Conv2d     False         864       [32, 3, 3, 3]   -0.0376      4.72        float32\n",
      "    0                       model.0.conv.bias              Conv2d     False          32                [32]     -3.67      7.89        float32\n",
      "    1                             model.0.act                SiLU     False           0                  []         -         -              -\n",
      "    2                     model.1.conv.weight              Conv2d     False       18432      [64, 32, 3, 3] -0.000163    0.0479        float32\n",
      "    2                       model.1.conv.bias              Conv2d     False          64                [64]    -0.174      5.51        float32\n",
      "    3                 model.2.cv1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  -0.00638     0.103        float32\n",
      "    3                   model.2.cv1.conv.bias              Conv2d     False          64                [64]    -0.293      4.05        float32\n",
      "    4                 model.2.cv2.conv.weight              Conv2d     False        6144      [64, 96, 1, 1]  -0.00288    0.0501        float32\n",
      "    4                   model.2.cv2.conv.bias              Conv2d     False          64                [64]     -2.91      4.62        float32\n",
      "    5             model.2.m.0.cv1.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00242    0.0619        float32\n",
      "    5               model.2.m.0.cv1.conv.bias              Conv2d     False          32                [32]     -2.23      5.14        float32\n",
      "    6             model.2.m.0.cv2.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00227    0.0533        float32\n",
      "    6               model.2.m.0.cv2.conv.bias              Conv2d     False          32                [32]     0.884      4.69        float32\n",
      "    7                     model.3.conv.weight              Conv2d     False       73728     [128, 64, 3, 3]  0.000252    0.0164        float32\n",
      "    7                       model.3.conv.bias              Conv2d     False         128               [128]     -1.85      3.89        float32\n",
      "    8                 model.4.cv1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]  0.000238    0.0631        float32\n",
      "    8                   model.4.cv1.conv.bias              Conv2d     False         128               [128]      -2.3      4.55        float32\n",
      "    9                 model.4.cv2.conv.weight              Conv2d     False       32768    [128, 256, 1, 1]  0.000163    0.0275        float32\n",
      "    9                   model.4.cv2.conv.bias              Conv2d     False         128               [128]    -0.654      3.94        float32\n",
      "   10             model.4.m.0.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000701      0.04        float32\n",
      "   10               model.4.m.0.cv1.conv.bias              Conv2d     False          64                [64]     -4.78      4.87        float32\n",
      "   11             model.4.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  9.14e-05    0.0174        float32\n",
      "   11               model.4.m.0.cv2.conv.bias              Conv2d     False          64                [64]     -2.91      3.49        float32\n",
      "   12             model.4.m.1.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000192    0.0123        float32\n",
      "   12               model.4.m.1.cv1.conv.bias              Conv2d     False          64                [64]      -5.6      3.48        float32\n",
      "   13             model.4.m.1.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -7.51e-05    0.0246        float32\n",
      "   13               model.4.m.1.cv2.conv.bias              Conv2d     False          64                [64]     -2.42      3.97        float32\n",
      "   14                 model.5.cv1.conv.weight              Conv2d     False       32768    [256, 128, 1, 1]  -2.5e-05    0.0348        float32\n",
      "   14                   model.5.cv1.conv.bias              Conv2d     False         256               [256]     -2.49       2.8        float32\n",
      "   15                 model.5.cv2.conv.weight              Conv2d     False        2304      [256, 1, 3, 3]  -0.00449     0.307        float32\n",
      "   15                   model.5.cv2.conv.bias              Conv2d     False         256               [256]    -0.443      5.68        float32\n",
      "   16                         model.5.cv2.act            Identity     False           0                  []         -         -              -\n",
      "   17                 model.6.cv1.conv.weight              Conv2d     False       65536    [256, 256, 1, 1]  9.36e-05    0.0241        float32\n",
      "   17                   model.6.cv1.conv.bias              Conv2d     False         256               [256]     -3.17      5.05        float32\n",
      "   18                 model.6.cv2.conv.weight              Conv2d     False      131072    [256, 512, 1, 1] -6.77e-05    0.0124        float32\n",
      "   18                   model.6.cv2.conv.bias              Conv2d     False         256               [256]     -3.09      3.36        float32\n",
      "   19             model.6.m.0.cv1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -6.48e-05    0.0111        float32\n",
      "   19               model.6.m.0.cv1.conv.bias              Conv2d     False         128               [128]     -7.08      3.09        float32\n",
      "   20             model.6.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -9.64e-05   0.00802        float32\n",
      "   20               model.6.m.0.cv2.conv.bias              Conv2d     False         128               [128]     -6.73      3.14        float32\n",
      "   21             model.6.m.1.cv1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -0.000184   0.00897        float32\n",
      "   21               model.6.m.1.cv1.conv.bias              Conv2d     False         128               [128]     -8.01      3.28        float32\n",
      "   22             model.6.m.1.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -0.000396    0.0323        float32\n",
      "   22               model.6.m.1.cv2.conv.bias              Conv2d     False         128               [128]     -4.47      3.27        float32\n",
      "   23                 model.7.cv1.conv.weight              Conv2d     False      131072    [512, 256, 1, 1]   0.00015    0.0138        float32\n",
      "   23                   model.7.cv1.conv.bias              Conv2d     False         512               [512]     -1.59      3.13        float32\n",
      "   24                 model.7.cv2.conv.weight              Conv2d     False        4608      [512, 1, 3, 3]   0.00351     0.168        float32\n",
      "   24                   model.7.cv2.conv.bias              Conv2d     False         512               [512]   -0.0519      5.16        float32\n",
      "   25                         model.7.cv2.act            Identity     False           0                  []         -         -              -\n",
      "   26                 model.8.cv1.conv.weight              Conv2d     False      262144    [512, 512, 1, 1] -1.33e-05   0.00562        float32\n",
      "   26                   model.8.cv1.conv.bias              Conv2d     False         512               [512]     -4.66       4.1        float32\n",
      "   27                 model.8.cv2.conv.weight              Conv2d     False      393216    [512, 768, 1, 1]  -2.5e-05   0.00933        float32\n",
      "   27                   model.8.cv2.conv.bias              Conv2d     False         512               [512]     -4.25       3.4        float32\n",
      "   28           model.8.m.0.cv1.0.conv.weight              Conv2d     False        2304      [256, 1, 3, 3]    0.0152      1.28        float32\n",
      "   28             model.8.m.0.cv1.0.conv.bias              Conv2d     False         256               [256]     -1.55      2.52        float32\n",
      "   29           model.8.m.0.cv1.1.conv.weight              Conv2d     False      131072    [512, 256, 1, 1]  8.94e-05    0.0197        float32\n",
      "   29             model.8.m.0.cv1.1.conv.bias              Conv2d     False         512               [512]     -1.38      3.25        float32\n",
      "   30           model.8.m.0.cv1.2.conv.weight              Conv2d     False       25088      [512, 1, 7, 7] -0.000153     0.117        float32\n",
      "   30             model.8.m.0.cv1.2.conv.bias              Conv2d     False         512               [512]     -3.89       6.6        float32\n",
      "   31                   model.8.m.0.cv1.2.act                SiLU     False           0                  []         -         -              -\n",
      "   32           model.8.m.0.cv1.3.conv.weight              Conv2d     False      131072    [256, 512, 1, 1] -4.97e-06     0.012        float32\n",
      "   32             model.8.m.0.cv1.3.conv.bias              Conv2d     False         256               [256]    -0.827      4.98        float32\n",
      "   33           model.8.m.0.cv1.4.conv.weight              Conv2d     False        2304      [256, 1, 3, 3] -0.000949     0.307        float32\n",
      "   33             model.8.m.0.cv1.4.conv.bias              Conv2d     False         256               [256]    -0.848      4.82        float32\n",
      "   34                 model.9.cv1.conv.weight              Conv2d     False      131072    [256, 512, 1, 1] -0.000243    0.0141        float32\n",
      "   34                   model.9.cv1.conv.bias              Conv2d     False         256               [256]     -1.59      4.83        float32\n",
      "   35                 model.9.cv2.conv.weight              Conv2d     False      524288   [512, 1024, 1, 1] -6.73e-06    0.0055        float32\n",
      "   35                   model.9.cv2.conv.bias              Conv2d     False         512               [512]     -5.14      3.52        float32\n",
      "   36                               model.9.m           MaxPool2d     False           0                  []         -         -              -\n",
      "   37                model.10.cv1.conv.weight              Conv2d     False      262144    [512, 512, 1, 1] -8.77e-05    0.0352        float32\n",
      "   37                  model.10.cv1.conv.bias              Conv2d     False         512               [512]     -3.21      4.52        float32\n",
      "   38                model.10.cv2.conv.weight              Conv2d     False      262144    [512, 512, 1, 1] -6.69e-05   0.00878        float32\n",
      "   38                  model.10.cv2.conv.bias              Conv2d     False         512               [512]     -6.01      3.83        float32\n",
      "   39           model.10.attn.qkv.conv.weight              Conv2d     False      131072    [512, 256, 1, 1]    -5e-06    0.0109        float32\n",
      "   39             model.10.attn.qkv.conv.bias              Conv2d     False         512               [512]      2.51      27.9        float32\n",
      "   40                   model.10.attn.qkv.act            Identity     False           0                  []         -         -              -\n",
      "   41          model.10.attn.proj.conv.weight              Conv2d     False       65536    [256, 256, 1, 1]  1.07e-05   0.00596        float32\n",
      "   41            model.10.attn.proj.conv.bias              Conv2d     False         256               [256]    -0.225      5.39        float32\n",
      "   42                  model.10.attn.proj.act            Identity     False           0                  []         -         -              -\n",
      "   43            model.10.attn.pe.conv.weight              Conv2d     False        2304      [256, 1, 3, 3]  -0.00243    0.0135        float32\n",
      "   43              model.10.attn.pe.conv.bias              Conv2d     False         256               [256]    -0.185      3.48        float32\n",
      "   44                    model.10.attn.pe.act            Identity     False           0                  []         -         -              -\n",
      "   45              model.10.ffn.0.conv.weight              Conv2d     False      131072    [512, 256, 1, 1] -3.51e-08   0.00567        float32\n",
      "   45                model.10.ffn.0.conv.bias              Conv2d     False         512               [512]     -5.21      1.95        float32\n",
      "   46              model.10.ffn.1.conv.weight              Conv2d     False      131072    [256, 512, 1, 1]   9.7e-06   0.00501        float32\n",
      "   46                model.10.ffn.1.conv.bias              Conv2d     False         256               [256]    -0.483      4.83        float32\n",
      "   47                      model.10.ffn.1.act            Identity     False           0                  []         -         -              -\n",
      "   48                                model.11            Upsample     False           0                  []         -         -              -\n",
      "   49                                model.12              Concat     False           0                  []         -         -              -\n",
      "   50                model.13.cv1.conv.weight              Conv2d     False      196608    [256, 768, 1, 1] -2.12e-05    0.0108        float32\n",
      "   50                  model.13.cv1.conv.bias              Conv2d     False         256               [256]     -5.18      4.29        float32\n",
      "   51                model.13.cv2.conv.weight              Conv2d     False       98304    [256, 384, 1, 1] -0.000104     0.023        float32\n",
      "   51                  model.13.cv2.conv.bias              Conv2d     False         256               [256]     -5.47      3.66        float32\n",
      "   52            model.13.m.0.cv1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -5.52e-05   0.00913        float32\n",
      "   52              model.13.m.0.cv1.conv.bias              Conv2d     False         128               [128]     -8.04      2.81        float32\n",
      "   53            model.13.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3]  8.52e-06   0.00814        float32\n",
      "   53              model.13.m.0.cv2.conv.bias              Conv2d     False         128               [128]     -3.93      3.78        float32\n",
      "   54                                model.14            Upsample     False           0                  []         -         -              -\n",
      "   55                                model.15              Concat     False           0                  []         -         -              -\n",
      "   56                model.16.cv1.conv.weight              Conv2d     False       49152    [128, 384, 1, 1] -0.000159    0.0184        float32\n",
      "   56                  model.16.cv1.conv.bias              Conv2d     False         128               [128]     -3.81      5.31        float32\n",
      "   57                model.16.cv2.conv.weight              Conv2d     False       24576    [128, 192, 1, 1] -9.63e-05    0.0369        float32\n",
      "   57                  model.16.cv2.conv.bias              Conv2d     False         128               [128]     -5.59      4.12        float32\n",
      "   58            model.16.m.0.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -5.08e-05    0.0182        float32\n",
      "   58              model.16.m.0.cv1.conv.bias              Conv2d     False          64                [64]      -6.2      3.37        float32\n",
      "   59            model.16.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000123    0.0139        float32\n",
      "   59              model.16.m.0.cv2.conv.bias              Conv2d     False          64                [64]     -1.93      2.99        float32\n",
      "   60                    model.17.conv.weight              Conv2d     False      147456    [128, 128, 3, 3]  4.52e-05   0.00509        float32\n",
      "   60                      model.17.conv.bias              Conv2d     False         128               [128]     -3.36      3.24        float32\n",
      "   61                                model.18              Concat     False           0                  []         -         -              -\n",
      "   62                model.19.cv1.conv.weight              Conv2d     False       98304    [256, 384, 1, 1]   1.2e-05    0.0246        float32\n",
      "   62                  model.19.cv1.conv.bias              Conv2d     False         256               [256]     -5.32      4.52        float32\n",
      "   63                model.19.cv2.conv.weight              Conv2d     False       98304    [256, 384, 1, 1]   1.5e-05    0.0208        float32\n",
      "   63                  model.19.cv2.conv.bias              Conv2d     False         256               [256]     -4.82      3.74        float32\n",
      "   64            model.19.m.0.cv1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -7.35e-05   0.00984        float32\n",
      "   64              model.19.m.0.cv1.conv.bias              Conv2d     False         128               [128]     -7.08      3.68        float32\n",
      "   65            model.19.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -0.000146    0.0143        float32\n",
      "   65              model.19.m.0.cv2.conv.bias              Conv2d     False         128               [128]      -3.4      3.08        float32\n",
      "   66                model.20.cv1.conv.weight              Conv2d     False       65536    [256, 256, 1, 1] -6.12e-05    0.0278        float32\n",
      "   66                  model.20.cv1.conv.bias              Conv2d     False         256               [256]    -0.263      4.39        float32\n",
      "   67                model.20.cv2.conv.weight              Conv2d     False        2304      [256, 1, 3, 3]   0.00387     0.208        float32\n",
      "   67                  model.20.cv2.conv.bias              Conv2d     False         256               [256]     0.321      6.34        float32\n",
      "   68                        model.20.cv2.act            Identity     False           0                  []         -         -              -\n",
      "   69                                model.21              Concat     False           0                  []         -         -              -\n",
      "   70                model.22.cv1.conv.weight              Conv2d     False      393216    [512, 768, 1, 1]  1.18e-05    0.0122        float32\n",
      "   70                  model.22.cv1.conv.bias              Conv2d     False         512               [512]     -5.76      4.67        float32\n",
      "   71                model.22.cv2.conv.weight              Conv2d     False      393216    [512, 768, 1, 1]  1.13e-06    0.0152        float32\n",
      "   71                  model.22.cv2.conv.bias              Conv2d     False         512               [512]     -6.02      3.79        float32\n",
      "   72          model.22.m.0.cv1.0.conv.weight              Conv2d     False        2304      [256, 1, 3, 3]    0.0338       1.4        float32\n",
      "   72            model.22.m.0.cv1.0.conv.bias              Conv2d     False         256               [256]    -0.316      2.64        float32\n",
      "   73          model.22.m.0.cv1.1.conv.weight              Conv2d     False      131072    [512, 256, 1, 1]   0.00052    0.0317        float32\n",
      "   73            model.22.m.0.cv1.1.conv.bias              Conv2d     False         512               [512]     -1.66      3.36        float32\n",
      "   74          model.22.m.0.cv1.2.conv.weight              Conv2d     False       25088      [512, 1, 7, 7]   0.00519     0.196        float32\n",
      "   74            model.22.m.0.cv1.2.conv.bias              Conv2d     False         512               [512]     -2.86      6.37        float32\n",
      "   75                  model.22.m.0.cv1.2.act                SiLU     False           0                  []         -         -              -\n",
      "   76          model.22.m.0.cv1.3.conv.weight              Conv2d     False      131072    [256, 512, 1, 1] -0.000362    0.0209        float32\n",
      "   76            model.22.m.0.cv1.3.conv.bias              Conv2d     False         256               [256]    0.0629      4.24        float32\n",
      "   77          model.22.m.0.cv1.4.conv.weight              Conv2d     False        2304      [256, 1, 3, 3]    0.0281     0.523        float32\n",
      "   77            model.22.m.0.cv1.4.conv.bias              Conv2d     False         256               [256]    -0.508      4.43        float32\n",
      "   78                          model.23.cv2.0            Identity     False           0                  []         -         -              -\n",
      "   79                model.23.dfl.conv.weight              Conv2d     False          16       [1, 16, 1, 1]       7.5      4.76        float32\n",
      "   80    model.23.one2one_cv2.0.0.conv.weight              Conv2d     False       73728     [64, 128, 3, 3] -0.000103   0.00675        float32\n",
      "   80      model.23.one2one_cv2.0.0.conv.bias              Conv2d     False          64                [64]     -3.01      4.63        float32\n",
      "   81            model.23.one2one_cv2.0.0.act                SiLU     False           0                  []         -         -              -\n",
      "   82    model.23.one2one_cv2.0.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -5.3e-05    0.0046        float32\n",
      "   82      model.23.one2one_cv2.0.1.conv.bias              Conv2d     False          64                [64]     -7.42       3.8        float32\n",
      "   83         model.23.one2one_cv2.0.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   0.00365    0.0687        float32\n",
      "   83           model.23.one2one_cv2.0.2.bias              Conv2d     False          64                [64]      1.88      2.35        float32\n",
      "   84    model.23.one2one_cv2.1.0.conv.weight              Conv2d     False      147456     [64, 256, 3, 3] -3.42e-05   0.00329        float32\n",
      "   84      model.23.one2one_cv2.1.0.conv.bias              Conv2d     False          64                [64]     -4.97      4.62        float32\n",
      "   85    model.23.one2one_cv2.1.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000101   0.00599        float32\n",
      "   85      model.23.one2one_cv2.1.1.conv.bias              Conv2d     False          64                [64]     -6.57      4.53        float32\n",
      "   86         model.23.one2one_cv2.1.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   0.00215     0.111        float32\n",
      "   86           model.23.one2one_cv2.1.2.bias              Conv2d     False          64                [64] -0.000851      2.96        float32\n",
      "   87    model.23.one2one_cv2.2.0.conv.weight              Conv2d     False      294912     [64, 512, 3, 3] -7.42e-05   0.00327        float32\n",
      "   87      model.23.one2one_cv2.2.0.conv.bias              Conv2d     False          64                [64]     -2.77      5.16        float32\n",
      "   88    model.23.one2one_cv2.2.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000345   0.00857        float32\n",
      "   88      model.23.one2one_cv2.2.1.conv.bias              Conv2d     False          64                [64]     -1.94      4.13        float32\n",
      "   89         model.23.one2one_cv2.2.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   -0.0344     0.325        float32\n",
      "   89           model.23.one2one_cv2.2.2.bias              Conv2d     False          64                [64]    -0.155      3.23        float32\n",
      "   90  model.23.one2one_cv3.0.0.0.conv.weight              Conv2d     False        1152      [128, 1, 3, 3]   -0.0203     0.675        float32\n",
      "   90    model.23.one2one_cv3.0.0.0.conv.bias              Conv2d     False         128               [128]      9.29      25.5        float32\n",
      "   91          model.23.one2one_cv3.0.0.0.act                SiLU     False           0                  []         -         -              -\n",
      "   92  model.23.one2one_cv3.0.0.1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]  0.000267    0.0246        float32\n",
      "   92    model.23.one2one_cv3.0.0.1.conv.bias              Conv2d     False         128               [128]     -1.64      11.1        float32\n",
      "   93  model.23.one2one_cv3.0.1.0.conv.weight              Conv2d     False        1152      [128, 1, 3, 3]  -0.00325     0.105        float32\n",
      "   93    model.23.one2one_cv3.0.1.0.conv.bias              Conv2d     False         128               [128]      4.14      21.1        float32\n",
      "   94  model.23.one2one_cv3.0.1.1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]    -0.002    0.0283        float32\n",
      "   94    model.23.one2one_cv3.0.1.1.conv.bias              Conv2d     False         128               [128]    -0.131      14.7        float32\n",
      "   95         model.23.one2one_cv3.0.2.weight              Conv2d     False        1152      [9, 128, 1, 1]   -0.0113    0.0663        float32\n",
      "   95           model.23.one2one_cv3.0.2.bias              Conv2d     False           9                 [9]     -11.6      4.63        float32\n",
      "   96  model.23.one2one_cv3.1.0.0.conv.weight              Conv2d     False        2304      [256, 1, 3, 3]    0.0317     0.783        float32\n",
      "   96    model.23.one2one_cv3.1.0.0.conv.bias              Conv2d     False         256               [256]    0.0996      4.73        float32\n",
      "   97  model.23.one2one_cv3.1.0.1.conv.weight              Conv2d     False       32768    [128, 256, 1, 1]  0.000144    0.0179        float32\n",
      "   97    model.23.one2one_cv3.1.0.1.conv.bias              Conv2d     False         128               [128]     0.417      3.65        float32\n",
      "   98  model.23.one2one_cv3.1.1.0.conv.weight              Conv2d     False        1152      [128, 1, 3, 3]    0.0178     0.487        float32\n",
      "   98    model.23.one2one_cv3.1.1.0.conv.bias              Conv2d     False         128               [128]     -1.02      4.91        float32\n",
      "   99  model.23.one2one_cv3.1.1.1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1] -0.000163    0.0435        float32\n",
      "   99    model.23.one2one_cv3.1.1.1.conv.bias              Conv2d     False         128               [128]     -4.21      4.59        float32\n",
      "  100         model.23.one2one_cv3.1.2.weight              Conv2d     False        1152      [9, 128, 1, 1]   -0.0207    0.0979        float32\n",
      "  100           model.23.one2one_cv3.1.2.bias              Conv2d     False           9                 [9]     -8.34      3.11        float32\n",
      "  101  model.23.one2one_cv3.2.0.0.conv.weight              Conv2d     False        4608      [512, 1, 3, 3]    0.0188     0.728        float32\n",
      "  101    model.23.one2one_cv3.2.0.0.conv.bias              Conv2d     False         512               [512]    -0.863      4.75        float32\n",
      "  102  model.23.one2one_cv3.2.0.1.conv.weight              Conv2d     False       65536    [128, 512, 1, 1]  -0.00016    0.0275        float32\n",
      "  102    model.23.one2one_cv3.2.0.1.conv.bias              Conv2d     False         128               [128]   -0.0843      4.63        float32\n",
      "  103  model.23.one2one_cv3.2.1.0.conv.weight              Conv2d     False        1152      [128, 1, 3, 3]    0.0126     0.345        float32\n",
      "  103    model.23.one2one_cv3.2.1.0.conv.bias              Conv2d     False         128               [128]     -2.29      5.02        float32\n",
      "  104  model.23.one2one_cv3.2.1.1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]  0.000393    0.0857        float32\n",
      "  104    model.23.one2one_cv3.2.1.1.conv.bias              Conv2d     False         128               [128]     -1.32      6.62        float32\n",
      "  105         model.23.one2one_cv3.2.2.weight              Conv2d     False        1152      [9, 128, 1, 1]   -0.0802     0.248        float32\n",
      "  105           model.23.one2one_cv3.2.2.bias              Conv2d     False           9                 [9]     -4.36      1.16        float32\n",
      "YOLOv10s summary (fused): 106 layers, 7,221,483 parameters, 0 gradients, 21.4 GFLOPs\n",
      "\n",
      "============================================================\n",
      "üöÄ STARTING EXPERIMENT FOR MODEL: yolov10s (Aug: False)\n",
      "============================================================\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.205 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=D:\\Virtual_Fahion\\GraduationThesis2_NS\\data\\data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train_yolov10s_aug_False, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov10s_aug_False, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1645766  ultralytics.nn.modules.head.v10Detect        [9, [128, 256, 512]]          \n",
      "YOLOv10s summary: 234 layers, 8,073,318 parameters, 8,073,302 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 537.8250.4 MB/s, size: 20.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2_NS\\data\\train\\labels.cache... 64864 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 64864/64864 64.8Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 1267.2877.3 MB/s, size: 83.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2_NS\\data\\valid\\labels.cache... 1720 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1720/1720 1.7Mit/s 0.0s\n",
      "Plotting labels to D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov10s_aug_False\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov10s_aug_False\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/30      4.86G      2.606       4.48      3.257         48        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 10.8it/s 6:16<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.5it/s 4.3s0.2s\n",
      "                   all       1720       1720      0.235      0.368      0.166     0.0911\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/30      5.09G      2.419      3.996      3.071         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.5it/s 5:53<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.5it/s 4.3s0.2s\n",
      "                   all       1720       1720      0.284       0.36      0.239      0.144\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/30      5.09G      2.316      3.806      2.989         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.8it/s 5:44<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.9it/s 4.2s0.2s\n",
      "                   all       1720       1720          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/30      5.09G      2.226      3.621      2.926         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.9it/s 5:40<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.7it/s 4.3s0.2s\n",
      "                   all       1720       1720      0.271       0.48      0.219      0.152\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/30      5.09G       2.17      3.465       2.88         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.0it/s 5:38<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.5it/s 4.3s0.2s\n",
      "                   all       1720       1720       0.45       0.48      0.448      0.306\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/30      5.09G      2.118      3.364       2.85         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.0it/s 5:38<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.4it/s 4.3s0.1s\n",
      "                   all       1720       1720      0.464      0.506      0.466      0.324\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/30      5.09G      2.093      3.278       2.83         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 11.9it/s 5:40<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.1it/s 4.5s0.1s\n",
      "                   all       1720       1720      0.465      0.528      0.489      0.339\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/30      5.09G      2.077      3.209       2.82         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.0it/s 5:37<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.4it/s 4.4s0.1s\n",
      "                   all       1720       1720      0.476      0.553      0.514      0.363\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/30      5.09G      2.061      3.159      2.807         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.1it/s 5:36<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 11.9it/s 4.5s0.1s\n",
      "                   all       1720       1720      0.511      0.545      0.531      0.379\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/30      5.09G      2.041      3.126      2.792         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.1it/s 5:35<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.7it/s 4.3s0.2s\n",
      "                   all       1720       1720      0.493      0.536      0.533      0.381\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/30      5.09G      2.035      3.077      2.789         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.0it/s 5:37<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.7it/s 4.3s0.2s\n",
      "                   all       1720       1720      0.524      0.553      0.553      0.398\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/30      5.09G      2.012      3.046      2.775         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.0it/s 5:38<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.7it/s 4.2s0.2s\n",
      "                   all       1720       1720      0.531      0.529      0.555      0.402\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/30      5.09G      1.999      3.011      2.768         43        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.0it/s 5:38<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.7it/s 4.3s0.2s\n",
      "                   all       1720       1720       0.54      0.525      0.562      0.407\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/30      5.09G      1.986      2.975      2.757         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.0it/s 5:38<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.8it/s 4.2s0.2s\n",
      "                   all       1720       1720      0.543       0.52      0.558      0.404\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/30      5.09G      1.967      2.933      2.745         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.0it/s 5:37<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.6it/s 4.3s0.1s\n",
      "                   all       1720       1720      0.536      0.527      0.557      0.403\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/30      5.09G      1.962      2.907      2.742         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.0it/s 5:37<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.6it/s 4.3s0.1s\n",
      "                   all       1720       1720       0.54      0.543      0.567      0.412\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/30      5.09G       1.94      2.875      2.726         37        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.0it/s 5:37<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.8it/s 4.2s0.2s\n",
      "                   all       1720       1720      0.542      0.547      0.572      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/30      5.09G      1.934       2.84      2.726         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.0it/s 5:37<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.7it/s 4.3s0.2s\n",
      "                   all       1720       1720      0.543      0.543      0.577      0.421\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/30      5.09G       1.92      2.803      2.715         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.0it/s 5:37<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.8it/s 4.2s0.2s\n",
      "                   all       1720       1720      0.553      0.534       0.58      0.423\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/30      5.09G      1.909      2.789      2.705         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.0it/s 5:37<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.8it/s 4.2s0.2s\n",
      "                   all       1720       1720      0.543      0.564      0.586      0.428\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/30      5.09G      1.866      2.318      3.011         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.1it/s 5:34<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.6it/s 4.3s0.2s\n",
      "                   all       1720       1720      0.538      0.567      0.591      0.434\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/30      5.09G      1.816       2.22       2.96         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.1it/s 5:34<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.7it/s 4.2s0.2s\n",
      "                   all       1720       1720       0.54      0.569      0.598       0.44\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/30      5.09G       1.79      2.153      2.933         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.1it/s 5:35<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.5it/s 4.3s0.1s\n",
      "                   all       1720       1720      0.544      0.576      0.602      0.444\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/30      5.09G      1.776      2.083      2.916         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.1it/s 5:34<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.2it/s 4.4s0.1s\n",
      "                   all       1720       1720      0.562      0.557      0.606      0.446\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/30      5.09G      1.749      2.034      2.892         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.1it/s 5:34<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.1it/s 4.5s0.1s\n",
      "                   all       1720       1720      0.562      0.583      0.611      0.452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/30      5.09G      1.724      1.976      2.868         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.2it/s 5:33<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.6it/s 4.3s0.2s\n",
      "                   all       1720       1720      0.577      0.589      0.618      0.456\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/30      5.09G      1.705      1.922       2.85         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.1it/s 5:36<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.6it/s 4.3s0.2s\n",
      "                   all       1720       1720      0.579      0.598      0.623      0.461\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/30      5.09G      1.679      1.874      2.823         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.1it/s 5:34<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 11.8it/s 4.6s0.1s\n",
      "                   all       1720       1720      0.596      0.597      0.629      0.465\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/30      5.09G      1.651      1.817      2.802         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.2it/s 5:32<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.3it/s 4.4s0.2s\n",
      "                   all       1720       1720      0.603      0.603      0.633      0.468\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/30      5.09G       1.63      1.769      2.782         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4054/4054 12.1it/s 5:34<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 12.8it/s 4.2s0.2s\n",
      "                   all       1720       1720      0.615      0.604      0.637      0.471\n",
      "\n",
      "30 epochs completed in 2.866 hours.\n",
      "Optimizer stripped from D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov10s_aug_False\\weights\\last.pt, 16.5MB\n",
      "Optimizer stripped from D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov10s_aug_False\\weights\\best.pt, 16.5MB\n",
      "\n",
      "Validating D:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov10s_aug_False\\weights\\best.pt...\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "YOLOv10s summary (fused): 106 layers, 7,221,483 parameters, 0 gradients, 21.4 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 13.3it/s 4.1s0.1s\n",
      "                   all       1720       1720      0.615      0.605      0.637      0.472\n",
      "                 angry        258        258      0.525      0.686      0.697      0.526\n",
      "              contempt         82         82      0.534      0.561      0.569      0.446\n",
      "               disgust        108        108      0.603      0.593      0.657       0.56\n",
      "                  fear        107        107      0.605      0.673       0.65      0.522\n",
      "                 happy        387        387      0.824      0.799      0.873      0.644\n",
      "               natural        172        172      0.483      0.547      0.464      0.323\n",
      "                   sad        312        312      0.491      0.624      0.604      0.409\n",
      "                sleepy         38         38      0.787      0.342      0.483      0.244\n",
      "             surprised        256        256      0.683      0.621      0.739      0.571\n",
      "Speed: 0.1ms preprocess, 0.7ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2_NS\\saveModels\\train_yolov10s_aug_False\u001b[0m\n",
      "Ultralytics 8.3.198  Python-3.9.23 torch-2.7.1+cu118 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 49140MiB)\n",
      "YOLOv10s summary (fused): 106 layers, 7,221,483 parameters, 0 gradients, 21.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 1062.0284.2 MB/s, size: 36.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Virtual_Fahion\\GraduationThesis2_NS\\data\\valid\\labels.cache... 1720 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1720/1720 1.7Mit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 108/108 21.7it/s 5.0s0.0s\n",
      "                   all       1720       1720      0.615      0.605      0.637      0.471\n",
      "                 angry        258        258      0.527       0.69      0.696      0.525\n",
      "              contempt         82         82      0.537      0.552       0.57      0.446\n",
      "               disgust        108        108      0.604      0.593      0.657       0.56\n",
      "                  fear        107        107      0.606      0.673      0.649      0.521\n",
      "                 happy        387        387       0.82      0.801      0.873      0.643\n",
      "               natural        172        172      0.483      0.547      0.463      0.323\n",
      "                   sad        312        312      0.491      0.622        0.6      0.408\n",
      "                sleepy         38         38      0.788      0.342      0.484      0.243\n",
      "             surprised        256        256      0.682      0.621      0.738      0.571\n",
      "Speed: 0.1ms preprocess, 1.2ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Virtual_Fahion\\GraduationThesis2_NS\\runs\\detect\\val6\u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "üìà VISUALIZING TRAINING & VALIDATION ANALYSIS FOR: yolov10s (Aug: False)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "üìä EXTRACTING PERFORMANCE INDICATORS FOR: yolov10s (Aug: False)\n",
      "--------------------------------------------------\n",
      "layer                                    name                type  gradient  parameters               shape        mu     sigma\n",
      "    0                     model.0.conv.weight              Conv2d     False         864       [32, 3, 3, 3]   -0.0376      4.72        float32\n",
      "    0                       model.0.conv.bias              Conv2d     False          32                [32]     -3.67      7.89        float32\n",
      "    1                             model.0.act                SiLU     False           0                  []         -         -              -\n",
      "    2                     model.1.conv.weight              Conv2d     False       18432      [64, 32, 3, 3] -0.000163    0.0479        float32\n",
      "    2                       model.1.conv.bias              Conv2d     False          64                [64]    -0.174      5.51        float32\n",
      "    3                 model.2.cv1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  -0.00638     0.103        float32\n",
      "    3                   model.2.cv1.conv.bias              Conv2d     False          64                [64]    -0.293      4.05        float32\n",
      "    4                 model.2.cv2.conv.weight              Conv2d     False        6144      [64, 96, 1, 1]  -0.00288    0.0501        float32\n",
      "    4                   model.2.cv2.conv.bias              Conv2d     False          64                [64]     -2.91      4.62        float32\n",
      "    5             model.2.m.0.cv1.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00242    0.0619        float32\n",
      "    5               model.2.m.0.cv1.conv.bias              Conv2d     False          32                [32]     -2.23      5.14        float32\n",
      "    6             model.2.m.0.cv2.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00227    0.0533        float32\n",
      "    6               model.2.m.0.cv2.conv.bias              Conv2d     False          32                [32]     0.884      4.69        float32\n",
      "    7                     model.3.conv.weight              Conv2d     False       73728     [128, 64, 3, 3]  0.000252    0.0164        float32\n",
      "    7                       model.3.conv.bias              Conv2d     False         128               [128]     -1.85      3.89        float32\n",
      "    8                 model.4.cv1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]  0.000238    0.0631        float32\n",
      "    8                   model.4.cv1.conv.bias              Conv2d     False         128               [128]      -2.3      4.55        float32\n",
      "    9                 model.4.cv2.conv.weight              Conv2d     False       32768    [128, 256, 1, 1]  0.000163    0.0275        float32\n",
      "    9                   model.4.cv2.conv.bias              Conv2d     False         128               [128]    -0.654      3.94        float32\n",
      "   10             model.4.m.0.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000701      0.04        float32\n",
      "   10               model.4.m.0.cv1.conv.bias              Conv2d     False          64                [64]     -4.78      4.87        float32\n",
      "   11             model.4.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  9.14e-05    0.0174        float32\n",
      "   11               model.4.m.0.cv2.conv.bias              Conv2d     False          64                [64]     -2.91      3.49        float32\n",
      "   12             model.4.m.1.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000192    0.0123        float32\n",
      "   12               model.4.m.1.cv1.conv.bias              Conv2d     False          64                [64]      -5.6      3.48        float32\n",
      "   13             model.4.m.1.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -7.51e-05    0.0246        float32\n",
      "   13               model.4.m.1.cv2.conv.bias              Conv2d     False          64                [64]     -2.42      3.97        float32\n",
      "   14                 model.5.cv1.conv.weight              Conv2d     False       32768    [256, 128, 1, 1]  -2.5e-05    0.0348        float32\n",
      "   14                   model.5.cv1.conv.bias              Conv2d     False         256               [256]     -2.49       2.8        float32\n",
      "   15                 model.5.cv2.conv.weight              Conv2d     False        2304      [256, 1, 3, 3]  -0.00449     0.307        float32\n",
      "   15                   model.5.cv2.conv.bias              Conv2d     False         256               [256]    -0.443      5.68        float32\n",
      "   16                         model.5.cv2.act            Identity     False           0                  []         -         -              -\n",
      "   17                 model.6.cv1.conv.weight              Conv2d     False       65536    [256, 256, 1, 1]  9.36e-05    0.0241        float32\n",
      "   17                   model.6.cv1.conv.bias              Conv2d     False         256               [256]     -3.17      5.05        float32\n",
      "   18                 model.6.cv2.conv.weight              Conv2d     False      131072    [256, 512, 1, 1] -6.77e-05    0.0124        float32\n",
      "   18                   model.6.cv2.conv.bias              Conv2d     False         256               [256]     -3.09      3.36        float32\n",
      "   19             model.6.m.0.cv1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -6.48e-05    0.0111        float32\n",
      "   19               model.6.m.0.cv1.conv.bias              Conv2d     False         128               [128]     -7.08      3.09        float32\n",
      "   20             model.6.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -9.64e-05   0.00802        float32\n",
      "   20               model.6.m.0.cv2.conv.bias              Conv2d     False         128               [128]     -6.73      3.14        float32\n",
      "   21             model.6.m.1.cv1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -0.000184   0.00897        float32\n",
      "   21               model.6.m.1.cv1.conv.bias              Conv2d     False         128               [128]     -8.01      3.28        float32\n",
      "   22             model.6.m.1.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -0.000396    0.0323        float32\n",
      "   22               model.6.m.1.cv2.conv.bias              Conv2d     False         128               [128]     -4.47      3.27        float32\n",
      "   23                 model.7.cv1.conv.weight              Conv2d     False      131072    [512, 256, 1, 1]   0.00015    0.0138        float32\n",
      "   23                   model.7.cv1.conv.bias              Conv2d     False         512               [512]     -1.59      3.13        float32\n",
      "   24                 model.7.cv2.conv.weight              Conv2d     False        4608      [512, 1, 3, 3]   0.00351     0.168        float32\n",
      "   24                   model.7.cv2.conv.bias              Conv2d     False         512               [512]   -0.0519      5.16        float32\n",
      "   25                         model.7.cv2.act            Identity     False           0                  []         -         -              -\n",
      "   26                 model.8.cv1.conv.weight              Conv2d     False      262144    [512, 512, 1, 1] -1.33e-05   0.00562        float32\n",
      "   26                   model.8.cv1.conv.bias              Conv2d     False         512               [512]     -4.66       4.1        float32\n",
      "   27                 model.8.cv2.conv.weight              Conv2d     False      393216    [512, 768, 1, 1]  -2.5e-05   0.00933        float32\n",
      "   27                   model.8.cv2.conv.bias              Conv2d     False         512               [512]     -4.25       3.4        float32\n",
      "   28           model.8.m.0.cv1.0.conv.weight              Conv2d     False        2304      [256, 1, 3, 3]    0.0152      1.28        float32\n",
      "   28             model.8.m.0.cv1.0.conv.bias              Conv2d     False         256               [256]     -1.55      2.52        float32\n",
      "   29           model.8.m.0.cv1.1.conv.weight              Conv2d     False      131072    [512, 256, 1, 1]  8.94e-05    0.0197        float32\n",
      "   29             model.8.m.0.cv1.1.conv.bias              Conv2d     False         512               [512]     -1.38      3.25        float32\n",
      "   30           model.8.m.0.cv1.2.conv.weight              Conv2d     False       25088      [512, 1, 7, 7] -0.000153     0.117        float32\n",
      "   30             model.8.m.0.cv1.2.conv.bias              Conv2d     False         512               [512]     -3.89       6.6        float32\n",
      "   31                   model.8.m.0.cv1.2.act                SiLU     False           0                  []         -         -              -\n",
      "   32           model.8.m.0.cv1.3.conv.weight              Conv2d     False      131072    [256, 512, 1, 1] -4.97e-06     0.012        float32\n",
      "   32             model.8.m.0.cv1.3.conv.bias              Conv2d     False         256               [256]    -0.827      4.98        float32\n",
      "   33           model.8.m.0.cv1.4.conv.weight              Conv2d     False        2304      [256, 1, 3, 3] -0.000949     0.307        float32\n",
      "   33             model.8.m.0.cv1.4.conv.bias              Conv2d     False         256               [256]    -0.848      4.82        float32\n",
      "   34                 model.9.cv1.conv.weight              Conv2d     False      131072    [256, 512, 1, 1] -0.000243    0.0141        float32\n",
      "   34                   model.9.cv1.conv.bias              Conv2d     False         256               [256]     -1.59      4.83        float32\n",
      "   35                 model.9.cv2.conv.weight              Conv2d     False      524288   [512, 1024, 1, 1] -6.73e-06    0.0055        float32\n",
      "   35                   model.9.cv2.conv.bias              Conv2d     False         512               [512]     -5.14      3.52        float32\n",
      "   36                               model.9.m           MaxPool2d     False           0                  []         -         -              -\n",
      "   37                model.10.cv1.conv.weight              Conv2d     False      262144    [512, 512, 1, 1] -8.77e-05    0.0352        float32\n",
      "   37                  model.10.cv1.conv.bias              Conv2d     False         512               [512]     -3.21      4.52        float32\n",
      "   38                model.10.cv2.conv.weight              Conv2d     False      262144    [512, 512, 1, 1] -6.69e-05   0.00878        float32\n",
      "   38                  model.10.cv2.conv.bias              Conv2d     False         512               [512]     -6.01      3.83        float32\n",
      "   39           model.10.attn.qkv.conv.weight              Conv2d     False      131072    [512, 256, 1, 1]    -5e-06    0.0109        float32\n",
      "   39             model.10.attn.qkv.conv.bias              Conv2d     False         512               [512]      2.51      27.9        float32\n",
      "   40                   model.10.attn.qkv.act            Identity     False           0                  []         -         -              -\n",
      "   41          model.10.attn.proj.conv.weight              Conv2d     False       65536    [256, 256, 1, 1]  1.07e-05   0.00596        float32\n",
      "   41            model.10.attn.proj.conv.bias              Conv2d     False         256               [256]    -0.225      5.39        float32\n",
      "   42                  model.10.attn.proj.act            Identity     False           0                  []         -         -              -\n",
      "   43            model.10.attn.pe.conv.weight              Conv2d     False        2304      [256, 1, 3, 3]  -0.00243    0.0135        float32\n",
      "   43              model.10.attn.pe.conv.bias              Conv2d     False         256               [256]    -0.185      3.48        float32\n",
      "   44                    model.10.attn.pe.act            Identity     False           0                  []         -         -              -\n",
      "   45              model.10.ffn.0.conv.weight              Conv2d     False      131072    [512, 256, 1, 1] -3.51e-08   0.00567        float32\n",
      "   45                model.10.ffn.0.conv.bias              Conv2d     False         512               [512]     -5.21      1.95        float32\n",
      "   46              model.10.ffn.1.conv.weight              Conv2d     False      131072    [256, 512, 1, 1]   9.7e-06   0.00501        float32\n",
      "   46                model.10.ffn.1.conv.bias              Conv2d     False         256               [256]    -0.483      4.83        float32\n",
      "   47                      model.10.ffn.1.act            Identity     False           0                  []         -         -              -\n",
      "   48                                model.11            Upsample     False           0                  []         -         -              -\n",
      "   49                                model.12              Concat     False           0                  []         -         -              -\n",
      "   50                model.13.cv1.conv.weight              Conv2d     False      196608    [256, 768, 1, 1] -2.12e-05    0.0108        float32\n",
      "   50                  model.13.cv1.conv.bias              Conv2d     False         256               [256]     -5.18      4.29        float32\n",
      "   51                model.13.cv2.conv.weight              Conv2d     False       98304    [256, 384, 1, 1] -0.000104     0.023        float32\n",
      "   51                  model.13.cv2.conv.bias              Conv2d     False         256               [256]     -5.47      3.66        float32\n",
      "   52            model.13.m.0.cv1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -5.52e-05   0.00913        float32\n",
      "   52              model.13.m.0.cv1.conv.bias              Conv2d     False         128               [128]     -8.04      2.81        float32\n",
      "   53            model.13.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3]  8.52e-06   0.00814        float32\n",
      "   53              model.13.m.0.cv2.conv.bias              Conv2d     False         128               [128]     -3.93      3.78        float32\n",
      "   54                                model.14            Upsample     False           0                  []         -         -              -\n",
      "   55                                model.15              Concat     False           0                  []         -         -              -\n",
      "   56                model.16.cv1.conv.weight              Conv2d     False       49152    [128, 384, 1, 1] -0.000159    0.0184        float32\n",
      "   56                  model.16.cv1.conv.bias              Conv2d     False         128               [128]     -3.81      5.31        float32\n",
      "   57                model.16.cv2.conv.weight              Conv2d     False       24576    [128, 192, 1, 1] -9.63e-05    0.0369        float32\n",
      "   57                  model.16.cv2.conv.bias              Conv2d     False         128               [128]     -5.59      4.12        float32\n",
      "   58            model.16.m.0.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -5.08e-05    0.0182        float32\n",
      "   58              model.16.m.0.cv1.conv.bias              Conv2d     False          64                [64]      -6.2      3.37        float32\n",
      "   59            model.16.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000123    0.0139        float32\n",
      "   59              model.16.m.0.cv2.conv.bias              Conv2d     False          64                [64]     -1.93      2.99        float32\n",
      "   60                    model.17.conv.weight              Conv2d     False      147456    [128, 128, 3, 3]  4.52e-05   0.00509        float32\n",
      "   60                      model.17.conv.bias              Conv2d     False         128               [128]     -3.36      3.24        float32\n",
      "   61                                model.18              Concat     False           0                  []         -         -              -\n",
      "   62                model.19.cv1.conv.weight              Conv2d     False       98304    [256, 384, 1, 1]   1.2e-05    0.0246        float32\n",
      "   62                  model.19.cv1.conv.bias              Conv2d     False         256               [256]     -5.32      4.52        float32\n",
      "   63                model.19.cv2.conv.weight              Conv2d     False       98304    [256, 384, 1, 1]   1.5e-05    0.0208        float32\n",
      "   63                  model.19.cv2.conv.bias              Conv2d     False         256               [256]     -4.82      3.74        float32\n",
      "   64            model.19.m.0.cv1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -7.35e-05   0.00984        float32\n",
      "   64              model.19.m.0.cv1.conv.bias              Conv2d     False         128               [128]     -7.08      3.68        float32\n",
      "   65            model.19.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -0.000146    0.0143        float32\n",
      "   65              model.19.m.0.cv2.conv.bias              Conv2d     False         128               [128]      -3.4      3.08        float32\n",
      "   66                model.20.cv1.conv.weight              Conv2d     False       65536    [256, 256, 1, 1] -6.12e-05    0.0278        float32\n",
      "   66                  model.20.cv1.conv.bias              Conv2d     False         256               [256]    -0.263      4.39        float32\n",
      "   67                model.20.cv2.conv.weight              Conv2d     False        2304      [256, 1, 3, 3]   0.00387     0.208        float32\n",
      "   67                  model.20.cv2.conv.bias              Conv2d     False         256               [256]     0.321      6.34        float32\n",
      "   68                        model.20.cv2.act            Identity     False           0                  []         -         -              -\n",
      "   69                                model.21              Concat     False           0                  []         -         -              -\n",
      "   70                model.22.cv1.conv.weight              Conv2d     False      393216    [512, 768, 1, 1]  1.18e-05    0.0122        float32\n",
      "   70                  model.22.cv1.conv.bias              Conv2d     False         512               [512]     -5.76      4.67        float32\n",
      "   71                model.22.cv2.conv.weight              Conv2d     False      393216    [512, 768, 1, 1]  1.13e-06    0.0152        float32\n",
      "   71                  model.22.cv2.conv.bias              Conv2d     False         512               [512]     -6.02      3.79        float32\n",
      "   72          model.22.m.0.cv1.0.conv.weight              Conv2d     False        2304      [256, 1, 3, 3]    0.0338       1.4        float32\n",
      "   72            model.22.m.0.cv1.0.conv.bias              Conv2d     False         256               [256]    -0.316      2.64        float32\n",
      "   73          model.22.m.0.cv1.1.conv.weight              Conv2d     False      131072    [512, 256, 1, 1]   0.00052    0.0317        float32\n",
      "   73            model.22.m.0.cv1.1.conv.bias              Conv2d     False         512               [512]     -1.66      3.36        float32\n",
      "   74          model.22.m.0.cv1.2.conv.weight              Conv2d     False       25088      [512, 1, 7, 7]   0.00519     0.196        float32\n",
      "   74            model.22.m.0.cv1.2.conv.bias              Conv2d     False         512               [512]     -2.86      6.37        float32\n",
      "   75                  model.22.m.0.cv1.2.act                SiLU     False           0                  []         -         -              -\n",
      "   76          model.22.m.0.cv1.3.conv.weight              Conv2d     False      131072    [256, 512, 1, 1] -0.000362    0.0209        float32\n",
      "   76            model.22.m.0.cv1.3.conv.bias              Conv2d     False         256               [256]    0.0629      4.24        float32\n",
      "   77          model.22.m.0.cv1.4.conv.weight              Conv2d     False        2304      [256, 1, 3, 3]    0.0281     0.523        float32\n",
      "   77            model.22.m.0.cv1.4.conv.bias              Conv2d     False         256               [256]    -0.508      4.43        float32\n",
      "   78                          model.23.cv2.0            Identity     False           0                  []         -         -              -\n",
      "   79                model.23.dfl.conv.weight              Conv2d     False          16       [1, 16, 1, 1]       7.5      4.76        float32\n",
      "   80    model.23.one2one_cv2.0.0.conv.weight              Conv2d     False       73728     [64, 128, 3, 3] -0.000103   0.00675        float32\n",
      "   80      model.23.one2one_cv2.0.0.conv.bias              Conv2d     False          64                [64]     -3.01      4.63        float32\n",
      "   81            model.23.one2one_cv2.0.0.act                SiLU     False           0                  []         -         -              -\n",
      "   82    model.23.one2one_cv2.0.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -5.3e-05    0.0046        float32\n",
      "   82      model.23.one2one_cv2.0.1.conv.bias              Conv2d     False          64                [64]     -7.42       3.8        float32\n",
      "   83         model.23.one2one_cv2.0.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   0.00365    0.0687        float32\n",
      "   83           model.23.one2one_cv2.0.2.bias              Conv2d     False          64                [64]      1.88      2.35        float32\n",
      "   84    model.23.one2one_cv2.1.0.conv.weight              Conv2d     False      147456     [64, 256, 3, 3] -3.42e-05   0.00329        float32\n",
      "   84      model.23.one2one_cv2.1.0.conv.bias              Conv2d     False          64                [64]     -4.97      4.62        float32\n",
      "   85    model.23.one2one_cv2.1.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000101   0.00599        float32\n",
      "   85      model.23.one2one_cv2.1.1.conv.bias              Conv2d     False          64                [64]     -6.57      4.53        float32\n",
      "   86         model.23.one2one_cv2.1.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   0.00215     0.111        float32\n",
      "   86           model.23.one2one_cv2.1.2.bias              Conv2d     False          64                [64] -0.000851      2.96        float32\n",
      "   87    model.23.one2one_cv2.2.0.conv.weight              Conv2d     False      294912     [64, 512, 3, 3] -7.42e-05   0.00327        float32\n",
      "   87      model.23.one2one_cv2.2.0.conv.bias              Conv2d     False          64                [64]     -2.77      5.16        float32\n",
      "   88    model.23.one2one_cv2.2.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000345   0.00857        float32\n",
      "   88      model.23.one2one_cv2.2.1.conv.bias              Conv2d     False          64                [64]     -1.94      4.13        float32\n",
      "   89         model.23.one2one_cv2.2.2.weight              Conv2d     False        4096      [64, 64, 1, 1]   -0.0344     0.325        float32\n",
      "   89           model.23.one2one_cv2.2.2.bias              Conv2d     False          64                [64]    -0.155      3.23        float32\n",
      "   90  model.23.one2one_cv3.0.0.0.conv.weight              Conv2d     False        1152      [128, 1, 3, 3]   -0.0203     0.675        float32\n",
      "   90    model.23.one2one_cv3.0.0.0.conv.bias              Conv2d     False         128               [128]      9.29      25.5        float32\n",
      "   91          model.23.one2one_cv3.0.0.0.act                SiLU     False           0                  []         -         -              -\n",
      "   92  model.23.one2one_cv3.0.0.1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]  0.000267    0.0246        float32\n",
      "   92    model.23.one2one_cv3.0.0.1.conv.bias              Conv2d     False         128               [128]     -1.64      11.1        float32\n",
      "   93  model.23.one2one_cv3.0.1.0.conv.weight              Conv2d     False        1152      [128, 1, 3, 3]  -0.00325     0.105        float32\n",
      "   93    model.23.one2one_cv3.0.1.0.conv.bias              Conv2d     False         128               [128]      4.14      21.1        float32\n",
      "   94  model.23.one2one_cv3.0.1.1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]    -0.002    0.0283        float32\n",
      "   94    model.23.one2one_cv3.0.1.1.conv.bias              Conv2d     False         128               [128]    -0.131      14.7        float32\n",
      "   95         model.23.one2one_cv3.0.2.weight              Conv2d     False        1152      [9, 128, 1, 1]   -0.0113    0.0663        float32\n",
      "   95           model.23.one2one_cv3.0.2.bias              Conv2d     False           9                 [9]     -11.6      4.63        float32\n",
      "   96  model.23.one2one_cv3.1.0.0.conv.weight              Conv2d     False        2304      [256, 1, 3, 3]    0.0317     0.783        float32\n",
      "   96    model.23.one2one_cv3.1.0.0.conv.bias              Conv2d     False         256               [256]    0.0996      4.73        float32\n",
      "   97  model.23.one2one_cv3.1.0.1.conv.weight              Conv2d     False       32768    [128, 256, 1, 1]  0.000144    0.0179        float32\n",
      "   97    model.23.one2one_cv3.1.0.1.conv.bias              Conv2d     False         128               [128]     0.417      3.65        float32\n",
      "   98  model.23.one2one_cv3.1.1.0.conv.weight              Conv2d     False        1152      [128, 1, 3, 3]    0.0178     0.487        float32\n",
      "   98    model.23.one2one_cv3.1.1.0.conv.bias              Conv2d     False         128               [128]     -1.02      4.91        float32\n",
      "   99  model.23.one2one_cv3.1.1.1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1] -0.000163    0.0435        float32\n",
      "   99    model.23.one2one_cv3.1.1.1.conv.bias              Conv2d     False         128               [128]     -4.21      4.59        float32\n",
      "  100         model.23.one2one_cv3.1.2.weight              Conv2d     False        1152      [9, 128, 1, 1]   -0.0207    0.0979        float32\n",
      "  100           model.23.one2one_cv3.1.2.bias              Conv2d     False           9                 [9]     -8.34      3.11        float32\n",
      "  101  model.23.one2one_cv3.2.0.0.conv.weight              Conv2d     False        4608      [512, 1, 3, 3]    0.0188     0.728        float32\n",
      "  101    model.23.one2one_cv3.2.0.0.conv.bias              Conv2d     False         512               [512]    -0.863      4.75        float32\n",
      "  102  model.23.one2one_cv3.2.0.1.conv.weight              Conv2d     False       65536    [128, 512, 1, 1]  -0.00016    0.0275        float32\n",
      "  102    model.23.one2one_cv3.2.0.1.conv.bias              Conv2d     False         128               [128]   -0.0843      4.63        float32\n",
      "  103  model.23.one2one_cv3.2.1.0.conv.weight              Conv2d     False        1152      [128, 1, 3, 3]    0.0126     0.345        float32\n",
      "  103    model.23.one2one_cv3.2.1.0.conv.bias              Conv2d     False         128               [128]     -2.29      5.02        float32\n",
      "  104  model.23.one2one_cv3.2.1.1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]  0.000393    0.0857        float32\n",
      "  104    model.23.one2one_cv3.2.1.1.conv.bias              Conv2d     False         128               [128]     -1.32      6.62        float32\n",
      "  105         model.23.one2one_cv3.2.2.weight              Conv2d     False        1152      [9, 128, 1, 1]   -0.0802     0.248        float32\n",
      "  105           model.23.one2one_cv3.2.2.bias              Conv2d     False           9                 [9]     -4.36      1.16        float32\n",
      "YOLOv10s summary (fused): 106 layers, 7,221,483 parameters, 0 gradients, 21.4 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# 3. Î™®Îç∏Î≥Ñ, Ï¶ùÍ∞ï ÏòµÏÖòÎ≥Ñ ÌïôÏäµ, Í≤ÄÏ¶ù Î∞è Í≤∞Í≥º Î∂ÑÏÑù\n",
    "# --------------------------------------------------------------------------\n",
    "all_results_summary = []\n",
    "\n",
    "for model_name in MODELS_TO_TEST:\n",
    "    for augment_status in AUGMENT_OPTIONS:\n",
    "        \n",
    "        run_name = f'train_{model_name}_aug_{augment_status}'\n",
    "        display_name = f'{model_name} (Aug: {augment_status})'\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"üöÄ STARTING EXPERIMENT FOR MODEL: {display_name}\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "        # 1. Î™®Îç∏ ÌïôÏäµ\n",
    "        model = YOLO(f\"{model_name}.pt\")\n",
    "        model.train(\n",
    "            data=data_yaml_path, epochs=EPOCHS, batch=BATCH_SIZE, imgsz=IMG_SIZE,\n",
    "            device=DEVICE, project=MODEL_SAVE_DIR, name=run_name,\n",
    "            exist_ok=True, save=True, pretrained=True, \n",
    "            augment=augment_status, plots=True, optimizer=OPTIMIZER\n",
    "        )\n",
    "\n",
    "        # 2. Í∞ÄÏû• ÏÑ±Îä• Ï¢ãÏùÄ Î™®Îç∏ Î°úÎìú\n",
    "        best_model_path = os.path.join(MODEL_SAVE_DIR, run_name, 'weights', 'best.pt')\n",
    "        best_model = YOLO(best_model_path)\n",
    "\n",
    "        # 3. Î™®Îç∏ ÏÑ±Îä• Í≤ÄÏ¶ù\n",
    "        val_results = best_model.val(\n",
    "            data=data_yaml_path, split='val', batch=BATCH_SIZE,\n",
    "            imgsz=IMG_SIZE, device=DEVICE, plots=True\n",
    "        )\n",
    "        \n",
    "        # ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ [ Ïã†Í∑ú Ï∂îÍ∞ÄÎêú Î∂ÄÎ∂Ñ ] ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ\n",
    "        # 4. ÌïôÏäµ Í≥ºÏ†ï Î∞è ÌÅ¥ÎûòÏä§Î≥Ñ ÏÑ±Îä• ÏãúÍ∞ÅÌôî\n",
    "        print(\"\\n\" + \"-\"*50)\n",
    "        print(f\"üìà VISUALIZING TRAINING & VALIDATION ANALYSIS FOR: {display_name}\")\n",
    "        print(\"-\"*50)\n",
    "        \n",
    "        # 2Í∞úÏùò Í∑∏ÎûòÌîÑÎ•º ÎÇòÎûÄÌûà Í∑∏Î¶¥ ÎèÑÌôîÏßÄ Ï§ÄÎπÑ\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "        fig.suptitle(f'Analysis for {display_name}', fontsize=16, weight='bold')\n",
    "\n",
    "        # 4-1. ÌïôÏäµ Í≥ºÏ†ï Í∑∏ÎûòÌîÑ (results.png) Î∂àÎü¨Ïò§Í∏∞\n",
    "        results_png_path = os.path.join(MODEL_SAVE_DIR, run_name, 'results.png')\n",
    "        if os.path.exists(results_png_path):\n",
    "            img_results = cv2.imread(results_png_path)\n",
    "            axes[0].imshow(cv2.cvtColor(img_results, cv2.COLOR_BGR2RGB))\n",
    "            axes[0].set_title('Training & Validation Curves')\n",
    "            axes[0].axis('off')\n",
    "        else:\n",
    "            axes[0].text(0.5, 0.5, 'results.png not found', ha='center'); axes[0].axis('off')\n",
    "\n",
    "        # 4-2. ÌÅ¥ÎûòÏä§Î≥Ñ ÌòºÎèô ÌñâÎ†¨ (confusion_matrix.png) Î∂àÎü¨Ïò§Í∏∞\n",
    "        cm_png_path = os.path.join(MODEL_SAVE_DIR, run_name, 'confusion_matrix.png')\n",
    "        if os.path.exists(cm_png_path):\n",
    "            img_cm = cv2.imread(cm_png_path)\n",
    "            axes[1].imshow(cv2.cvtColor(img_cm, cv2.COLOR_BGR2RGB))\n",
    "            axes[1].set_title('Confusion Matrix')\n",
    "            axes[1].axis('off')\n",
    "        else:\n",
    "            axes[1].text(0.5, 0.5, 'confusion_matrix.png not found', ha='center'); axes[1].axis('off')\n",
    "            \n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()        \n",
    "\n",
    "        # 5. ÏµúÏ¢Ö ÌèâÍ∞Ä ÏßÄÌëú Ï∂îÏ∂ú\n",
    "        print(\"\\n\" + \"-\"*50)\n",
    "        print(f\"üìä EXTRACTING PERFORMANCE INDICATORS FOR: {display_name}\")\n",
    "        print(\"-\"*50)\n",
    "        \n",
    "        map50 = val_results.box.map50\n",
    "        precision = val_results.box.p.mean()\n",
    "        recall = val_results.box.r.mean()\n",
    "        \n",
    "        speed = val_results.speed\n",
    "        latency_ms = speed['preprocess'] + speed['inference'] + speed['postprocess']\n",
    "        \n",
    "        info = model_info(best_model.model, detailed=True, imgsz=IMG_SIZE)\n",
    "        params_m = info[1] / 1e6 \n",
    "        gflops = info[3]\n",
    "\n",
    "        # 6. ÌÜµÌï© Í≤∞Í≥º Î¶¨Ïä§Ìä∏Ïóê Ï∂îÍ∞Ä\n",
    "        all_results_summary.append({\n",
    "            \"Model\": display_name, \"mAP@50\": map50, \"Precision\": precision,\n",
    "            \"Recall\": recall, \"Latency (ms)\": latency_ms,\n",
    "            \"Parameters (M)\": params_m, \"GFLOPs\": gflops\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8016889-c180-4ef9-a489-72cf0199b614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üèÜ FINAL RESULTS SUMMARY FOR ALL MODELS üèÜ\n",
      "============================================================\n",
      "\n",
      "                      mAP@50 Precision Recall Latency (ms) Parameters (M) GFLOPs\n",
      "Model                                                                           \n",
      "yolov8s (Aug: False)   0.702     0.661  0.606         1.71          11.13  28.45\n",
      "yolov8s (Aug: True)    0.697     0.652  0.616         1.71          11.13  28.45\n",
      "yolov5s (Aug: True)    0.659     0.615  0.613         1.66           9.12  23.85\n",
      "yolov5s (Aug: False)   0.659     0.615  0.613         1.61           9.12  23.85\n",
      "yolov10s (Aug: True)   0.637     0.615  0.605         1.44           7.22  21.43\n",
      "yolov10s (Aug: False)  0.637     0.615  0.605         1.45           7.22  21.43\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# 4. Î™®Îì† Î™®Îç∏ Ïã§Ìóò Í≤∞Í≥º ÌÜµÌï© ÎπÑÍµê Î∂ÑÏÑù\n",
    "# --------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üèÜ FINAL RESULTS SUMMARY FOR ALL MODELS üèÜ\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "summary_df = pd.DataFrame(all_results_summary).set_index(\"Model\")\n",
    "print(summary_df.sort_values(by=\"mAP@50\", ascending=False).to_string(formatters={\n",
    "    'mAP@50': '{:.3f}'.format, 'Precision': '{:.3f}'.format, 'Recall': '{:.3f}'.format,\n",
    "    'Latency (ms)': '{:.2f}'.format, 'Parameters (M)': '{:.2f}'.format, 'GFLOPs': '{:.2f}'.format\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e176afbd-68ad-4929-8789-cce9544ac615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================================================\n",
      "üìà VISUALIZING PERFORMANCE COMPARISON üìà\n",
      "============================================================\n",
      "\n",
      "\n",
      "Accuracy vs. Latency tradeoff plot saved to 'tradeoff_plot.png'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual performance comparison plots saved to 'comparison_plots.png'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "üéâ All experiments completed.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# 5. ÏÑ±Îä• ÏßÄÌëú ÏãúÍ∞ÅÌôî\n",
    "# --------------------------------------------------------------------------\n",
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"üìà VISUALIZING PERFORMANCE COMPARISON üìà\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# 1. Ï†ïÌôïÎèÑ/ÏÜçÎèÑ Ìä∏Î†àÏù¥ÎìúÏò§ÌîÑ ÏãúÍ∞ÅÌôî (Scatter Plot)\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    data=summary_df, x=\"Latency (ms)\", y=\"mAP@50\",\n",
    "    hue=\"Model\", size=\"Parameters (M)\", sizes=(100, 1000),\n",
    "    alpha=0.8, palette=\"viridis\", ax=ax\n",
    ")\n",
    "ax.set_title(\"Accuracy vs. Latency Trade-off\", fontsize=18, weight='bold')\n",
    "ax.set_xlabel(\"Latency (ms) - Lower is Faster\", fontsize=12)\n",
    "ax.set_ylabel(\"mAP@50 - Higher is Better\", fontsize=12)\n",
    "ax.legend(title=\"Model\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "for i, row in summary_df.iterrows():\n",
    "    ax.text(row['Latency (ms)']+0.1, row['mAP@50'], i, fontsize=9, ha='left')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ [ Ïã†Í∑ú Ï∂îÍ∞ÄÎêú Î∂ÄÎ∂Ñ ] ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ\n",
    "# ÌòÑÏû¨ Í∑∏Î¶ºÏùÑ ÌååÏùºÎ°ú Ï†ÄÏû• (plt.show() Ïù¥Ï†ÑÏóê Ìò∏Ï∂ú)\n",
    "plt.savefig('tradeoff_plot.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\nAccuracy vs. Latency tradeoff plot saved to 'tradeoff_plot.png'\")\n",
    "# ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ [ Ïó¨Í∏∞ÍπåÏßÄ Ïã†Í∑ú Ï∂îÍ∞ÄÎêú Î∂ÄÎ∂Ñ ] ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 2. Í∞úÎ≥Ñ ÏÑ±Îä• ÏßÄÌëú ÎπÑÍµê (Bar Plots)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
    "fig.suptitle('Individual Performance Indicator Comparison', fontsize=20, weight='bold')\n",
    "metrics_to_plot = [\"mAP@50\", \"Latency (ms)\", \"Parameters (M)\", \"GFLOPs\"]\n",
    "for ax, metric in zip(axes.flatten(), metrics_to_plot):\n",
    "    ascending = True if \"Latency\" in metric or \"Parameters\" in metric or \"GFLOPs\" in metric else False\n",
    "    sorted_df = summary_df.sort_values(by=metric, ascending=ascending)\n",
    "    colors = plt.cm.plasma(np.linspace(0, 1, len(sorted_df)))\n",
    "    bars = ax.barh(sorted_df.index, sorted_df[metric], color=colors)\n",
    "    ax.set_title(metric, fontsize=14)\n",
    "    ax.set_xlabel(\"Value\", fontsize=12)\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        ax.text(width * 1.01, bar.get_y() + bar.get_height()/2., f'{width:.2f}',\n",
    "                va='center', ha='left', fontsize=10)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "# ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ [ Ïã†Í∑ú Ï∂îÍ∞ÄÎêú Î∂ÄÎ∂Ñ ] ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ\n",
    "# ÌòÑÏû¨ Í∑∏Î¶ºÏùÑ ÌååÏùºÎ°ú Ï†ÄÏû• (plt.show() Ïù¥Ï†ÑÏóê Ìò∏Ï∂ú)\n",
    "plt.savefig('comparison_plots.png', dpi=300)\n",
    "print(\"Individual performance comparison plots saved to 'comparison_plots.png'\")\n",
    "# ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ [ Ïó¨Í∏∞ÍπåÏßÄ Ïã†Í∑ú Ï∂îÍ∞ÄÎêú Î∂ÄÎ∂Ñ ] ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\\nüéâ All experiments completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GraduationThesis",
   "language": "python",
   "name": "graduationthesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
