# CNN 모델 학습 프로젝트 (VGG-16 기반)

## I. 데이터 설명

### 데이터 구성
- **수집 데이터**: 3명의 사진 (각각 100장의 학습 데이터, 20장의 테스트 데이터)으로 총 360장.
- **데이터 사용**:
  - 학습 데이터의 30%를 검증 데이터로 활용.
  - 사진 사이즈는 일관되게 전처리되지 않았으며, 정면 얼굴 사진만 사용하지 않음.
- **클래스 라벨**:
  - Class label: harin
  - Class label: pildo
  - Class label: yera

---

## II. 모델의 구조

### 모델 특징
1. **입력 데이터**: 224x224 픽셀 크기의 3채널(RGB) 컬러 이미지.
2. **VGG16 모델 기반**:
   - 마지막 합성곱 레이어에 전역 평균 풀링(Global Average Pooling) 적용.
   - 512개의 특징 벡터 생성 후 이를 32개로 축소.
3. **활성화 함수**:
   - ReLU 활성화 함수 사용.
   - Softmax 활성화 함수를 통해 3개의 클래스 확률 계산.
4. **전이 학습(Transfer Learning)**:
   - ImageNet으로 사전 학습된 VGG16 모델 활용.
   - 기존 VGG16 모델의 분류 층을 새로운 데이터 셋에 맞게 수정.

---

## III. 학습 과정

### 학습 특징
- **Validation 손실 함수 감소**: 전반적으로 검증 데이터에 대해 손실 값 감소와 정확도 증가를 확인.
- **데이터 증강(Data Augmentation)**:
  - 회전, 이동, 확대/축소 등을 적용하여 일반화 성능 향상.
  - 과적합 방지 효과.

---

## IV. 학습 결과

### 모델 평가
- **전반적 성능**: Validation 정확도와 손실이 개선되었으나, 훈련 데이터와의 성능 차이가 발생.
- **모델 성능**:
  - 전이 학습을 통해 적은 데이터로도 효과적인 학습 결과 확인.
  - 데이터 증강을 통해 다양한 상황에서의 일반화 성능 개선.

---

## V. 프로젝트 수행을 통해 얻은 경험

### 전이 학습의 중요성
- 대규모 데이터 셋으로 사전 학습된 VGG16을 활용해 적은 데이터로도 효과적인 모델 개발 가능.
- 검증된 모델 구조를 활용하면, 처음부터 모델 설계 없이 빠르게 시작 가능.

### 데이터 증강의 효과
- 데이터 증강 기법을 통해 모델의 일반화 성능을 높이는 방법을 이해.
- 과도한 증강은 오히려 학습을 방해할 수 있음.

### 아쉬운 점
- 손실(Loss)와 정확도(Accuracy) 외 다양한 평가 지표 활용 부족.
- 모델 성능을 다각적으로 분석하지 못한 점이 아쉬움.

---

## VI. 결론 및 개선 방향

- **결론**:
  - VGG16 기반 전이 학습을 통해 적은 데이터로도 효과적인 이미지 분류가 가능함을 확인.
  - 데이터 증강 기법이 모델의 일반화 성능 향상에 기여.

- **개선 방향**:
  - 다양한 평가 지표를 활용하여 모델 성능을 다각적으로 분석.
  - 데이터 전처리 과정에서 입력 데이터의 일관성을 확보하여 성능 개선.
  - 정면 얼굴 이미지를 포함한 다양한 각도의 데이터를 활용하여 학습 데이터 확장.

